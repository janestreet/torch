(* THIS FILE IS AUTOMATICALLY GENERATED, DO NOT EDIT BY HAND! *)

open Ctypes
open Torch_bindings.Type_defs
open Torch_stubs
open Wrapper_utils
open C.Generated

let __and__ self other = stubs___and__ self other |> with_tensor_gc
let __and__tensor_ self other = stubs___and__tensor_ self other |> with_tensor_gc
let __iand__ self other = stubs___iand__ self other |> with_tensor_gc
let __iand__tensor_ self other = stubs___iand__tensor_ self other |> with_tensor_gc
let __ilshift__ self other = stubs___ilshift__ self other |> with_tensor_gc
let __ilshift__tensor_ self other = stubs___ilshift__tensor_ self other |> with_tensor_gc
let __ior__ self other = stubs___ior__ self other |> with_tensor_gc
let __ior__tensor_ self other = stubs___ior__tensor_ self other |> with_tensor_gc
let __irshift__ self other = stubs___irshift__ self other |> with_tensor_gc
let __irshift__tensor_ self other = stubs___irshift__tensor_ self other |> with_tensor_gc
let __ixor__ self other = stubs___ixor__ self other |> with_tensor_gc
let __ixor__tensor_ self other = stubs___ixor__tensor_ self other |> with_tensor_gc
let __lshift__ self other = stubs___lshift__ self other |> with_tensor_gc

let __lshift__scalar_out_ ~out self other =
  stubs___lshift__scalar_out_ out self other |> with_tensor_gc
;;

let __lshift__tensor_ self other = stubs___lshift__tensor_ self other |> with_tensor_gc

let __lshift__tensor_out_ ~out self other =
  stubs___lshift__tensor_out_ out self other |> with_tensor_gc
;;

let __or__ self other = stubs___or__ self other |> with_tensor_gc
let __or__tensor_ self other = stubs___or__tensor_ self other |> with_tensor_gc
let __rshift__ self other = stubs___rshift__ self other |> with_tensor_gc

let __rshift__scalar_out_ ~out self other =
  stubs___rshift__scalar_out_ out self other |> with_tensor_gc
;;

let __rshift__tensor_ self other = stubs___rshift__tensor_ self other |> with_tensor_gc

let __rshift__tensor_out_ ~out self other =
  stubs___rshift__tensor_out_ out self other |> with_tensor_gc
;;

let __xor__ self other = stubs___xor__ self other |> with_tensor_gc
let __xor__tensor_ self other = stubs___xor__tensor_ self other |> with_tensor_gc

let _adaptive_avg_pool2d self ~output_size =
  stubs__adaptive_avg_pool2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let _adaptive_avg_pool2d_backward ~grad_output self =
  stubs__adaptive_avg_pool2d_backward grad_output self |> with_tensor_gc
;;

let _adaptive_avg_pool2d_backward_out ~out ~grad_output self =
  stubs__adaptive_avg_pool2d_backward_out out grad_output self |> with_tensor_gc
;;

let _adaptive_avg_pool2d_out ~out self ~output_size =
  stubs__adaptive_avg_pool2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let _adaptive_avg_pool3d self ~output_size =
  stubs__adaptive_avg_pool3d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let _adaptive_avg_pool3d_backward ~grad_output self =
  stubs__adaptive_avg_pool3d_backward grad_output self |> with_tensor_gc
;;

let _adaptive_avg_pool3d_backward_out ~out ~grad_output self =
  stubs__adaptive_avg_pool3d_backward_out out grad_output self |> with_tensor_gc
;;

let _adaptive_avg_pool3d_out ~out self ~output_size =
  stubs__adaptive_avg_pool3d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let _add_batch_dim self ~batch_dim ~level =
  stubs__add_batch_dim self (Int64.of_int batch_dim) (Int64.of_int level)
  |> with_tensor_gc
;;

let _add_relu ?alpha self other =
  stubs__add_relu
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _add_relu_ ?alpha self other =
  stubs__add_relu_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _add_relu_out ?alpha ~out self other =
  stubs__add_relu_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _add_relu_scalar ?alpha self other =
  stubs__add_relu_scalar
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _add_relu_scalar_ ?alpha self other =
  stubs__add_relu_scalar_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _add_relu_scalar_out ?alpha ~out self other =
  stubs__add_relu_scalar_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _addmm_activation ?beta ?alpha self ~mat1 ~mat2 ~use_gelu =
  stubs__addmm_activation
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
    (if use_gelu then 1 else 0)
  |> with_tensor_gc
;;

let _addmm_activation_out ?beta ?alpha ~out self ~mat1 ~mat2 ~use_gelu =
  stubs__addmm_activation_out
    out
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
    (if use_gelu then 1 else 0)
  |> with_tensor_gc
;;

let _aminmax self =
  let out__ = CArray.make raw_tensor 2 in
  stubs__aminmax (CArray.start out__) self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _aminmax_dim self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs__aminmax_dim
    (CArray.start out__)
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _aminmax_dim_out ~out0 ~out1 self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs__aminmax_dim_out
    (CArray.start out__)
    out0
    out1
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _aminmax_out ~out0 ~out1 self =
  let out__ = CArray.make raw_tensor 2 in
  stubs__aminmax_out (CArray.start out__) out0 out1 self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _amp_update_scale
  self
  ~growth_tracker
  ~found_inf
  ~scale_growth_factor
  ~scale_backoff_factor
  ~growth_interval
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__amp_update_scale
    (CArray.start out__)
    self
    growth_tracker
    found_inf
    scale_growth_factor
    scale_backoff_factor
    (Int64.of_int growth_interval);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _amp_update_scale_
  self
  ~growth_tracker
  ~found_inf
  ~scale_growth_factor
  ~scale_backoff_factor
  ~growth_interval
  =
  stubs__amp_update_scale_
    self
    growth_tracker
    found_inf
    scale_growth_factor
    scale_backoff_factor
    (Int64.of_int growth_interval)
  |> with_tensor_gc
;;

let _amp_update_scale_out
  ~out
  self
  ~growth_tracker
  ~found_inf
  ~scale_growth_factor
  ~scale_backoff_factor
  ~growth_interval
  =
  stubs__amp_update_scale_out
    out
    self
    growth_tracker
    found_inf
    scale_growth_factor
    scale_backoff_factor
    (Int64.of_int growth_interval)
  |> with_tensor_gc
;;

let _assert_scalar self ~assert_msg = stubs__assert_scalar self assert_msg

let _assert_tensor_metadata ~a ~size ~stride ~dtype ~device =
  stubs__assert_tensor_metadata
    a
    (match size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match size with
     | None -> -1
     | Some v -> List.length v)
    (match stride with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match stride with
     | None -> -1
     | Some v -> List.length v)
    (Kind.packed_to_int dtype)
    (Device.option_to_int device)
;;

let _autocast_to_full_precision self ~cuda_enabled ~cpu_enabled =
  stubs__autocast_to_full_precision
    self
    (if cuda_enabled then 1 else 0)
    (if cpu_enabled then 1 else 0)
  |> with_tensor_gc
;;

let _autocast_to_reduced_precision self ~cuda_enabled ~cpu_enabled ~cuda_dtype ~cpu_dtype =
  stubs__autocast_to_reduced_precision
    self
    (if cuda_enabled then 1 else 0)
    (if cpu_enabled then 1 else 0)
    (Kind.packed_to_int cuda_dtype)
    (Kind.packed_to_int cpu_dtype)
  |> with_tensor_gc
;;

let _batch_norm_no_update input ~weight ~bias ~running_mean ~running_var ~momentum ~eps =
  let out__ = CArray.make raw_tensor 4 in
  stubs__batch_norm_no_update
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _batch_norm_no_update_out
  ~out0
  ~out1
  ~out2
  ~out3
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__batch_norm_no_update_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _batch_norm_with_update input ~weight ~bias ~running_mean ~running_var ~momentum ~eps =
  let out__ = CArray.make raw_tensor 4 in
  stubs__batch_norm_with_update
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _batch_norm_with_update_functional
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 6 in
  stubs__batch_norm_with_update_functional
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  let t5 = CArray.get out__ 5 |> with_tensor_gc in
  t0, t1, t2, t3, t4, t5
;;

let _batch_norm_with_update_out
  ~out
  ~save_mean
  ~save_invstd
  ~reserve
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__batch_norm_with_update_out
    (CArray.start out__)
    out
    save_mean
    save_invstd
    reserve
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _cast_byte self ~non_blocking =
  stubs__cast_byte self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_char self ~non_blocking =
  stubs__cast_char self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_double self ~non_blocking =
  stubs__cast_double self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_float self ~non_blocking =
  stubs__cast_float self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_half self ~non_blocking =
  stubs__cast_half self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_int self ~non_blocking =
  stubs__cast_int self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_long self ~non_blocking =
  stubs__cast_long self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cast_short self ~non_blocking =
  stubs__cast_short self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cdist_backward ~grad ~x1 ~x2 ~p ~cdist =
  stubs__cdist_backward grad x1 x2 p cdist |> with_tensor_gc
;;

let _cdist_backward_out ~out ~grad ~x1 ~x2 ~p ~cdist =
  stubs__cdist_backward_out out grad x1 x2 p cdist |> with_tensor_gc
;;

let _cholesky_solve_helper self ~a ~upper =
  stubs__cholesky_solve_helper self a (if upper then 1 else 0) |> with_tensor_gc
;;

let _cholesky_solve_helper_out ~out self ~a ~upper =
  stubs__cholesky_solve_helper_out out self a (if upper then 1 else 0) |> with_tensor_gc
;;

let _chunk_cat tensors ~dim ~num_chunks =
  let result =
    stubs__chunk_cat
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
      (Int64.of_int num_chunks)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let _chunk_cat_out ~out tensors ~dim ~num_chunks =
  let result =
    stubs__chunk_cat_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
      (Int64.of_int num_chunks)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let _coalesce self = stubs__coalesce self |> with_tensor_gc
let _coalesce_out ~out self = stubs__coalesce_out out self |> with_tensor_gc

let _coalesced self ~coalesced =
  stubs__coalesced self (if coalesced then 1 else 0) |> with_tensor_gc
;;

let _coalesced_ self ~coalesced =
  stubs__coalesced_ self (if coalesced then 1 else 0) |> with_tensor_gc
;;

let _coalesced_out ~out self ~coalesced =
  stubs__coalesced_out out self (if coalesced then 1 else 0) |> with_tensor_gc
;;

let _compute_linear_combination input ~coefficients =
  stubs__compute_linear_combination input coefficients |> with_tensor_gc
;;

let _compute_linear_combination_out ~out input ~coefficients =
  stubs__compute_linear_combination_out out input coefficients |> with_tensor_gc
;;

let _conj self = stubs__conj self |> with_tensor_gc
let _conj_copy self = stubs__conj_copy self |> with_tensor_gc
let _conj_copy_out ~out self = stubs__conj_copy_out out self |> with_tensor_gc
let _conj_physical self = stubs__conj_physical self |> with_tensor_gc
let _conj_physical_out ~out self = stubs__conj_physical_out out self |> with_tensor_gc

let _conv_depthwise2d self ~weight ~kernel_size ~bias ~stride ~padding ~dilation =
  stubs__conv_depthwise2d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let _conv_depthwise2d_out ~out self ~weight ~kernel_size ~bias ~stride ~padding ~dilation =
  stubs__conv_depthwise2d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let _convert_indices_from_coo_to_csr self ~size ~out_int32 =
  stubs__convert_indices_from_coo_to_csr
    self
    (Int64.of_int size)
    (if out_int32 then 1 else 0)
  |> with_tensor_gc
;;

let _convert_indices_from_coo_to_csr_out ~out self ~size ~out_int32 =
  stubs__convert_indices_from_coo_to_csr_out
    out
    self
    (Int64.of_int size)
    (if out_int32 then 1 else 0)
  |> with_tensor_gc
;;

let _convert_indices_from_csr_to_coo ~crow_indices ~col_indices ~out_int32 ~transpose =
  stubs__convert_indices_from_csr_to_coo
    crow_indices
    col_indices
    (if out_int32 then 1 else 0)
    (if transpose then 1 else 0)
  |> with_tensor_gc
;;

let _convert_indices_from_csr_to_coo_out
  ~out
  ~crow_indices
  ~col_indices
  ~out_int32
  ~transpose
  =
  stubs__convert_indices_from_csr_to_coo_out
    out
    crow_indices
    col_indices
    (if out_int32 then 1 else 0)
    (if transpose then 1 else 0)
  |> with_tensor_gc
;;

let _convert_weight_to_int4pack self ~innerktiles =
  stubs__convert_weight_to_int4pack self (Int64.of_int innerktiles) |> with_tensor_gc
;;

let _convert_weight_to_int4pack_for_cpu self ~innerktiles =
  stubs__convert_weight_to_int4pack_for_cpu self (Int64.of_int innerktiles)
  |> with_tensor_gc
;;

let _convolution
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  ~benchmark
  ~deterministic
  ~cudnn_enabled
  ~allow_tf32
  =
  stubs__convolution
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if cudnn_enabled then 1 else 0)
    (if allow_tf32 then 1 else 0)
  |> with_tensor_gc
;;

let _convolution_deprecated
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  ~benchmark
  ~deterministic
  ~cudnn_enabled
  =
  stubs__convolution_deprecated
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if cudnn_enabled then 1 else 0)
  |> with_tensor_gc
;;

let _convolution_mode input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs__convolution_mode
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    padding
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let _convolution_out
  ~out
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  ~benchmark
  ~deterministic
  ~cudnn_enabled
  ~allow_tf32
  =
  stubs__convolution_out
    out
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if cudnn_enabled then 1 else 0)
    (if allow_tf32 then 1 else 0)
  |> with_tensor_gc
;;

let _copy_from self ~dst ~non_blocking =
  stubs__copy_from self dst (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _copy_from_and_resize self ~dst =
  stubs__copy_from_and_resize self dst |> with_tensor_gc
;;

let _copy_from_and_resize_out ~out self ~dst =
  stubs__copy_from_and_resize_out out self dst |> with_tensor_gc
;;

let _copy_from_out ~out self ~dst ~non_blocking =
  stubs__copy_from_out out self dst (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _cslt_compress input = stubs__cslt_compress input |> with_tensor_gc

let _cslt_sparse_mm
  ~compressed_a
  ~dense_b
  ~bias
  ~alpha
  ~out_dtype
  ~transpose_result
  ~alg_id
  ~split_k
  ~split_k_one_kernel
  =
  stubs__cslt_sparse_mm
    compressed_a
    dense_b
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match alpha with
     | Some v -> v
     | None -> none_gc_tensor)
    (Kind.packed_to_int out_dtype)
    (if transpose_result then 1 else 0)
    (Int64.of_int alg_id)
    (Int64.of_int split_k)
    (if split_k_one_kernel then 1 else 0)
  |> with_tensor_gc
;;

let _cslt_sparse_mm_search
  ~compressed_a
  ~dense_b
  ~bias
  ~alpha
  ~out_dtype
  ~transpose_result
  =
  stubs__cslt_sparse_mm_search
    compressed_a
    dense_b
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match alpha with
     | Some v -> v
     | None -> none_gc_tensor)
    (Kind.packed_to_int out_dtype)
    (if transpose_result then 1 else 0)
;;

let _ctc_loss ~log_probs ~targets ~input_lengths ~target_lengths ~blank ~zero_infinity =
  let out__ = CArray.make raw_tensor 2 in
  stubs__ctc_loss
    (CArray.start out__)
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _ctc_loss_backward
  ~grad
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~neg_log_likelihood
  ~log_alpha
  ~blank
  ~zero_infinity
  =
  stubs__ctc_loss_backward
    grad
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    neg_log_likelihood
    log_alpha
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0)
  |> with_tensor_gc
;;

let _ctc_loss_backward_out
  ~out
  ~grad
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~neg_log_likelihood
  ~log_alpha
  ~blank
  ~zero_infinity
  =
  stubs__ctc_loss_backward_out
    out
    grad
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    neg_log_likelihood
    log_alpha
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0)
  |> with_tensor_gc
;;

let _ctc_loss_backward_tensor
  ~grad
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~neg_log_likelihood
  ~log_alpha
  ~blank
  ~zero_infinity
  =
  stubs__ctc_loss_backward_tensor
    grad
    log_probs
    targets
    input_lengths
    target_lengths
    neg_log_likelihood
    log_alpha
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0)
  |> with_tensor_gc
;;

let _ctc_loss_out
  ~out0
  ~out1
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~zero_infinity
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__ctc_loss_out
    (CArray.start out__)
    out0
    out1
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _ctc_loss_tensor
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~zero_infinity
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__ctc_loss_tensor
    (CArray.start out__)
    log_probs
    targets
    input_lengths
    target_lengths
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _ctc_loss_tensor_out
  ~out0
  ~out1
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~zero_infinity
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__ctc_loss_tensor_out
    (CArray.start out__)
    out0
    out1
    log_probs
    targets
    input_lengths
    target_lengths
    (Int64.of_int blank)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _cudnn_ctc_loss
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~deterministic
  ~zero_infinity
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__cudnn_ctc_loss
    (CArray.start out__)
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    (Int64.of_int blank)
    (if deterministic then 1 else 0)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _cudnn_ctc_loss_out
  ~out0
  ~out1
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~deterministic
  ~zero_infinity
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__cudnn_ctc_loss_out
    (CArray.start out__)
    out0
    out1
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    (Int64.of_int blank)
    (if deterministic then 1 else 0)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _cudnn_ctc_loss_tensor
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~deterministic
  ~zero_infinity
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__cudnn_ctc_loss_tensor
    (CArray.start out__)
    log_probs
    targets
    input_lengths
    target_lengths
    (Int64.of_int blank)
    (if deterministic then 1 else 0)
    (if zero_infinity then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _cudnn_init_dropout_state ~dropout ~train ~dropout_seed ~options =
  stubs__cudnn_init_dropout_state
    dropout
    (if train then 1 else 0)
    (Int64.of_int dropout_seed)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _cudnn_init_dropout_state_out ~out ~dropout ~train ~dropout_seed =
  stubs__cudnn_init_dropout_state_out
    out
    dropout
    (if train then 1 else 0)
    (Int64.of_int dropout_seed)
  |> with_tensor_gc
;;

let _cudnn_rnn
  input
  ~weight
  ~weight_stride0
  ~weight_buf
  ~hx
  ~cx
  ~mode
  ~hidden_size
  ~proj_size
  ~num_layers
  ~batch_first
  ~dropout
  ~train
  ~bidirectional
  ~batch_sizes
  ~dropout_state
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs__cudnn_rnn
    (CArray.start out__)
    input
    (CArray.of_list gc_tensor weight |> CArray.start)
    (List.length weight)
    (Int64.of_int weight_stride0)
    (match weight_buf with
     | Some v -> v
     | None -> none_gc_tensor)
    hx
    (match cx with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int proj_size)
    (Int64.of_int num_layers)
    (if batch_first then 1 else 0)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (match dropout_state with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  keep_values_alive weight;
  t0, t1, t2, t3, t4
;;

let _cudnn_rnn_flatten_weight
  ~weight_arr
  ~weight_stride0
  ~input_size
  ~mode
  ~hidden_size
  ~proj_size
  ~num_layers
  ~batch_first
  ~bidirectional
  =
  let result =
    stubs__cudnn_rnn_flatten_weight
      (CArray.of_list gc_tensor weight_arr |> CArray.start)
      (List.length weight_arr)
      (Int64.of_int weight_stride0)
      (Int64.of_int input_size)
      (Int64.of_int mode)
      (Int64.of_int hidden_size)
      (Int64.of_int proj_size)
      (Int64.of_int num_layers)
      (if batch_first then 1 else 0)
      (if bidirectional then 1 else 0)
    |> with_tensor_gc
  in
  keep_values_alive weight_arr;
  result
;;

let _cudnn_rnn_flatten_weight_out
  ~out
  ~weight_arr
  ~weight_stride0
  ~input_size
  ~mode
  ~hidden_size
  ~proj_size
  ~num_layers
  ~batch_first
  ~bidirectional
  =
  let result =
    stubs__cudnn_rnn_flatten_weight_out
      out
      (CArray.of_list gc_tensor weight_arr |> CArray.start)
      (List.length weight_arr)
      (Int64.of_int weight_stride0)
      (Int64.of_int input_size)
      (Int64.of_int mode)
      (Int64.of_int hidden_size)
      (Int64.of_int proj_size)
      (Int64.of_int num_layers)
      (if batch_first then 1 else 0)
      (if bidirectional then 1 else 0)
    |> with_tensor_gc
  in
  keep_values_alive weight_arr;
  result
;;

let _cudnn_rnn_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~out4
  input
  ~weight
  ~weight_stride0
  ~weight_buf
  ~hx
  ~cx
  ~mode
  ~hidden_size
  ~proj_size
  ~num_layers
  ~batch_first
  ~dropout
  ~train
  ~bidirectional
  ~batch_sizes
  ~dropout_state
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs__cudnn_rnn_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    out4
    input
    (CArray.of_list gc_tensor weight |> CArray.start)
    (List.length weight)
    (Int64.of_int weight_stride0)
    (match weight_buf with
     | Some v -> v
     | None -> none_gc_tensor)
    hx
    (match cx with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int proj_size)
    (Int64.of_int num_layers)
    (if batch_first then 1 else 0)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (match dropout_state with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  keep_values_alive weight;
  t0, t1, t2, t3, t4
;;

let _debug_has_internal_overlap self = stubs__debug_has_internal_overlap self
let _dim_arange ~like ~dim = stubs__dim_arange like (Int64.of_int dim) |> with_tensor_gc
let _dimi self = stubs__dimi self
let _dimv self = stubs__dimv self

let _dirichlet_grad ~x ~alpha ~total =
  stubs__dirichlet_grad x alpha total |> with_tensor_gc
;;

let _dirichlet_grad_out ~out ~x ~alpha ~total =
  stubs__dirichlet_grad_out out x alpha total |> with_tensor_gc
;;

let _dyn_quant_matmul_4bit ~inp ~packed_weights ~block_size ~in_features ~out_features =
  stubs__dyn_quant_matmul_4bit
    inp
    packed_weights
    (Int64.of_int block_size)
    (Int64.of_int in_features)
    (Int64.of_int out_features)
  |> with_tensor_gc
;;

let _dyn_quant_pack_4bit_weight
  ~weights
  ~scales_zeros
  ~bias
  ~block_size
  ~in_features
  ~out_features
  =
  stubs__dyn_quant_pack_4bit_weight
    weights
    scales_zeros
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int block_size)
    (Int64.of_int in_features)
    (Int64.of_int out_features)
  |> with_tensor_gc
;;

let _efficient_attention_backward
  ~grad_out_
  ~query
  ~key
  ~value
  ~bias
  ~out
  ~cu_seqlens_q
  ~cu_seqlens_k
  ~max_seqlen_q
  ~max_seqlen_k
  ~logsumexp
  ~dropout_p
  ~philox_seed
  ~philox_offset
  ~custom_mask_type
  ~bias_requires_grad
  ~scale
  ~num_splits_key
  ~window_size
  ~shared_storage_dqdkdv
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__efficient_attention_backward
    (CArray.start out__)
    grad_out_
    query
    key
    value
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    out
    (match cu_seqlens_q with
     | Some v -> v
     | None -> none_gc_tensor)
    (match cu_seqlens_k with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int max_seqlen_q)
    (Int64.of_int max_seqlen_k)
    logsumexp
    dropout_p
    philox_seed
    philox_offset
    (Int64.of_int custom_mask_type)
    (if bias_requires_grad then 1 else 0)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1)
    (match num_splits_key with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match num_splits_key with
     | Some _ -> 0
     | None -> 1)
    (match window_size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match window_size with
     | Some _ -> 0
     | None -> 1)
    (if shared_storage_dqdkdv then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _efficientzerotensor ~size ~options =
  stubs__efficientzerotensor
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _efficientzerotensor_out ~out ~size =
  stubs__efficientzerotensor_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _embedding_bag
  ~weight
  ~indices
  ~offsets
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~include_last_offset
  ~padding_idx
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__embedding_bag
    (CArray.start out__)
    weight
    indices
    offsets
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (if include_last_offset then 1 else 0)
    (Int64.of_int padding_idx);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _embedding_bag_backward
  ~grad
  ~indices
  ~offsets
  ~offset2bag
  ~bag_size
  ~maximum_indices
  ~num_weights
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~padding_idx
  =
  stubs__embedding_bag_backward
    grad
    indices
    offsets
    offset2bag
    bag_size
    maximum_indices
    (Int64.of_int num_weights)
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int padding_idx)
  |> with_tensor_gc
;;

let _embedding_bag_dense_backward
  ~grad
  ~indices
  ~offset2bag
  ~bag_size
  ~maximum_indices
  ~num_weights
  ~scale_grad_by_freq
  ~mode
  ~per_sample_weights
  ~padding_idx
  =
  stubs__embedding_bag_dense_backward
    grad
    indices
    offset2bag
    bag_size
    maximum_indices
    (Int64.of_int num_weights)
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int padding_idx)
  |> with_tensor_gc
;;

let _embedding_bag_dense_backward_out
  ~out
  ~grad
  ~indices
  ~offset2bag
  ~bag_size
  ~maximum_indices
  ~num_weights
  ~scale_grad_by_freq
  ~mode
  ~per_sample_weights
  ~padding_idx
  =
  stubs__embedding_bag_dense_backward_out
    out
    grad
    indices
    offset2bag
    bag_size
    maximum_indices
    (Int64.of_int num_weights)
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int padding_idx)
  |> with_tensor_gc
;;

let _embedding_bag_forward_only
  ~weight
  ~indices
  ~offsets
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~include_last_offset
  ~padding_idx
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__embedding_bag_forward_only
    (CArray.start out__)
    weight
    indices
    offsets
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (if include_last_offset then 1 else 0)
    (Int64.of_int padding_idx);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _embedding_bag_forward_only_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~weight
  ~indices
  ~offsets
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~include_last_offset
  ~padding_idx
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__embedding_bag_forward_only_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    weight
    indices
    offsets
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (if include_last_offset then 1 else 0)
    (Int64.of_int padding_idx);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _embedding_bag_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~weight
  ~indices
  ~offsets
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~include_last_offset
  ~padding_idx
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__embedding_bag_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    weight
    indices
    offsets
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (if include_last_offset then 1 else 0)
    (Int64.of_int padding_idx);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _embedding_bag_per_sample_weights_backward
  ~grad
  ~weight
  ~indices
  ~offsets
  ~offset2bag
  ~mode
  ~padding_idx
  =
  stubs__embedding_bag_per_sample_weights_backward
    grad
    weight
    indices
    offsets
    offset2bag
    (Int64.of_int mode)
    (Int64.of_int padding_idx)
  |> with_tensor_gc
;;

let _embedding_bag_per_sample_weights_backward_out
  ~out
  ~grad
  ~weight
  ~indices
  ~offsets
  ~offset2bag
  ~mode
  ~padding_idx
  =
  stubs__embedding_bag_per_sample_weights_backward_out
    out
    grad
    weight
    indices
    offsets
    offset2bag
    (Int64.of_int mode)
    (Int64.of_int padding_idx)
  |> with_tensor_gc
;;

let _embedding_bag_sparse_backward
  ~grad
  ~indices
  ~offsets
  ~offset2bag
  ~bag_size
  ~num_weights
  ~scale_grad_by_freq
  ~mode
  ~per_sample_weights
  ~padding_idx
  =
  stubs__embedding_bag_sparse_backward
    grad
    indices
    offsets
    offset2bag
    bag_size
    (Int64.of_int num_weights)
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int padding_idx)
  |> with_tensor_gc
;;

let _empty_affine_quantized ~size ~options ~scale ~zero_point =
  stubs__empty_affine_quantized
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    scale
    (Int64.of_int zero_point)
  |> with_tensor_gc
;;

let _empty_affine_quantized_out ~out ~size ~scale ~zero_point =
  stubs__empty_affine_quantized_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    scale
    (Int64.of_int zero_point)
  |> with_tensor_gc
;;

let _empty_per_channel_affine_quantized ~size ~scales ~zero_points ~axis ~options =
  stubs__empty_per_channel_affine_quantized
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    scales
    zero_points
    (Int64.of_int axis)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _empty_per_channel_affine_quantized_out ~out ~size ~scales ~zero_points ~axis =
  stubs__empty_per_channel_affine_quantized_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    scales
    zero_points
    (Int64.of_int axis)
  |> with_tensor_gc
;;

let _euclidean_dist ~x1 ~x2 = stubs__euclidean_dist x1 x2 |> with_tensor_gc

let _euclidean_dist_out ~out ~x1 ~x2 =
  stubs__euclidean_dist_out out x1 x2 |> with_tensor_gc
;;

let _fake_quantize_learnable_per_channel_affine
  self
  ~scale
  ~zero_point
  ~axis
  ~quant_min
  ~quant_max
  ~grad_factor
  =
  stubs__fake_quantize_learnable_per_channel_affine
    self
    scale
    zero_point
    (Int64.of_int axis)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    grad_factor
  |> with_tensor_gc
;;

let _fake_quantize_learnable_per_channel_affine_backward
  ~grad
  self
  ~scale
  ~zero_point
  ~axis
  ~quant_min
  ~quant_max
  ~grad_factor
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__fake_quantize_learnable_per_channel_affine_backward
    (CArray.start out__)
    grad
    self
    scale
    zero_point
    (Int64.of_int axis)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    grad_factor;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _fake_quantize_learnable_per_channel_affine_out
  ~out
  self
  ~scale
  ~zero_point
  ~axis
  ~quant_min
  ~quant_max
  ~grad_factor
  =
  stubs__fake_quantize_learnable_per_channel_affine_out
    out
    self
    scale
    zero_point
    (Int64.of_int axis)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    grad_factor
  |> with_tensor_gc
;;

let _fake_quantize_learnable_per_tensor_affine
  self
  ~scale
  ~zero_point
  ~quant_min
  ~quant_max
  ~grad_factor
  =
  stubs__fake_quantize_learnable_per_tensor_affine
    self
    scale
    zero_point
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    grad_factor
  |> with_tensor_gc
;;

let _fake_quantize_learnable_per_tensor_affine_backward
  ~grad
  self
  ~scale
  ~zero_point
  ~quant_min
  ~quant_max
  ~grad_factor
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__fake_quantize_learnable_per_tensor_affine_backward
    (CArray.start out__)
    grad
    self
    scale
    zero_point
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    grad_factor;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _fake_quantize_learnable_per_tensor_affine_out
  ~out
  self
  ~scale
  ~zero_point
  ~quant_min
  ~quant_max
  ~grad_factor
  =
  stubs__fake_quantize_learnable_per_tensor_affine_out
    out
    self
    scale
    zero_point
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    grad_factor
  |> with_tensor_gc
;;

let _fake_quantize_per_tensor_affine_cachemask_tensor_qparams
  self
  ~scale
  ~zero_point
  ~fake_quant_enabled
  ~quant_min
  ~quant_max
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__fake_quantize_per_tensor_affine_cachemask_tensor_qparams
    (CArray.start out__)
    self
    scale
    zero_point
    fake_quant_enabled
    (Int64.of_int quant_min)
    (Int64.of_int quant_max);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _fake_quantize_per_tensor_affine_cachemask_tensor_qparams_out
  ~out0
  ~out1
  self
  ~scale
  ~zero_point
  ~fake_quant_enabled
  ~quant_min
  ~quant_max
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__fake_quantize_per_tensor_affine_cachemask_tensor_qparams_out
    (CArray.start out__)
    out0
    out1
    self
    scale
    zero_point
    fake_quant_enabled
    (Int64.of_int quant_min)
    (Int64.of_int quant_max);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _fft_c2c self ~dim ~normalization ~forward =
  stubs__fft_c2c
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Int64.of_int normalization)
    (if forward then 1 else 0)
  |> with_tensor_gc
;;

let _fft_c2c_out ~out self ~dim ~normalization ~forward =
  stubs__fft_c2c_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Int64.of_int normalization)
    (if forward then 1 else 0)
  |> with_tensor_gc
;;

let _fft_c2r self ~dim ~normalization ~last_dim_size =
  stubs__fft_c2r
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Int64.of_int normalization)
    (Int64.of_int last_dim_size)
  |> with_tensor_gc
;;

let _fft_c2r_out ~out self ~dim ~normalization ~last_dim_size =
  stubs__fft_c2r_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Int64.of_int normalization)
    (Int64.of_int last_dim_size)
  |> with_tensor_gc
;;

let _fft_r2c self ~dim ~normalization ~onesided =
  stubs__fft_r2c
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Int64.of_int normalization)
    (if onesided then 1 else 0)
  |> with_tensor_gc
;;

let _fft_r2c_out ~out self ~dim ~normalization ~onesided =
  stubs__fft_r2c_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Int64.of_int normalization)
    (if onesided then 1 else 0)
  |> with_tensor_gc
;;

let _fill_mem_eff_dropout_mask_ self ~dropout_p ~seed ~offset =
  stubs__fill_mem_eff_dropout_mask_
    self
    dropout_p
    (Int64.of_int seed)
    (Int64.of_int offset)
  |> with_tensor_gc
;;

let _flash_attention_backward
  ~grad_out
  ~query
  ~key
  ~value
  ~out
  ~logsumexp
  ~cum_seq_q
  ~cum_seq_k
  ~max_q
  ~max_k
  ~dropout_p
  ~is_causal
  ~rng_state
  ~unused
  ~scale
  ~window_size_left
  ~window_size_right
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__flash_attention_backward
    (CArray.start out__)
    grad_out
    query
    key
    value
    out
    logsumexp
    cum_seq_q
    cum_seq_k
    (Int64.of_int max_q)
    (Int64.of_int max_k)
    dropout_p
    (if is_causal then 1 else 0)
    rng_state
    unused
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1)
    (match window_size_left with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match window_size_left with
     | Some _ -> 0
     | None -> 1)
    (match window_size_right with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match window_size_right with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _foobar self ~arg1 ~arg2 ~arg3 =
  stubs__foobar
    self
    (if arg1 then 1 else 0)
    (if arg2 then 1 else 0)
    (if arg3 then 1 else 0)
  |> with_tensor_gc
;;

let _foobar_out ~out self ~arg1 ~arg2 ~arg3 =
  stubs__foobar_out
    out
    self
    (if arg1 then 1 else 0)
    (if arg2 then 1 else 0)
    (if arg3 then 1 else 0)
  |> with_tensor_gc
;;

let _functional_assert_async self ~assert_msg ~dep_token =
  stubs__functional_assert_async self assert_msg dep_token |> with_tensor_gc
;;

let _functional_assert_scalar self ~assert_msg ~dep_token =
  stubs__functional_assert_scalar self assert_msg dep_token |> with_tensor_gc
;;

let _functional_sym_constrain_range ~size ~min ~max ~dep_token =
  stubs__functional_sym_constrain_range
    size
    (match min with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match min with
     | Some _ -> 0
     | None -> 1)
    (match max with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match max with
     | Some _ -> 0
     | None -> 1)
    dep_token
  |> with_tensor_gc
;;

let _functional_sym_constrain_range_for_size ~size ~min ~max ~dep_token =
  stubs__functional_sym_constrain_range_for_size
    size
    (match min with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match min with
     | Some _ -> 0
     | None -> 1)
    (match max with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match max with
     | Some _ -> 0
     | None -> 1)
    dep_token
  |> with_tensor_gc
;;

let _fused_adagrad
  ~out
  self
  ~grads
  ~state_sums
  ~state_steps
  ~lr
  ~lr_decay
  ~weight_decay
  ~eps
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adagrad
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor state_sums |> CArray.start)
      (List.length state_sums)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      lr_decay
      weight_decay
      eps
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive state_sums;
  keep_values_alive state_steps;
  result
;;

let _fused_adagrad_
  self
  ~grads
  ~state_sums
  ~state_steps
  ~lr
  ~lr_decay
  ~weight_decay
  ~eps
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adagrad_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor state_sums |> CArray.start)
      (List.length state_sums)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      lr_decay
      weight_decay
      eps
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive state_sums;
  keep_values_alive state_steps;
  result
;;

let _fused_adam
  ~out
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adam
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adam_
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adam_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adam_tensor_lr_
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adam_tensor_lr_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adam_tensor_lr_out
  ~out
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adam_tensor_lr_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adamw
  ~out
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adamw
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adamw_
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adamw_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adamw_tensor_lr_
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adamw_tensor_lr_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_adamw_tensor_lr_out
  ~out
  self
  ~grads
  ~exp_avgs
  ~exp_avg_sqs
  ~max_exp_avg_sqs
  ~state_steps
  ~lr
  ~beta1
  ~beta2
  ~weight_decay
  ~eps
  ~amsgrad
  ~maximize
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_adamw_tensor_lr_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor exp_avgs |> CArray.start)
      (List.length exp_avgs)
      (CArray.of_list gc_tensor exp_avg_sqs |> CArray.start)
      (List.length exp_avg_sqs)
      (CArray.of_list gc_tensor max_exp_avg_sqs |> CArray.start)
      (List.length max_exp_avg_sqs)
      (CArray.of_list gc_tensor state_steps |> CArray.start)
      (List.length state_steps)
      lr
      beta1
      beta2
      weight_decay
      eps
      (if amsgrad then 1 else 0)
      (if maximize then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive exp_avgs;
  keep_values_alive exp_avg_sqs;
  keep_values_alive max_exp_avg_sqs;
  keep_values_alive state_steps;
  result
;;

let _fused_dropout self ~p =
  let out__ = CArray.make raw_tensor 2 in
  stubs__fused_dropout (CArray.start out__) self p;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _fused_dropout_out ~out0 ~out1 self ~p =
  let out__ = CArray.make raw_tensor 2 in
  stubs__fused_dropout_out (CArray.start out__) out0 out1 self p;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _fused_moving_avg_obs_fq_helper
  self
  ~observer_on
  ~fake_quant_on
  ~running_min
  ~running_max
  ~scale
  ~zero_point
  ~averaging_const
  ~quant_min
  ~quant_max
  ~ch_axis
  ~per_row_fake_quant
  ~symmetric_quant
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__fused_moving_avg_obs_fq_helper
    (CArray.start out__)
    self
    observer_on
    fake_quant_on
    running_min
    running_max
    scale
    zero_point
    averaging_const
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    (Int64.of_int ch_axis)
    (if per_row_fake_quant then 1 else 0)
    (if symmetric_quant then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _fused_moving_avg_obs_fq_helper_functional
  self
  ~observer_on
  ~fake_quant_on
  ~running_min
  ~running_max
  ~scale
  ~zero_point
  ~averaging_const
  ~quant_min
  ~quant_max
  ~ch_axis
  ~per_row_fake_quant
  ~symmetric_quant
  =
  let out__ = CArray.make raw_tensor 6 in
  stubs__fused_moving_avg_obs_fq_helper_functional
    (CArray.start out__)
    self
    observer_on
    fake_quant_on
    running_min
    running_max
    scale
    zero_point
    averaging_const
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    (Int64.of_int ch_axis)
    (if per_row_fake_quant then 1 else 0)
    (if symmetric_quant then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  let t5 = CArray.get out__ 5 |> with_tensor_gc in
  t0, t1, t2, t3, t4, t5
;;

let _fused_moving_avg_obs_fq_helper_out
  ~out0
  ~out1
  self
  ~observer_on
  ~fake_quant_on
  ~running_min
  ~running_max
  ~scale
  ~zero_point
  ~averaging_const
  ~quant_min
  ~quant_max
  ~ch_axis
  ~per_row_fake_quant
  ~symmetric_quant
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__fused_moving_avg_obs_fq_helper_out
    (CArray.start out__)
    out0
    out1
    self
    observer_on
    fake_quant_on
    running_min
    running_max
    scale
    zero_point
    averaging_const
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    (Int64.of_int ch_axis)
    (if per_row_fake_quant then 1 else 0)
    (if symmetric_quant then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _fused_sdp_choice
  ~query
  ~key
  ~value
  ~attn_mask
  ~dropout_p
  ~is_causal
  ~scale
  ~enable_gqa
  =
  stubs__fused_sdp_choice
    query
    key
    value
    (match attn_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    dropout_p
    (if is_causal then 1 else 0)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1)
    (if enable_gqa then 1 else 0)
;;

let _fused_sgd
  ~out
  self
  ~grads
  ~momentum_buffer_list
  ~weight_decay
  ~momentum
  ~lr
  ~dampening
  ~nesterov
  ~maximize
  ~is_first_step
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_sgd
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor momentum_buffer_list |> CArray.start)
      (List.length momentum_buffer_list)
      weight_decay
      momentum
      lr
      dampening
      (if nesterov then 1 else 0)
      (if maximize then 1 else 0)
      (if is_first_step then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive momentum_buffer_list;
  result
;;

let _fused_sgd_
  self
  ~grads
  ~momentum_buffer_list
  ~weight_decay
  ~momentum
  ~lr
  ~dampening
  ~nesterov
  ~maximize
  ~is_first_step
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_sgd_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor momentum_buffer_list |> CArray.start)
      (List.length momentum_buffer_list)
      weight_decay
      momentum
      lr
      dampening
      (if nesterov then 1 else 0)
      (if maximize then 1 else 0)
      (if is_first_step then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive momentum_buffer_list;
  result
;;

let _fused_sgd_tensor_lr_
  self
  ~grads
  ~momentum_buffer_list
  ~weight_decay
  ~momentum
  ~lr
  ~dampening
  ~nesterov
  ~maximize
  ~is_first_step
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_sgd_tensor_lr_
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor momentum_buffer_list |> CArray.start)
      (List.length momentum_buffer_list)
      weight_decay
      momentum
      lr
      dampening
      (if nesterov then 1 else 0)
      (if maximize then 1 else 0)
      (if is_first_step then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive momentum_buffer_list;
  result
;;

let _fused_sgd_tensor_lr_out
  ~out
  self
  ~grads
  ~momentum_buffer_list
  ~weight_decay
  ~momentum
  ~lr
  ~dampening
  ~nesterov
  ~maximize
  ~is_first_step
  ~grad_scale
  ~found_inf
  =
  let result =
    stubs__fused_sgd_tensor_lr_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor self |> CArray.start)
      (List.length self)
      (CArray.of_list gc_tensor grads |> CArray.start)
      (List.length grads)
      (CArray.of_list gc_tensor momentum_buffer_list |> CArray.start)
      (List.length momentum_buffer_list)
      weight_decay
      momentum
      lr
      dampening
      (if nesterov then 1 else 0)
      (if maximize then 1 else 0)
      (if is_first_step then 1 else 0)
      (match grad_scale with
       | Some v -> v
       | None -> none_gc_tensor)
      (match found_inf with
       | Some v -> v
       | None -> none_gc_tensor)
  in
  keep_values_alive out;
  keep_values_alive self;
  keep_values_alive grads;
  keep_values_alive momentum_buffer_list;
  result
;;

let _fw_primal self ~level = stubs__fw_primal self (Int64.of_int level) |> with_tensor_gc

let _fw_primal_copy self ~level =
  stubs__fw_primal_copy self (Int64.of_int level) |> with_tensor_gc
;;

let _fw_primal_copy_out ~out self ~level =
  stubs__fw_primal_copy_out out self (Int64.of_int level) |> with_tensor_gc
;;

let _gather_sparse_backward self ~dim ~index ~grad =
  stubs__gather_sparse_backward self (Int64.of_int dim) index grad |> with_tensor_gc
;;

let _grid_sampler_2d_cpu_fallback
  input
  ~grid
  ~interpolation_mode
  ~padding_mode
  ~align_corners
  =
  stubs__grid_sampler_2d_cpu_fallback
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let _grid_sampler_2d_cpu_fallback_backward
  ~grad_output
  input
  ~grid
  ~interpolation_mode
  ~padding_mode
  ~align_corners
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__grid_sampler_2d_cpu_fallback_backward
    (CArray.start out__)
    grad_output
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _grid_sampler_2d_cpu_fallback_out
  ~out
  input
  ~grid
  ~interpolation_mode
  ~padding_mode
  ~align_corners
  =
  stubs__grid_sampler_2d_cpu_fallback_out
    out
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let _has_compatible_shallow_copy_type self ~from =
  stubs__has_compatible_shallow_copy_type self from
;;

let _has_same_storage_numel self other = stubs__has_same_storage_numel self other

let _histogramdd_bin_edges self ~bins ~range ~weight ~density =
  stubs__histogramdd_bin_edges
    self
    (List.map Int64.of_int bins |> CArray.of_list int64_t |> CArray.start)
    (List.length bins)
    (range |> CArray.of_list double |> CArray.start)
    (List.length range)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (if density then 1 else 0)
  |> to_tensor_list
;;

let _histogramdd_bin_edges_out ~out self ~bins ~range ~weight ~density =
  let result =
    stubs__histogramdd_bin_edges_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      self
      (List.map Int64.of_int bins |> CArray.of_list int64_t |> CArray.start)
      (List.length bins)
      (range |> CArray.of_list double |> CArray.start)
      (List.length range)
      (match weight with
       | Some v -> v
       | None -> none_gc_tensor)
      (if density then 1 else 0)
  in
  keep_values_alive out;
  result
;;

let _histogramdd_from_bin_cts self ~bins ~range ~weight ~density =
  stubs__histogramdd_from_bin_cts
    self
    (List.map Int64.of_int bins |> CArray.of_list int64_t |> CArray.start)
    (List.length bins)
    (range |> CArray.of_list double |> CArray.start)
    (List.length range)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (if density then 1 else 0)
  |> with_tensor_gc
;;

let _histogramdd_from_bin_cts_out ~out self ~bins ~range ~weight ~density =
  stubs__histogramdd_from_bin_cts_out
    out
    self
    (List.map Int64.of_int bins |> CArray.of_list int64_t |> CArray.start)
    (List.length bins)
    (range |> CArray.of_list double |> CArray.start)
    (List.length range)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (if density then 1 else 0)
  |> with_tensor_gc
;;

let _histogramdd_from_bin_tensors self ~bins ~weight ~density =
  let result =
    stubs__histogramdd_from_bin_tensors
      self
      (CArray.of_list gc_tensor bins |> CArray.start)
      (List.length bins)
      (match weight with
       | Some v -> v
       | None -> none_gc_tensor)
      (if density then 1 else 0)
    |> with_tensor_gc
  in
  keep_values_alive bins;
  result
;;

let _histogramdd_from_bin_tensors_out ~out self ~bins ~weight ~density =
  let result =
    stubs__histogramdd_from_bin_tensors_out
      out
      self
      (CArray.of_list gc_tensor bins |> CArray.start)
      (List.length bins)
      (match weight with
       | Some v -> v
       | None -> none_gc_tensor)
      (if density then 1 else 0)
    |> with_tensor_gc
  in
  keep_values_alive bins;
  result
;;

let _indices self = stubs__indices self |> with_tensor_gc
let _indices_copy self = stubs__indices_copy self |> with_tensor_gc
let _indices_copy_out ~out self = stubs__indices_copy_out out self |> with_tensor_gc
let _int_mm self ~mat2 = stubs__int_mm self mat2 |> with_tensor_gc
let _int_mm_out ~out self ~mat2 = stubs__int_mm_out out self mat2 |> with_tensor_gc
let _is_all_true self = stubs__is_all_true self |> with_tensor_gc
let _is_any_true self = stubs__is_any_true self |> with_tensor_gc
let _is_zerotensor self = stubs__is_zerotensor self
let _lazy_clone self = stubs__lazy_clone self |> with_tensor_gc

let _linalg_check_errors ~info ~api_name ~is_matrix =
  stubs__linalg_check_errors info api_name (if is_matrix then 1 else 0)
;;

let _linalg_det ~a =
  let out__ = CArray.make raw_tensor 3 in
  stubs__linalg_det (CArray.start out__) a;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _linalg_det_result result ~lu ~pivots ~a =
  let out__ = CArray.make raw_tensor 3 in
  stubs__linalg_det_result (CArray.start out__) result lu pivots a;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _linalg_eigh ~a ~uplo ~compute_v =
  let out__ = CArray.make raw_tensor 2 in
  stubs__linalg_eigh (CArray.start out__) a uplo (if compute_v then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _linalg_eigh_eigenvalues ~eigenvalues ~eigenvectors ~a ~uplo ~compute_v =
  let out__ = CArray.make raw_tensor 2 in
  stubs__linalg_eigh_eigenvalues
    (CArray.start out__)
    eigenvalues
    eigenvectors
    a
    uplo
    (if compute_v then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _linalg_eigvals self = stubs__linalg_eigvals self |> with_tensor_gc

let _linalg_slogdet ~a =
  let out__ = CArray.make raw_tensor 4 in
  stubs__linalg_slogdet (CArray.start out__) a;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _linalg_slogdet_sign ~sign ~logabsdet ~lu ~pivots ~a =
  let out__ = CArray.make raw_tensor 4 in
  stubs__linalg_slogdet_sign (CArray.start out__) sign logabsdet lu pivots a;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _linalg_solve_ex ~a ~b ~left ~check_errors =
  let out__ = CArray.make raw_tensor 4 in
  stubs__linalg_solve_ex
    (CArray.start out__)
    a
    b
    (if left then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _linalg_solve_ex_result result ~lu ~pivots ~info ~a ~b ~left ~check_errors =
  let out__ = CArray.make raw_tensor 4 in
  stubs__linalg_solve_ex_result
    (CArray.start out__)
    result
    lu
    pivots
    info
    a
    b
    (if left then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _linalg_svd ~a ~full_matrices ~compute_uv ~driver =
  let out__ = CArray.make raw_tensor 3 in
  stubs__linalg_svd
    (CArray.start out__)
    a
    (if full_matrices then 1 else 0)
    (if compute_uv then 1 else 0)
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _linalg_svd_u ~u ~s ~vh ~a ~full_matrices ~compute_uv ~driver =
  let out__ = CArray.make raw_tensor 3 in
  stubs__linalg_svd_u
    (CArray.start out__)
    u
    s
    vh
    a
    (if full_matrices then 1 else 0)
    (if compute_uv then 1 else 0)
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _log_softmax self ~dim ~half_to_float =
  stubs__log_softmax self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _log_softmax_backward_data ~grad_output ~output ~dim ~input_dtype =
  stubs__log_softmax_backward_data
    grad_output
    output
    (Int64.of_int dim)
    (Kind.packed_to_int input_dtype)
  |> with_tensor_gc
;;

let _log_softmax_backward_data_out ~out ~grad_output ~output ~dim ~input_dtype =
  stubs__log_softmax_backward_data_out
    out
    grad_output
    output
    (Int64.of_int dim)
    (Kind.packed_to_int input_dtype)
  |> with_tensor_gc
;;

let _log_softmax_out ~out self ~dim ~half_to_float =
  stubs__log_softmax_out out self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _logcumsumexp self ~dim =
  stubs__logcumsumexp self (Int64.of_int dim) |> with_tensor_gc
;;

let _logcumsumexp_out ~out self ~dim =
  stubs__logcumsumexp_out out self (Int64.of_int dim) |> with_tensor_gc
;;

let _lstm_mps
  input
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let out__ = CArray.make raw_tensor 6 in
  stubs__lstm_mps
    (CArray.start out__)
    input
    (CArray.of_list gc_tensor hx |> CArray.start)
    (List.length hx)
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  let t5 = CArray.get out__ 5 |> with_tensor_gc in
  keep_values_alive hx;
  keep_values_alive params;
  t0, t1, t2, t3, t4, t5
;;

let _lstm_mps_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~out4
  ~out5
  input
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let out__ = CArray.make raw_tensor 6 in
  stubs__lstm_mps_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    out4
    out5
    input
    (CArray.of_list gc_tensor hx |> CArray.start)
    (List.length hx)
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  let t5 = CArray.get out__ 5 |> with_tensor_gc in
  keep_values_alive hx;
  keep_values_alive params;
  t0, t1, t2, t3, t4, t5
;;

let _lu_with_info self ~pivot ~check_errors =
  let out__ = CArray.make raw_tensor 3 in
  stubs__lu_with_info
    (CArray.start out__)
    self
    (if pivot then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _make_dep_token ~options =
  stubs__make_dep_token (Kind.packed_to_int (fst options)) (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _make_dual ~primal ~tangent ~level =
  stubs__make_dual primal tangent (Int64.of_int level) |> with_tensor_gc
;;

let _make_dual_copy ~primal ~tangent ~level =
  stubs__make_dual_copy primal tangent (Int64.of_int level) |> with_tensor_gc
;;

let _make_dual_copy_out ~out ~primal ~tangent ~level =
  stubs__make_dual_copy_out out primal tangent (Int64.of_int level) |> with_tensor_gc
;;

let _make_per_channel_quantized_tensor self ~scale ~zero_point ~axis =
  stubs__make_per_channel_quantized_tensor self scale zero_point (Int64.of_int axis)
  |> with_tensor_gc
;;

let _make_per_channel_quantized_tensor_out ~out self ~scale ~zero_point ~axis =
  stubs__make_per_channel_quantized_tensor_out
    out
    self
    scale
    zero_point
    (Int64.of_int axis)
  |> with_tensor_gc
;;

let _make_per_tensor_quantized_tensor self ~scale ~zero_point =
  stubs__make_per_tensor_quantized_tensor self scale (Int64.of_int zero_point)
  |> with_tensor_gc
;;

let _make_per_tensor_quantized_tensor_out ~out self ~scale ~zero_point =
  stubs__make_per_tensor_quantized_tensor_out out self scale (Int64.of_int zero_point)
  |> with_tensor_gc
;;

let _masked_scale self ~mask ~scale =
  stubs__masked_scale self mask scale |> with_tensor_gc
;;

let _masked_scale_out ~out self ~mask ~scale =
  stubs__masked_scale_out out self mask scale |> with_tensor_gc
;;

let _masked_softmax self ~mask ~dim ~mask_type =
  stubs__masked_softmax
    self
    mask
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (match mask_type with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match mask_type with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _masked_softmax_backward ~grad_output ~output ~mask ~dim =
  stubs__masked_softmax_backward
    grad_output
    output
    mask
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _masked_softmax_backward_out ~out ~grad_output ~output ~mask ~dim =
  stubs__masked_softmax_backward_out
    out
    grad_output
    output
    mask
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _masked_softmax_out ~out self ~mask ~dim ~mask_type =
  stubs__masked_softmax_out
    out
    self
    mask
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (match mask_type with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match mask_type with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _mixed_dtypes_linear input ~weight ~scale ~bias ~activation =
  stubs__mixed_dtypes_linear
    input
    weight
    scale
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value activation ~default:"")
    (match activation with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _mkldnn_reshape self ~shape =
  stubs__mkldnn_reshape
    self
    (List.map Int64.of_int shape |> CArray.of_list int64_t |> CArray.start)
    (List.length shape)
  |> with_tensor_gc
;;

let _mkldnn_reshape_out ~out self ~shape =
  stubs__mkldnn_reshape_out
    out
    self
    (List.map Int64.of_int shape |> CArray.of_list int64_t |> CArray.start)
    (List.length shape)
  |> with_tensor_gc
;;

let _mkldnn_transpose self ~dim0 ~dim1 =
  stubs__mkldnn_transpose self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let _mkldnn_transpose_ self ~dim0 ~dim1 =
  stubs__mkldnn_transpose_ self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let _mkldnn_transpose_out ~out self ~dim0 ~dim1 =
  stubs__mkldnn_transpose_out out self (Int64.of_int dim0) (Int64.of_int dim1)
  |> with_tensor_gc
;;

let _mps_convolution self ~weight ~bias ~padding ~stride ~dilation ~groups =
  stubs__mps_convolution
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let _mps_convolution_out ~out self ~weight ~bias ~padding ~stride ~dilation ~groups =
  stubs__mps_convolution_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let _mps_convolution_transpose
  self
  ~weight
  ~padding
  ~output_padding
  ~stride
  ~dilation
  ~groups
  =
  stubs__mps_convolution_transpose
    self
    weight
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let _mps_convolution_transpose_out
  ~out
  self
  ~weight
  ~padding
  ~output_padding
  ~stride
  ~dilation
  ~groups
  =
  stubs__mps_convolution_transpose_out
    out
    self
    weight
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let _native_batch_norm_legit
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__native_batch_norm_legit
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _native_batch_norm_legit_functional
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs__native_batch_norm_legit_functional
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _native_batch_norm_legit_no_stats input ~weight ~bias ~training ~momentum ~eps =
  let out__ = CArray.make raw_tensor 3 in
  stubs__native_batch_norm_legit_no_stats
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _native_batch_norm_legit_no_stats_out
  ~out
  ~save_mean
  ~save_invstd
  input
  ~weight
  ~bias
  ~training
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__native_batch_norm_legit_no_stats_out
    (CArray.start out__)
    out
    save_mean
    save_invstd
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _native_batch_norm_legit_no_training
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__native_batch_norm_legit_no_training
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _native_batch_norm_legit_no_training_out
  ~out0
  ~out1
  ~out2
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__native_batch_norm_legit_no_training_out
    (CArray.start out__)
    out0
    out1
    out2
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _native_batch_norm_legit_out
  ~out
  ~save_mean
  ~save_invstd
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__native_batch_norm_legit_out
    (CArray.start out__)
    out
    save_mean
    save_invstd
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    running_mean
    running_var
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _native_multi_head_attention
  ~query
  ~key
  ~value
  ~embed_dim
  ~num_head
  ~qkv_weight
  ~qkv_bias
  ~proj_weight
  ~proj_bias
  ~mask
  ~need_weights
  ~average_attn_weights
  ~mask_type
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__native_multi_head_attention
    (CArray.start out__)
    query
    key
    value
    (Int64.of_int embed_dim)
    (Int64.of_int num_head)
    qkv_weight
    qkv_bias
    proj_weight
    proj_bias
    (match mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (if need_weights then 1 else 0)
    (if average_attn_weights then 1 else 0)
    (match mask_type with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match mask_type with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _native_multi_head_attention_out
  ~out0
  ~out1
  ~query
  ~key
  ~value
  ~embed_dim
  ~num_head
  ~qkv_weight
  ~qkv_bias
  ~proj_weight
  ~proj_bias
  ~mask
  ~need_weights
  ~average_attn_weights
  ~mask_type
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__native_multi_head_attention_out
    (CArray.start out__)
    out0
    out1
    query
    key
    value
    (Int64.of_int embed_dim)
    (Int64.of_int num_head)
    qkv_weight
    qkv_bias
    proj_weight
    proj_bias
    (match mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (if need_weights then 1 else 0)
    (if average_attn_weights then 1 else 0)
    (match mask_type with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match mask_type with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _neg_view self = stubs__neg_view self |> with_tensor_gc
let _neg_view_copy self = stubs__neg_view_copy self |> with_tensor_gc
let _neg_view_copy_out ~out self = stubs__neg_view_copy_out out self |> with_tensor_gc

let _nested_compute_contiguous_strides_offsets ~nested_size =
  let out__ = CArray.make raw_tensor 2 in
  stubs__nested_compute_contiguous_strides_offsets (CArray.start out__) nested_size;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _nested_from_padded ~padded ~cpu_nested_shape_example ~fuse_transform_0213 =
  stubs__nested_from_padded
    padded
    cpu_nested_shape_example
    (if fuse_transform_0213 then 1 else 0)
  |> with_tensor_gc
;;

let _nested_from_padded_and_nested_example ~padded ~nt_example =
  stubs__nested_from_padded_and_nested_example padded nt_example |> with_tensor_gc
;;

let _nested_from_padded_and_nested_example_out ~out ~padded ~nt_example =
  stubs__nested_from_padded_and_nested_example_out out padded nt_example |> with_tensor_gc
;;

let _nested_from_padded_out ~out ~padded ~cpu_nested_shape_example ~fuse_transform_0213 =
  stubs__nested_from_padded_out
    out
    padded
    cpu_nested_shape_example
    (if fuse_transform_0213 then 1 else 0)
  |> with_tensor_gc
;;

let _nested_from_padded_tensor
  ~padded
  ~offsets
  ~dummy
  ~ragged_idx
  ~min_seqlen
  ~max_seqlen
  ~sum_s
  =
  stubs__nested_from_padded_tensor
    padded
    offsets
    dummy
    (Int64.of_int ragged_idx)
    (match min_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
    (match sum_s with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match sum_s with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _nested_get_jagged_dummy ~any = stubs__nested_get_jagged_dummy any |> with_tensor_gc
let _nested_get_lengths self = stubs__nested_get_lengths self |> with_tensor_gc
let _nested_get_max_seqlen self = stubs__nested_get_max_seqlen self |> with_tensor_gc
let _nested_get_min_seqlen self = stubs__nested_get_min_seqlen self |> with_tensor_gc
let _nested_get_offsets self = stubs__nested_get_offsets self |> with_tensor_gc
let _nested_get_ragged_idx self = stubs__nested_get_ragged_idx self
let _nested_get_values self = stubs__nested_get_values self |> with_tensor_gc
let _nested_get_values_copy self = stubs__nested_get_values_copy self |> with_tensor_gc

let _nested_get_values_copy_out ~out self =
  stubs__nested_get_values_copy_out out self |> with_tensor_gc
;;

let _nested_select_backward ~grad_output self ~dim ~index =
  stubs__nested_select_backward grad_output self (Int64.of_int dim) (Int64.of_int index)
  |> with_tensor_gc
;;

let _nested_sum_backward ~grad self ~dim ~keepdim =
  stubs__nested_sum_backward
    grad
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let _nested_view_from_buffer self ~nested_size ~nested_strides ~offsets =
  stubs__nested_view_from_buffer self nested_size nested_strides offsets |> with_tensor_gc
;;

let _nested_view_from_buffer_copy self ~nested_size ~nested_strides ~offsets =
  stubs__nested_view_from_buffer_copy self nested_size nested_strides offsets
  |> with_tensor_gc
;;

let _nested_view_from_buffer_copy_out ~out self ~nested_size ~nested_strides ~offsets =
  stubs__nested_view_from_buffer_copy_out out self nested_size nested_strides offsets
  |> with_tensor_gc
;;

let _nested_view_from_jagged
  self
  ~offsets
  ~dummy
  ~lengths
  ~ragged_idx
  ~min_seqlen
  ~max_seqlen
  =
  stubs__nested_view_from_jagged
    self
    offsets
    dummy
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int ragged_idx)
    (match min_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let _nested_view_from_jagged_copy
  self
  ~offsets
  ~dummy
  ~lengths
  ~ragged_idx
  ~min_seqlen
  ~max_seqlen
  =
  stubs__nested_view_from_jagged_copy
    self
    offsets
    dummy
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int ragged_idx)
    (match min_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let _nested_view_from_jagged_copy_out
  ~out
  self
  ~offsets
  ~dummy
  ~lengths
  ~ragged_idx
  ~min_seqlen
  ~max_seqlen
  =
  stubs__nested_view_from_jagged_copy_out
    out
    self
    offsets
    dummy
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int ragged_idx)
    (match min_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max_seqlen with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let _new_zeros_with_same_feature_meta self other ~self_num_batch_dims =
  stubs__new_zeros_with_same_feature_meta self other (Int64.of_int self_num_batch_dims)
  |> with_tensor_gc
;;

let _new_zeros_with_same_feature_meta_out ~out self other ~self_num_batch_dims =
  stubs__new_zeros_with_same_feature_meta_out
    out
    self
    other
    (Int64.of_int self_num_batch_dims)
  |> with_tensor_gc
;;

let _nnpack_available = stubs__nnpack_available

let _nnpack_spatial_convolution input ~weight ~bias ~padding ~stride =
  stubs__nnpack_spatial_convolution
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let _nnpack_spatial_convolution_out ~out input ~weight ~bias ~padding ~stride =
  stubs__nnpack_spatial_convolution_out
    out
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let _nnz self = stubs__nnz self

let _pack_padded_sequence input ~lengths ~batch_first =
  let out__ = CArray.make raw_tensor 2 in
  stubs__pack_padded_sequence
    (CArray.start out__)
    input
    lengths
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _pack_padded_sequence_backward ~grad ~input_size ~batch_sizes ~batch_first =
  stubs__pack_padded_sequence_backward
    grad
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    batch_sizes
    (if batch_first then 1 else 0)
  |> with_tensor_gc
;;

let _pack_padded_sequence_out ~out0 ~out1 input ~lengths ~batch_first =
  let out__ = CArray.make raw_tensor 2 in
  stubs__pack_padded_sequence_out
    (CArray.start out__)
    out0
    out1
    input
    lengths
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _pad_circular self ~pad =
  stubs__pad_circular
    self
    (List.map Int64.of_int pad |> CArray.of_list int64_t |> CArray.start)
    (List.length pad)
  |> with_tensor_gc
;;

let _pad_enum self ~pad ~mode ~value =
  stubs__pad_enum
    self
    (List.map Int64.of_int pad |> CArray.of_list int64_t |> CArray.start)
    (List.length pad)
    (Int64.of_int mode)
    (Option.value value ~default:0.0)
    (match value with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _pad_packed_sequence ~data ~batch_sizes ~batch_first ~padding_value ~total_length =
  let out__ = CArray.make raw_tensor 2 in
  stubs__pad_packed_sequence
    (CArray.start out__)
    data
    batch_sizes
    (if batch_first then 1 else 0)
    padding_value
    (Int64.of_int total_length);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _pdist_backward ~grad self ~p ~pdist =
  stubs__pdist_backward grad self p pdist |> with_tensor_gc
;;

let _pdist_backward_out ~out ~grad self ~p ~pdist =
  stubs__pdist_backward_out out grad self p pdist |> with_tensor_gc
;;

let _pin_memory self ~device =
  stubs__pin_memory self (Device.option_to_int device) |> with_tensor_gc
;;

let _pin_memory_out ~out self ~device =
  stubs__pin_memory_out out self (Device.option_to_int device) |> with_tensor_gc
;;

let _prelu_kernel self ~weight = stubs__prelu_kernel self weight |> with_tensor_gc

let _prelu_kernel_backward ~grad_output self ~weight =
  let out__ = CArray.make raw_tensor 2 in
  stubs__prelu_kernel_backward (CArray.start out__) grad_output self weight;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _print ~s = stubs__print s
let _propagate_xla_data input ~output = stubs__propagate_xla_data input output

let _remove_batch_dim self ~level ~batch_size ~out_dim =
  stubs__remove_batch_dim
    self
    (Int64.of_int level)
    (Int64.of_int batch_size)
    (Int64.of_int out_dim)
  |> with_tensor_gc
;;

let _reshape_alias self ~size ~stride =
  stubs__reshape_alias
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let _reshape_alias_copy self ~size ~stride =
  stubs__reshape_alias_copy
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let _reshape_alias_copy_out ~out self ~size ~stride =
  stubs__reshape_alias_copy_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let _reshape_copy self ~size =
  stubs__reshape_copy
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _reshape_from_tensor self ~shape =
  stubs__reshape_from_tensor self shape |> with_tensor_gc
;;

let _resize_output self ~size ~device =
  stubs__resize_output
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Device.to_int device)
  |> with_tensor_gc
;;

let _resize_output_ self ~size ~device =
  stubs__resize_output_
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Device.to_int device)
  |> with_tensor_gc
;;

let _resize_output_out ~out self ~size ~device =
  stubs__resize_output_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Device.to_int device)
  |> with_tensor_gc
;;

let _rowwise_prune ~weight ~mask ~compressed_indices_dtype =
  let out__ = CArray.make raw_tensor 2 in
  stubs__rowwise_prune
    (CArray.start out__)
    weight
    mask
    (Kind.packed_to_int compressed_indices_dtype);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _safe_softmax self ~dim ~dtype =
  stubs__safe_softmax self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let _sample_dirichlet self = stubs__sample_dirichlet self |> with_tensor_gc

let _sample_dirichlet_out ~out self =
  stubs__sample_dirichlet_out out self |> with_tensor_gc
;;

let _saturate_weight_to_fp16 ~weight =
  stubs__saturate_weight_to_fp16 weight |> with_tensor_gc
;;

let _scaled_dot_product_attention_math
  ~query
  ~key
  ~value
  ~attn_mask
  ~dropout_p
  ~is_causal
  ~dropout_mask
  ~scale
  ~enable_gqa
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__scaled_dot_product_attention_math
    (CArray.start out__)
    query
    key
    value
    (match attn_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    dropout_p
    (if is_causal then 1 else 0)
    (match dropout_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1)
    (if enable_gqa then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _scaled_dot_product_attention_math_for_mps
  ~query
  ~key
  ~value
  ~attn_mask
  ~dropout_p
  ~is_causal
  ~dropout_mask
  ~scale
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__scaled_dot_product_attention_math_for_mps
    (CArray.start out__)
    query
    key
    value
    (match attn_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    dropout_p
    (if is_causal then 1 else 0)
    (match dropout_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _scaled_dot_product_cudnn_attention_backward
  ~grad_out
  ~query
  ~key
  ~value
  ~out
  ~logsumexp
  ~philox_seed
  ~philox_offset
  ~attn_bias
  ~cum_seq_q
  ~cum_seq_k
  ~max_q
  ~max_k
  ~dropout_p
  ~is_causal
  ~scale
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__scaled_dot_product_cudnn_attention_backward
    (CArray.start out__)
    grad_out
    query
    key
    value
    out
    logsumexp
    philox_seed
    philox_offset
    attn_bias
    cum_seq_q
    cum_seq_k
    (Int64.of_int max_q)
    (Int64.of_int max_k)
    dropout_p
    (if is_causal then 1 else 0)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _scaled_dot_product_efficient_attention
  ~query
  ~key
  ~value
  ~attn_bias
  ~compute_log_sumexp
  ~dropout_p
  ~is_causal
  ~scale
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs__scaled_dot_product_efficient_attention
    (CArray.start out__)
    query
    key
    value
    (match attn_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (if compute_log_sumexp then 1 else 0)
    dropout_p
    (if is_causal then 1 else 0)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let _scaled_dot_product_flash_attention_backward
  ~grad_out
  ~query
  ~key
  ~value
  ~out
  ~logsumexp
  ~cum_seq_q
  ~cum_seq_k
  ~max_q
  ~max_k
  ~dropout_p
  ~is_causal
  ~philox_seed
  ~philox_offset
  ~scale
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__scaled_dot_product_flash_attention_backward
    (CArray.start out__)
    grad_out
    query
    key
    value
    out
    logsumexp
    cum_seq_q
    cum_seq_k
    (Int64.of_int max_q)
    (Int64.of_int max_k)
    dropout_p
    (if is_causal then 1 else 0)
    philox_seed
    philox_offset
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _scaled_dot_product_flash_attention_for_cpu
  ~query
  ~key
  ~value
  ~dropout_p
  ~is_causal
  ~attn_mask
  ~scale
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__scaled_dot_product_flash_attention_for_cpu
    (CArray.start out__)
    query
    key
    value
    dropout_p
    (if is_causal then 1 else 0)
    (match attn_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _scaled_dot_product_flash_attention_for_cpu_backward
  ~grad_out
  ~query
  ~key
  ~value
  ~out
  ~logsumexp
  ~dropout_p
  ~is_causal
  ~attn_mask
  ~scale
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__scaled_dot_product_flash_attention_for_cpu_backward
    (CArray.start out__)
    grad_out
    query
    key
    value
    out
    logsumexp
    dropout_p
    (if is_causal then 1 else 0)
    (match attn_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _scaled_grouped_mm
  self
  ~mat2
  ~scale_a
  ~scale_b
  ~offs
  ~bias
  ~scale_result
  ~out_dtype
  ~use_fast_accum
  =
  stubs__scaled_grouped_mm
    self
    mat2
    scale_a
    scale_b
    (match offs with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match scale_result with
     | Some v -> v
     | None -> none_gc_tensor)
    (Kind.packed_to_int out_dtype)
    (if use_fast_accum then 1 else 0)
  |> with_tensor_gc
;;

let _scaled_mm self ~mat2 ~scale_a ~scale_b ~bias ~scale_result ~out_dtype ~use_fast_accum
  =
  stubs__scaled_mm
    self
    mat2
    scale_a
    scale_b
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match scale_result with
     | Some v -> v
     | None -> none_gc_tensor)
    (Kind.packed_to_int out_dtype)
    (if use_fast_accum then 1 else 0)
  |> with_tensor_gc
;;

let _scaled_mm_out
  ~out
  self
  ~mat2
  ~scale_a
  ~scale_b
  ~bias
  ~scale_result
  ~out_dtype
  ~use_fast_accum
  =
  stubs__scaled_mm_out
    out
    self
    mat2
    scale_a
    scale_b
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match scale_result with
     | Some v -> v
     | None -> none_gc_tensor)
    (Kind.packed_to_int out_dtype)
    (if use_fast_accum then 1 else 0)
  |> with_tensor_gc
;;

let _scatter_reduce self ~dim ~index ~src ~reduce ~include_self =
  stubs__scatter_reduce
    self
    (Int64.of_int dim)
    index
    src
    reduce
    (if include_self then 1 else 0)
  |> with_tensor_gc
;;

let _scatter_reduce_ self ~dim ~index ~src ~reduce ~include_self =
  stubs__scatter_reduce_
    self
    (Int64.of_int dim)
    index
    src
    reduce
    (if include_self then 1 else 0)
  |> with_tensor_gc
;;

let _scatter_reduce_two_out ~out self ~dim ~index ~src ~reduce ~include_self =
  stubs__scatter_reduce_two_out
    out
    self
    (Int64.of_int dim)
    index
    src
    reduce
    (if include_self then 1 else 0)
  |> with_tensor_gc
;;

let _segment_reduce_backward ~grad ~output ~data ~reduce ~lengths ~offsets ~axis ~initial =
  stubs__segment_reduce_backward
    grad
    output
    data
    reduce
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (match offsets with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int axis)
    initial
  |> with_tensor_gc
;;

let _segment_reduce_backward_out
  ~out
  ~grad
  ~output
  ~data
  ~reduce
  ~lengths
  ~offsets
  ~axis
  ~initial
  =
  stubs__segment_reduce_backward_out
    out
    grad
    output
    data
    reduce
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (match offsets with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int axis)
    initial
  |> with_tensor_gc
;;

let _shape_as_tensor self = stubs__shape_as_tensor self |> with_tensor_gc

let _slow_conv2d_backward
  ~grad_input
  ~grad_weight
  ~grad_bias
  ~grad_output
  self
  ~weight
  ~kernel_size
  ~stride
  ~padding
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__slow_conv2d_backward
    (CArray.start out__)
    grad_input
    grad_weight
    grad_bias
    grad_output
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _sobol_engine_draw ~quasi ~n ~sobolstate ~dimension ~num_generated ~dtype =
  let out__ = CArray.make raw_tensor 2 in
  stubs__sobol_engine_draw
    (CArray.start out__)
    quasi
    (Int64.of_int n)
    sobolstate
    (Int64.of_int dimension)
    (Int64.of_int num_generated)
    (Kind.packed_to_int dtype);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _sobol_engine_ff_ self ~n ~sobolstate ~dimension ~num_generated =
  stubs__sobol_engine_ff_
    self
    (Int64.of_int n)
    sobolstate
    (Int64.of_int dimension)
    (Int64.of_int num_generated)
  |> with_tensor_gc
;;

let _sobol_engine_initialize_state_ self ~dimension =
  stubs__sobol_engine_initialize_state_ self (Int64.of_int dimension) |> with_tensor_gc
;;

let _sobol_engine_scramble_ self ~ltm ~dimension =
  stubs__sobol_engine_scramble_ self ltm (Int64.of_int dimension) |> with_tensor_gc
;;

let _softmax self ~dim ~half_to_float =
  stubs__softmax self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _softmax_backward_data ~grad_output ~output ~dim ~input_dtype =
  stubs__softmax_backward_data
    grad_output
    output
    (Int64.of_int dim)
    (Kind.packed_to_int input_dtype)
  |> with_tensor_gc
;;

let _softmax_backward_data_out ~grad_input ~grad_output ~output ~dim ~input_dtype =
  stubs__softmax_backward_data_out
    grad_input
    grad_output
    output
    (Int64.of_int dim)
    (Kind.packed_to_int input_dtype)
  |> with_tensor_gc
;;

let _softmax_out ~out self ~dim ~half_to_float =
  stubs__softmax_out out self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_addmm ?beta ?alpha self ~mat1 ~mat2 =
  stubs__sparse_addmm
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _sparse_addmm_out ?beta ?alpha ~out self ~mat1 ~mat2 =
  stubs__sparse_addmm_out
    out
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _sparse_broadcast_to self ~size =
  stubs__sparse_broadcast_to
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _sparse_broadcast_to_copy self ~size =
  stubs__sparse_broadcast_to_copy
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _sparse_broadcast_to_copy_out ~out self ~size =
  stubs__sparse_broadcast_to_copy_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _sparse_bsc_tensor_unsafe ~ccol_indices ~row_indices ~values ~size ~options =
  stubs__sparse_bsc_tensor_unsafe
    ccol_indices
    row_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_bsr_tensor_unsafe ~crow_indices ~col_indices ~values ~size ~options =
  stubs__sparse_bsr_tensor_unsafe
    crow_indices
    col_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_compressed_tensor_unsafe
  ~compressed_indices
  ~plain_indices
  ~values
  ~size
  ~options
  =
  stubs__sparse_compressed_tensor_unsafe
    compressed_indices
    plain_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_compressed_tensor_with_dims
  ~nnz
  ~dense_dim
  ~size
  ~blocksize
  ~index_dtype
  ~options
  =
  stubs__sparse_compressed_tensor_with_dims
    (Int64.of_int nnz)
    (Int64.of_int dense_dim)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int blocksize |> CArray.of_list int64_t |> CArray.start)
    (List.length blocksize)
    (Kind.packed_to_int index_dtype)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_coo_tensor_unsafe ~indices ~values ~size ~options ~is_coalesced =
  stubs__sparse_coo_tensor_unsafe
    indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    (if is_coalesced then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_coo_tensor_with_dims ~sparse_dim ~dense_dim ~size ~options =
  stubs__sparse_coo_tensor_with_dims
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_coo_tensor_with_dims_and_tensors
  ~sparse_dim
  ~dense_dim
  ~size
  ~indices
  ~values
  ~options
  ~is_coalesced
  =
  stubs__sparse_coo_tensor_with_dims_and_tensors
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    (if is_coalesced then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_coo_tensor_with_dims_and_tensors_out
  ~out
  ~sparse_dim
  ~dense_dim
  ~size
  ~indices
  ~values
  ~is_coalesced
  =
  stubs__sparse_coo_tensor_with_dims_and_tensors_out
    out
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    indices
    values
    (if is_coalesced then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_coo_tensor_with_dims_out ~out ~sparse_dim ~dense_dim ~size =
  stubs__sparse_coo_tensor_with_dims_out
    out
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _sparse_csc_tensor_unsafe ~ccol_indices ~row_indices ~values ~size ~options =
  stubs__sparse_csc_tensor_unsafe
    ccol_indices
    row_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_csr_prod self ~dim ~keepdim ~dtype =
  stubs__sparse_csr_prod
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_csr_prod_dim_dtype_out ~out self ~dim ~keepdim ~dtype =
  stubs__sparse_csr_prod_dim_dtype_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_csr_sum self ~dim ~keepdim ~dtype =
  stubs__sparse_csr_sum
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_csr_sum_dim_dtype_out ~out self ~dim ~keepdim ~dtype =
  stubs__sparse_csr_sum_dim_dtype_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_csr_tensor_unsafe ~crow_indices ~col_indices ~values ~size ~options =
  stubs__sparse_csr_tensor_unsafe
    crow_indices
    col_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let _sparse_log_softmax self ~dim ~half_to_float =
  stubs__sparse_log_softmax self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_log_softmax_backward_data ~grad_output ~output ~dim self =
  stubs__sparse_log_softmax_backward_data grad_output output (Int64.of_int dim) self
  |> with_tensor_gc
;;

let _sparse_log_softmax_backward_data_out ~out ~grad_output ~output ~dim self =
  stubs__sparse_log_softmax_backward_data_out
    out
    grad_output
    output
    (Int64.of_int dim)
    self
  |> with_tensor_gc
;;

let _sparse_log_softmax_int self ~dim ~dtype =
  stubs__sparse_log_softmax_int self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_log_softmax_out ~out self ~dim ~half_to_float =
  stubs__sparse_log_softmax_out
    out
    self
    (Int64.of_int dim)
    (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_mask_projection self ~mask ~accumulate_matches =
  stubs__sparse_mask_projection self mask (if accumulate_matches then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_mask_projection_out ~out self ~mask ~accumulate_matches =
  stubs__sparse_mask_projection_out out self mask (if accumulate_matches then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_mm ~sparse ~dense = stubs__sparse_mm sparse dense |> with_tensor_gc

let _sparse_mm_reduce ~sparse ~dense ~reduce =
  stubs__sparse_mm_reduce sparse dense reduce |> with_tensor_gc
;;

let _sparse_mm_reduce_impl self other ~reduce =
  let out__ = CArray.make raw_tensor 2 in
  stubs__sparse_mm_reduce_impl (CArray.start out__) self other reduce;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _sparse_semi_structured_apply input ~thread_masks =
  let out__ = CArray.make raw_tensor 2 in
  stubs__sparse_semi_structured_apply (CArray.start out__) input thread_masks;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _sparse_semi_structured_apply_dense input ~thread_masks =
  stubs__sparse_semi_structured_apply_dense input thread_masks |> with_tensor_gc
;;

let _sparse_semi_structured_linear input ~weight ~meta ~bias ~activation ~out_dtype =
  stubs__sparse_semi_structured_linear
    input
    weight
    meta
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value activation ~default:"")
    (match activation with
     | Some _ -> 0
     | None -> 1)
    (Kind.packed_to_int out_dtype)
  |> with_tensor_gc
;;

let _sparse_semi_structured_mm ~mat1 ~mat1_meta ~mat2 ~out_dtype =
  stubs__sparse_semi_structured_mm mat1 mat1_meta mat2 (Kind.packed_to_int out_dtype)
  |> with_tensor_gc
;;

let _sparse_semi_structured_tile input ~algorithm ~use_cutlass =
  let out__ = CArray.make raw_tensor 5 in
  stubs__sparse_semi_structured_tile
    (CArray.start out__)
    input
    algorithm
    (if use_cutlass then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _sparse_softmax self ~dim ~half_to_float =
  stubs__sparse_softmax self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_softmax_backward_data ~grad_output ~output ~dim self =
  stubs__sparse_softmax_backward_data grad_output output (Int64.of_int dim) self
  |> with_tensor_gc
;;

let _sparse_softmax_backward_data_out ~out ~grad_output ~output ~dim self =
  stubs__sparse_softmax_backward_data_out out grad_output output (Int64.of_int dim) self
  |> with_tensor_gc
;;

let _sparse_softmax_int self ~dim ~dtype =
  stubs__sparse_softmax_int self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_softmax_out ~out self ~dim ~half_to_float =
  stubs__sparse_softmax_out out self (Int64.of_int dim) (if half_to_float then 1 else 0)
  |> with_tensor_gc
;;

let _sparse_sparse_matmul self other =
  stubs__sparse_sparse_matmul self other |> with_tensor_gc
;;

let _sparse_sparse_matmul_out ~out self other =
  stubs__sparse_sparse_matmul_out out self other |> with_tensor_gc
;;

let _sparse_sum self = stubs__sparse_sum self |> with_tensor_gc

let _sparse_sum_backward ~grad self ~dim =
  stubs__sparse_sum_backward
    grad
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let _sparse_sum_backward_out ~out ~grad self ~dim =
  stubs__sparse_sum_backward_out
    out
    grad
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let _sparse_sum_dim self ~dim =
  stubs__sparse_sum_dim
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let _sparse_sum_dim_dtype self ~dim ~dtype =
  stubs__sparse_sum_dim_dtype
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let _sparse_sum_dim_out ~out self ~dim =
  stubs__sparse_sum_dim_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let _sparse_sum_dtype self ~dtype =
  stubs__sparse_sum_dtype self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let _spdiags ~diagonals ~offsets ~shape =
  stubs__spdiags
    diagonals
    offsets
    (List.map Int64.of_int shape |> CArray.of_list int64_t |> CArray.start)
    (List.length shape)
  |> with_tensor_gc
;;

let _spdiags_out ~out ~diagonals ~offsets ~shape =
  stubs__spdiags_out
    out
    diagonals
    offsets
    (List.map Int64.of_int shape |> CArray.of_list int64_t |> CArray.start)
    (List.length shape)
  |> with_tensor_gc
;;

let _spsolve ~a ~b ~left = stubs__spsolve a b (if left then 1 else 0) |> with_tensor_gc

let _stack tensors ~dim =
  let result =
    stubs__stack
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let _stack_out ~out tensors ~dim =
  let result =
    stubs__stack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let _standard_gamma self = stubs__standard_gamma self |> with_tensor_gc

let _standard_gamma_grad self ~output =
  stubs__standard_gamma_grad self output |> with_tensor_gc
;;

let _standard_gamma_grad_out ~out self ~output =
  stubs__standard_gamma_grad_out out self output |> with_tensor_gc
;;

let _standard_gamma_out ~out self = stubs__standard_gamma_out out self |> with_tensor_gc

let _test_ambiguous_defaults ~dummy ~a ~b =
  stubs__test_ambiguous_defaults dummy (Int64.of_int a) (Int64.of_int b) |> with_tensor_gc
;;

let _test_ambiguous_defaults_b ~dummy ~a ~b =
  stubs__test_ambiguous_defaults_b dummy (Int64.of_int a) b |> with_tensor_gc
;;

let _test_autograd_multiple_dispatch self =
  stubs__test_autograd_multiple_dispatch self |> with_tensor_gc
;;

let _test_autograd_multiple_dispatch_fullcoverage_out ~out self =
  stubs__test_autograd_multiple_dispatch_fullcoverage_out out self |> with_tensor_gc
;;

let _test_autograd_multiple_dispatch_ntonly self ~b =
  stubs__test_autograd_multiple_dispatch_ntonly self (if b then 1 else 0)
  |> with_tensor_gc
;;

let _test_autograd_multiple_dispatch_view self =
  stubs__test_autograd_multiple_dispatch_view self |> with_tensor_gc
;;

let _test_autograd_multiple_dispatch_view_copy self =
  stubs__test_autograd_multiple_dispatch_view_copy self |> with_tensor_gc
;;

let _test_autograd_multiple_dispatch_view_copy_out ~out self =
  stubs__test_autograd_multiple_dispatch_view_copy_out out self |> with_tensor_gc
;;

let _test_check_tensor self = stubs__test_check_tensor self |> with_tensor_gc

let _test_functorch_fallback self other =
  stubs__test_functorch_fallback self other |> with_tensor_gc
;;

let _test_functorch_fallback_out ~out self other =
  stubs__test_functorch_fallback_out out self other |> with_tensor_gc
;;

let _test_optional_filled_intlist ~values ~addends =
  stubs__test_optional_filled_intlist
    values
    (match addends with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match addends with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let _test_optional_filled_intlist_out ~out ~values ~addends =
  stubs__test_optional_filled_intlist_out
    out
    values
    (match addends with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match addends with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let _test_optional_floatlist ~values ~addends =
  stubs__test_optional_floatlist
    values
    (addends |> CArray.of_list double |> CArray.start)
    (List.length addends)
  |> with_tensor_gc
;;

let _test_optional_floatlist_out ~out ~values ~addends =
  stubs__test_optional_floatlist_out
    out
    values
    (addends |> CArray.of_list double |> CArray.start)
    (List.length addends)
  |> with_tensor_gc
;;

let _test_optional_intlist ~values ~addends =
  stubs__test_optional_intlist
    values
    (match addends with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match addends with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let _test_optional_intlist_out ~out ~values ~addends =
  stubs__test_optional_intlist_out
    out
    values
    (match addends with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match addends with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let _test_parallel_materialize self ~num_parallel ~skip_first =
  stubs__test_parallel_materialize
    self
    (Int64.of_int num_parallel)
    (if skip_first then 1 else 0)
  |> with_tensor_gc
;;

let _test_serialization_subcmul ?alpha self other =
  stubs__test_serialization_subcmul
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let _test_string_default ~dummy ~a ~b =
  stubs__test_string_default dummy a b |> with_tensor_gc
;;

let _test_warn_in_autograd self = stubs__test_warn_in_autograd self |> with_tensor_gc

let _test_warn_in_autograd_out ~out self =
  stubs__test_warn_in_autograd_out out self |> with_tensor_gc
;;

let _thnn_differentiable_gru_cell_backward
  ~grad_hy
  ~input_gates
  ~hidden_gates
  ~hx
  ~input_bias
  ~hidden_bias
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs__thnn_differentiable_gru_cell_backward
    (CArray.start out__)
    grad_hy
    input_gates
    hidden_gates
    hx
    (match input_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match hidden_bias with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _thnn_differentiable_lstm_cell_backward
  ~grad_hy
  ~grad_cy
  ~input_gates
  ~hidden_gates
  ~input_bias
  ~hidden_bias
  ~cx
  ~cy
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs__thnn_differentiable_lstm_cell_backward
    (CArray.start out__)
    (match grad_hy with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_cy with
     | Some v -> v
     | None -> none_gc_tensor)
    input_gates
    hidden_gates
    (match input_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match hidden_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    cx
    cy;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _thnn_fused_gru_cell ~input_gates ~hidden_gates ~hx ~input_bias ~hidden_bias =
  let out__ = CArray.make raw_tensor 2 in
  stubs__thnn_fused_gru_cell
    (CArray.start out__)
    input_gates
    hidden_gates
    hx
    (match input_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match hidden_bias with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _thnn_fused_gru_cell_backward ~grad_hy ~workspace ~has_bias =
  let out__ = CArray.make raw_tensor 5 in
  stubs__thnn_fused_gru_cell_backward
    (CArray.start out__)
    grad_hy
    workspace
    (if has_bias then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _thnn_fused_gru_cell_backward_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~out4
  ~grad_hy
  ~workspace
  ~has_bias
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs__thnn_fused_gru_cell_backward_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    out4
    grad_hy
    workspace
    (if has_bias then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _thnn_fused_gru_cell_out
  ~out0
  ~out1
  ~input_gates
  ~hidden_gates
  ~hx
  ~input_bias
  ~hidden_bias
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__thnn_fused_gru_cell_out
    (CArray.start out__)
    out0
    out1
    input_gates
    hidden_gates
    hx
    (match input_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match hidden_bias with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _thnn_fused_lstm_cell ~input_gates ~hidden_gates ~cx ~input_bias ~hidden_bias =
  let out__ = CArray.make raw_tensor 3 in
  stubs__thnn_fused_lstm_cell
    (CArray.start out__)
    input_gates
    hidden_gates
    cx
    (match input_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match hidden_bias with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _thnn_fused_lstm_cell_backward ~grad_hy ~grad_cy ~cx ~cy ~workspace ~has_bias =
  let out__ = CArray.make raw_tensor 5 in
  stubs__thnn_fused_lstm_cell_backward
    (CArray.start out__)
    (match grad_hy with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_cy with
     | Some v -> v
     | None -> none_gc_tensor)
    cx
    cy
    workspace
    (if has_bias then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  t0, t1, t2, t3, t4
;;

let _thnn_fused_lstm_cell_backward_impl ~grad_hy ~grad_cy ~cx ~cy ~workspace ~has_bias =
  let out__ = CArray.make raw_tensor 3 in
  stubs__thnn_fused_lstm_cell_backward_impl
    (CArray.start out__)
    (match grad_hy with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_cy with
     | Some v -> v
     | None -> none_gc_tensor)
    cx
    cy
    workspace
    (if has_bias then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _thnn_fused_lstm_cell_backward_impl_out
  ~out0
  ~out1
  ~out2
  ~grad_hy
  ~grad_cy
  ~cx
  ~cy
  ~workspace
  ~has_bias
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__thnn_fused_lstm_cell_backward_impl_out
    (CArray.start out__)
    out0
    out1
    out2
    (match grad_hy with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_cy with
     | Some v -> v
     | None -> none_gc_tensor)
    cx
    cy
    workspace
    (if has_bias then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _thnn_fused_lstm_cell_out
  ~out0
  ~out1
  ~out2
  ~input_gates
  ~hidden_gates
  ~cx
  ~input_bias
  ~hidden_bias
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs__thnn_fused_lstm_cell_out
    (CArray.start out__)
    out0
    out1
    out2
    input_gates
    hidden_gates
    cx
    (match input_bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match hidden_bias with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _to_copy self ~options ~non_blocking =
  stubs__to_copy
    self
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    (if non_blocking then 1 else 0)
  |> with_tensor_gc
;;

let _to_copy_out ~out self ~non_blocking =
  stubs__to_copy_out out self (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let _to_cpu tensors =
  let result =
    stubs__to_cpu (CArray.of_list gc_tensor tensors |> CArray.start) (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let _to_dense self ~dtype ~masked_grad =
  stubs__to_dense self (Kind.packed_to_int dtype) (if masked_grad then 1 else 0)
  |> with_tensor_gc
;;

let _to_dense_out ~out self ~dtype ~masked_grad =
  stubs__to_dense_out out self (Kind.packed_to_int dtype) (if masked_grad then 1 else 0)
  |> with_tensor_gc
;;

let _to_sparse_bsc self ~blocksize ~dense_dim =
  stubs__to_sparse_bsc
    self
    (List.map Int64.of_int blocksize |> CArray.of_list int64_t |> CArray.start)
    (List.length blocksize)
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_bsc_out ~out self ~blocksize ~dense_dim =
  stubs__to_sparse_bsc_out
    out
    self
    (List.map Int64.of_int blocksize |> CArray.of_list int64_t |> CArray.start)
    (List.length blocksize)
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_bsr self ~blocksize ~dense_dim =
  stubs__to_sparse_bsr
    self
    (List.map Int64.of_int blocksize |> CArray.of_list int64_t |> CArray.start)
    (List.length blocksize)
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_bsr_out ~out self ~blocksize ~dense_dim =
  stubs__to_sparse_bsr_out
    out
    self
    (List.map Int64.of_int blocksize |> CArray.of_list int64_t |> CArray.start)
    (List.length blocksize)
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_csc self ~dense_dim =
  stubs__to_sparse_csc
    self
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_csc_out ~out self ~dense_dim =
  stubs__to_sparse_csc_out
    out
    self
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_csr self ~dense_dim =
  stubs__to_sparse_csr
    self
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_csr_out ~out self ~dense_dim =
  stubs__to_sparse_csr_out
    out
    self
    (match dense_dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dense_dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _to_sparse_semi_structured ~dense =
  let out__ = CArray.make raw_tensor 2 in
  stubs__to_sparse_semi_structured (CArray.start out__) dense;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _transform_bias_rescale_qkv ~qkv ~qkv_bias ~num_heads =
  let out__ = CArray.make raw_tensor 3 in
  stubs__transform_bias_rescale_qkv
    (CArray.start out__)
    qkv
    qkv_bias
    (Int64.of_int num_heads);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _transform_bias_rescale_qkv_out ~out0 ~out1 ~out2 ~qkv ~qkv_bias ~num_heads =
  let out__ = CArray.make raw_tensor 3 in
  stubs__transform_bias_rescale_qkv_out
    (CArray.start out__)
    out0
    out1
    out2
    qkv
    qkv_bias
    (Int64.of_int num_heads);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _transformer_encoder_layer_fwd
  ~src
  ~embed_dim
  ~num_heads
  ~qkv_weight
  ~qkv_bias
  ~proj_weight
  ~proj_bias
  ~use_gelu
  ~norm_first
  ~eps
  ~norm_weight_1
  ~norm_bias_1
  ~norm_weight_2
  ~norm_bias_2
  ~ffn_weight_1
  ~ffn_bias_1
  ~ffn_weight_2
  ~ffn_bias_2
  ~mask
  ~mask_type
  =
  stubs__transformer_encoder_layer_fwd
    src
    (Int64.of_int embed_dim)
    (Int64.of_int num_heads)
    qkv_weight
    qkv_bias
    proj_weight
    proj_bias
    (if use_gelu then 1 else 0)
    (if norm_first then 1 else 0)
    eps
    norm_weight_1
    norm_bias_1
    norm_weight_2
    norm_bias_2
    ffn_weight_1
    ffn_bias_1
    ffn_weight_2
    ffn_bias_2
    (match mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (match mask_type with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match mask_type with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _transformer_encoder_layer_fwd_out
  ~out
  ~src
  ~embed_dim
  ~num_heads
  ~qkv_weight
  ~qkv_bias
  ~proj_weight
  ~proj_bias
  ~use_gelu
  ~norm_first
  ~eps
  ~norm_weight_1
  ~norm_bias_1
  ~norm_weight_2
  ~norm_bias_2
  ~ffn_weight_1
  ~ffn_bias_1
  ~ffn_weight_2
  ~ffn_bias_2
  ~mask
  ~mask_type
  =
  stubs__transformer_encoder_layer_fwd_out
    out
    src
    (Int64.of_int embed_dim)
    (Int64.of_int num_heads)
    qkv_weight
    qkv_bias
    proj_weight
    proj_bias
    (if use_gelu then 1 else 0)
    (if norm_first then 1 else 0)
    eps
    norm_weight_1
    norm_bias_1
    norm_weight_2
    norm_bias_2
    ffn_weight_1
    ffn_bias_1
    ffn_weight_2
    ffn_bias_2
    (match mask with
     | Some v -> v
     | None -> none_gc_tensor)
    (match mask_type with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match mask_type with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _trilinear ~i1 ~i2 ~i3 ~expand1 ~expand2 ~expand3 ~sumdim ~unroll_dim =
  stubs__trilinear
    i1
    i2
    i3
    (List.map Int64.of_int expand1 |> CArray.of_list int64_t |> CArray.start)
    (List.length expand1)
    (List.map Int64.of_int expand2 |> CArray.of_list int64_t |> CArray.start)
    (List.length expand2)
    (List.map Int64.of_int expand3 |> CArray.of_list int64_t |> CArray.start)
    (List.length expand3)
    (List.map Int64.of_int sumdim |> CArray.of_list int64_t |> CArray.start)
    (List.length sumdim)
    (Int64.of_int unroll_dim)
  |> with_tensor_gc
;;

let _trilinear_out ~out ~i1 ~i2 ~i3 ~expand1 ~expand2 ~expand3 ~sumdim ~unroll_dim =
  stubs__trilinear_out
    out
    i1
    i2
    i3
    (List.map Int64.of_int expand1 |> CArray.of_list int64_t |> CArray.start)
    (List.length expand1)
    (List.map Int64.of_int expand2 |> CArray.of_list int64_t |> CArray.start)
    (List.length expand2)
    (List.map Int64.of_int expand3 |> CArray.of_list int64_t |> CArray.start)
    (List.length expand3)
    (List.map Int64.of_int sumdim |> CArray.of_list int64_t |> CArray.start)
    (List.length sumdim)
    (Int64.of_int unroll_dim)
  |> with_tensor_gc
;;

let _triton_multi_head_attention
  ~query
  ~key
  ~value
  ~embed_dim
  ~num_head
  ~qkv_weight
  ~qkv_bias
  ~proj_weight
  ~proj_bias
  ~mask
  =
  stubs__triton_multi_head_attention
    query
    key
    value
    (Int64.of_int embed_dim)
    (Int64.of_int num_head)
    qkv_weight
    qkv_bias
    proj_weight
    proj_bias
    (match mask with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let _triton_multi_head_attention_out
  ~out
  ~query
  ~key
  ~value
  ~embed_dim
  ~num_head
  ~qkv_weight
  ~qkv_bias
  ~proj_weight
  ~proj_bias
  ~mask
  =
  stubs__triton_multi_head_attention_out
    out
    query
    key
    value
    (Int64.of_int embed_dim)
    (Int64.of_int num_head)
    qkv_weight
    qkv_bias
    proj_weight
    proj_bias
    (match mask with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let _triton_scaled_dot_attention ~q ~k ~v ~dropout_p =
  stubs__triton_scaled_dot_attention q k v dropout_p |> with_tensor_gc
;;

let _triton_scaled_dot_attention_out ~out ~q ~k ~v ~dropout_p =
  stubs__triton_scaled_dot_attention_out out q k v dropout_p |> with_tensor_gc
;;

let _unique self ~sorted ~return_inverse =
  let out__ = CArray.make raw_tensor 2 in
  stubs__unique
    (CArray.start out__)
    self
    (if sorted then 1 else 0)
    (if return_inverse then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _unique2 self ~sorted ~return_inverse ~return_counts =
  let out__ = CArray.make raw_tensor 3 in
  stubs__unique2
    (CArray.start out__)
    self
    (if sorted then 1 else 0)
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _unique2_out ~out0 ~out1 ~out2 self ~sorted ~return_inverse ~return_counts =
  let out__ = CArray.make raw_tensor 3 in
  stubs__unique2_out
    (CArray.start out__)
    out0
    out1
    out2
    self
    (if sorted then 1 else 0)
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let _unique_out ~out0 ~out1 self ~sorted ~return_inverse =
  let out__ = CArray.make raw_tensor 2 in
  stubs__unique_out
    (CArray.start out__)
    out0
    out1
    self
    (if sorted then 1 else 0)
    (if return_inverse then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _unpack_dual ~dual ~level =
  let out__ = CArray.make raw_tensor 2 in
  stubs__unpack_dual (CArray.start out__) dual (Int64.of_int level);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _unsafe_view self ~size =
  stubs__unsafe_view
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _unsafe_view_out ~out self ~size =
  stubs__unsafe_view_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let _upsample_bicubic2d_aa self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs__upsample_bicubic2d_aa
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bicubic2d_aa_backward
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs__upsample_bicubic2d_aa_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bicubic2d_aa_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs__upsample_bicubic2d_aa_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bicubic2d_aa_out ~out self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs__upsample_bicubic2d_aa_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bicubic2d_aa_vec input ~output_size ~align_corners ~scale_factors =
  stubs__upsample_bicubic2d_aa_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let _upsample_bilinear2d_aa self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs__upsample_bilinear2d_aa
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bilinear2d_aa_backward
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs__upsample_bilinear2d_aa_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bilinear2d_aa_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs__upsample_bilinear2d_aa_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bilinear2d_aa_out ~out self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs__upsample_bilinear2d_aa_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_bilinear2d_aa_vec input ~output_size ~align_corners ~scale_factors =
  stubs__upsample_bilinear2d_aa_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let _upsample_nearest_exact1d self ~output_size ~scales =
  stubs__upsample_nearest_exact1d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact1d_backward ~grad_output ~output_size ~input_size ~scales =
  stubs__upsample_nearest_exact1d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact1d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~scales
  =
  stubs__upsample_nearest_exact1d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact1d_out ~out self ~output_size ~scales =
  stubs__upsample_nearest_exact1d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact1d_vec input ~output_size ~scale_factors =
  stubs__upsample_nearest_exact1d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let _upsample_nearest_exact2d self ~output_size ~scales_h ~scales_w =
  stubs__upsample_nearest_exact2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact2d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~scales_h
  ~scales_w
  =
  stubs__upsample_nearest_exact2d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact2d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~scales_h
  ~scales_w
  =
  stubs__upsample_nearest_exact2d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact2d_out ~out self ~output_size ~scales_h ~scales_w =
  stubs__upsample_nearest_exact2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact2d_vec input ~output_size ~scale_factors =
  stubs__upsample_nearest_exact2d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let _upsample_nearest_exact3d self ~output_size ~scales_d ~scales_h ~scales_w =
  stubs__upsample_nearest_exact3d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact3d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs__upsample_nearest_exact3d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact3d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs__upsample_nearest_exact3d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact3d_out ~out self ~output_size ~scales_d ~scales_h ~scales_w =
  stubs__upsample_nearest_exact3d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let _upsample_nearest_exact3d_vec input ~output_size ~scale_factors =
  stubs__upsample_nearest_exact3d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let _use_cudnn_ctc_loss ~log_probs ~targets ~input_lengths ~target_lengths ~blank =
  stubs__use_cudnn_ctc_loss
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    (Int64.of_int blank)
;;

let _use_cudnn_ctc_loss_tensor ~log_probs ~targets ~input_lengths ~target_lengths ~blank =
  stubs__use_cudnn_ctc_loss_tensor
    log_probs
    targets
    input_lengths
    target_lengths
    (Int64.of_int blank)
;;

let _use_cudnn_rnn_flatten_weight = stubs__use_cudnn_rnn_flatten_weight

let _validate_compressed_sparse_indices
  ~is_crow
  ~compressed_idx
  ~plain_idx
  ~cdim
  ~dim
  ~nnz
  =
  stubs__validate_compressed_sparse_indices
    (if is_crow then 1 else 0)
    compressed_idx
    plain_idx
    (Int64.of_int cdim)
    (Int64.of_int dim)
    (Int64.of_int nnz)
;;

let _validate_sparse_bsc_tensor_args ~ccol_indices ~row_indices ~values ~size =
  stubs__validate_sparse_bsc_tensor_args
    ccol_indices
    row_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
;;

let _validate_sparse_bsr_tensor_args ~crow_indices ~col_indices ~values ~size =
  stubs__validate_sparse_bsr_tensor_args
    crow_indices
    col_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
;;

let _validate_sparse_csc_tensor_args ~ccol_indices ~row_indices ~values ~size =
  stubs__validate_sparse_csc_tensor_args
    ccol_indices
    row_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
;;

let _values self = stubs__values self |> with_tensor_gc
let _values_copy self = stubs__values_copy self |> with_tensor_gc
let _values_copy_out ~out self = stubs__values_copy_out out self |> with_tensor_gc
let _version self = stubs__version self

let _weight_int4pack_mm self ~mat2 ~qgroupsize ~qscaleandzeros =
  stubs__weight_int4pack_mm self mat2 (Int64.of_int qgroupsize) qscaleandzeros
  |> with_tensor_gc
;;

let _weight_int4pack_mm_for_cpu self ~mat2 ~qgroupsize ~qscaleandzeros =
  stubs__weight_int4pack_mm_for_cpu self mat2 (Int64.of_int qgroupsize) qscaleandzeros
  |> with_tensor_gc
;;

let _weight_int8pack_mm self ~mat2 ~scales =
  stubs__weight_int8pack_mm self mat2 scales |> with_tensor_gc
;;

let _weight_norm ~v ~g ~dim = stubs__weight_norm v g (Int64.of_int dim) |> with_tensor_gc

let _weight_norm_differentiable_backward ~grad_w ~saved_v ~saved_g ~saved_norms ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs__weight_norm_differentiable_backward
    (CArray.start out__)
    grad_w
    saved_v
    saved_g
    saved_norms
    (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _weight_norm_interface ~v ~g ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs__weight_norm_interface (CArray.start out__) v g (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _weight_norm_interface_backward ~grad_w ~saved_v ~saved_g ~saved_norms ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs__weight_norm_interface_backward
    (CArray.start out__)
    grad_w
    saved_v
    saved_g
    saved_norms
    (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _weight_norm_interface_backward_out
  ~out0
  ~out1
  ~grad_w
  ~saved_v
  ~saved_g
  ~saved_norms
  ~dim
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs__weight_norm_interface_backward_out
    (CArray.start out__)
    out0
    out1
    grad_w
    saved_v
    saved_g
    saved_norms
    (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _weight_norm_interface_out ~out0 ~out1 ~v ~g ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs__weight_norm_interface_out (CArray.start out__) out0 out1 v g (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let _wrapped_linear_prepack ~weight ~weight_scale ~weight_zero_point ~bias =
  stubs__wrapped_linear_prepack weight weight_scale weight_zero_point bias
  |> with_tensor_gc
;;

let _wrapped_quantized_linear_prepacked
  input
  ~input_scale
  ~input_zero_point
  ~packed_weight
  ~output_scale
  ~output_zero_point
  ~out_channel
  =
  stubs__wrapped_quantized_linear_prepacked
    input
    input_scale
    input_zero_point
    packed_weight
    output_scale
    output_zero_point
    (Int64.of_int out_channel)
  |> with_tensor_gc
;;

let abs self = stubs_abs self |> with_tensor_gc
let abs_ self = stubs_abs_ self |> with_tensor_gc
let abs_out ~out self = stubs_abs_out out self |> with_tensor_gc
let absolute self = stubs_absolute self |> with_tensor_gc
let absolute_ self = stubs_absolute_ self |> with_tensor_gc
let absolute_out ~out self = stubs_absolute_out out self |> with_tensor_gc
let acos self = stubs_acos self |> with_tensor_gc
let acos_ self = stubs_acos_ self |> with_tensor_gc
let acos_out ~out self = stubs_acos_out out self |> with_tensor_gc
let acosh self = stubs_acosh self |> with_tensor_gc
let acosh_ self = stubs_acosh_ self |> with_tensor_gc
let acosh_out ~out self = stubs_acosh_out out self |> with_tensor_gc

let adaptive_avg_pool1d self ~output_size =
  stubs_adaptive_avg_pool1d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let adaptive_avg_pool1d_out ~out self ~output_size =
  stubs_adaptive_avg_pool1d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let adaptive_avg_pool2d self ~output_size =
  stubs_adaptive_avg_pool2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let adaptive_avg_pool2d_out ~out self ~output_size =
  stubs_adaptive_avg_pool2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let adaptive_avg_pool3d self ~output_size =
  stubs_adaptive_avg_pool3d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let adaptive_avg_pool3d_backward ~grad_input ~grad_output self =
  stubs_adaptive_avg_pool3d_backward grad_input grad_output self |> with_tensor_gc
;;

let adaptive_avg_pool3d_out ~out self ~output_size =
  stubs_adaptive_avg_pool3d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let adaptive_max_pool1d self ~output_size =
  let out__ = CArray.make raw_tensor 2 in
  stubs_adaptive_max_pool1d
    (CArray.start out__)
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let adaptive_max_pool2d self ~output_size =
  let out__ = CArray.make raw_tensor 2 in
  stubs_adaptive_max_pool2d
    (CArray.start out__)
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let adaptive_max_pool2d_backward ~grad_output self ~indices =
  stubs_adaptive_max_pool2d_backward grad_output self indices |> with_tensor_gc
;;

let adaptive_max_pool2d_backward_grad_input ~grad_input ~grad_output self ~indices =
  stubs_adaptive_max_pool2d_backward_grad_input grad_input grad_output self indices
  |> with_tensor_gc
;;

let adaptive_max_pool2d_out ~out ~indices self ~output_size =
  let out__ = CArray.make raw_tensor 2 in
  stubs_adaptive_max_pool2d_out
    (CArray.start out__)
    out
    indices
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let adaptive_max_pool3d self ~output_size =
  let out__ = CArray.make raw_tensor 2 in
  stubs_adaptive_max_pool3d
    (CArray.start out__)
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let adaptive_max_pool3d_backward ~grad_output self ~indices =
  stubs_adaptive_max_pool3d_backward grad_output self indices |> with_tensor_gc
;;

let adaptive_max_pool3d_backward_grad_input ~grad_input ~grad_output self ~indices =
  stubs_adaptive_max_pool3d_backward_grad_input grad_input grad_output self indices
  |> with_tensor_gc
;;

let adaptive_max_pool3d_out ~out ~indices self ~output_size =
  let out__ = CArray.make raw_tensor 2 in
  stubs_adaptive_max_pool3d_out
    (CArray.start out__)
    out
    indices
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let add ?alpha self other =
  stubs_add
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let add_ ?alpha self other =
  stubs_add_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let add_out ?alpha ~out self other =
  stubs_add_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let add_scalar ?alpha self other =
  stubs_add_scalar
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let add_scalar_ ?alpha self other =
  stubs_add_scalar_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let add_scalar_out ?alpha ~out self other =
  stubs_add_scalar_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addbmm ?beta ?alpha self ~batch1 ~batch2 =
  stubs_addbmm
    self
    batch1
    batch2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addbmm_ ?beta ?alpha self ~batch1 ~batch2 =
  stubs_addbmm_
    self
    batch1
    batch2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addbmm_out ?beta ?alpha ~out self ~batch1 ~batch2 =
  stubs_addbmm_out
    out
    self
    batch1
    batch2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addcdiv ?value self ~tensor1 ~tensor2 =
  stubs_addcdiv
    self
    tensor1
    tensor2
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addcdiv_ ?value self ~tensor1 ~tensor2 =
  stubs_addcdiv_
    self
    tensor1
    tensor2
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addcdiv_out ?value ~out self ~tensor1 ~tensor2 =
  stubs_addcdiv_out
    out
    self
    tensor1
    tensor2
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addcmul ?value self ~tensor1 ~tensor2 =
  stubs_addcmul
    self
    tensor1
    tensor2
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addcmul_ ?value self ~tensor1 ~tensor2 =
  stubs_addcmul_
    self
    tensor1
    tensor2
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addcmul_out ?value ~out self ~tensor1 ~tensor2 =
  stubs_addcmul_out
    out
    self
    tensor1
    tensor2
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addmm ?beta ?alpha self ~mat1 ~mat2 =
  stubs_addmm
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addmm_ ?beta ?alpha self ~mat1 ~mat2 =
  stubs_addmm_
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addmm_out ?beta ?alpha ~out self ~mat1 ~mat2 =
  stubs_addmm_out
    out
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addmv ?beta ?alpha self ~mat ~vec =
  stubs_addmv
    self
    mat
    vec
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addmv_ ?beta ?alpha self ~mat ~vec =
  stubs_addmv_
    self
    mat
    vec
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addmv_out ?beta ?alpha ~out self ~mat ~vec =
  stubs_addmv_out
    out
    self
    mat
    vec
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addr ?beta ?alpha self ~vec1 ~vec2 =
  stubs_addr
    self
    vec1
    vec2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addr_ ?beta ?alpha self ~vec1 ~vec2 =
  stubs_addr_
    self
    vec1
    vec2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let addr_out ?beta ?alpha ~out self ~vec1 ~vec2 =
  stubs_addr_out
    out
    self
    vec1
    vec2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let adjoint self = stubs_adjoint self |> with_tensor_gc

let affine_grid_generator ~theta ~size ~align_corners =
  stubs_affine_grid_generator
    theta
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let affine_grid_generator_backward ~grad ~size ~align_corners =
  stubs_affine_grid_generator_backward
    grad
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let affine_grid_generator_out ~out ~theta ~size ~align_corners =
  stubs_affine_grid_generator_out
    out
    theta
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let alias self = stubs_alias self |> with_tensor_gc
let alias_copy self = stubs_alias_copy self |> with_tensor_gc
let alias_copy_out ~out self = stubs_alias_copy_out out self |> with_tensor_gc
let align_as self other = stubs_align_as self other |> with_tensor_gc

let align_tensors tensors =
  let result =
    stubs_align_tensors
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let all self = stubs_all self |> with_tensor_gc
let all_all_out ~out self = stubs_all_all_out out self |> with_tensor_gc

let all_dim self ~dim ~keepdim =
  stubs_all_dim self (Int64.of_int dim) (if keepdim then 1 else 0) |> with_tensor_gc
;;

let all_dims self ~dim ~keepdim =
  stubs_all_dims
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let all_dims_out ~out self ~dim ~keepdim =
  stubs_all_dims_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let all_out ~out self ~dim ~keepdim =
  stubs_all_out out self (Int64.of_int dim) (if keepdim then 1 else 0) |> with_tensor_gc
;;

let allclose self other ~rtol ~atol ~equal_nan =
  stubs_allclose self other rtol atol (if equal_nan then 1 else 0)
;;

let alpha_dropout input ~p ~train =
  stubs_alpha_dropout input p (if train then 1 else 0) |> with_tensor_gc
;;

let alpha_dropout_ self ~p ~train =
  stubs_alpha_dropout_ self p (if train then 1 else 0) |> with_tensor_gc
;;

let amax self ~dim ~keepdim =
  stubs_amax
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let amax_out ~out self ~dim ~keepdim =
  stubs_amax_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let amin self ~dim ~keepdim =
  stubs_amin
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let amin_out ~out self ~dim ~keepdim =
  stubs_amin_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let aminmax self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_aminmax
    (CArray.start out__)
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let aminmax_out ~min ~max self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_aminmax_out
    (CArray.start out__)
    min
    max
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let angle self = stubs_angle self |> with_tensor_gc
let angle_out ~out self = stubs_angle_out out self |> with_tensor_gc
let any self = stubs_any self |> with_tensor_gc
let any_all_out ~out self = stubs_any_all_out out self |> with_tensor_gc

let any_dim self ~dim ~keepdim =
  stubs_any_dim self (Int64.of_int dim) (if keepdim then 1 else 0) |> with_tensor_gc
;;

let any_dims self ~dim ~keepdim =
  stubs_any_dims
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let any_dims_out ~out self ~dim ~keepdim =
  stubs_any_dims_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let any_out ~out self ~dim ~keepdim =
  stubs_any_out out self (Int64.of_int dim) (if keepdim then 1 else 0) |> with_tensor_gc
;;

let arange ~end_ ~options =
  stubs_arange end_ (Kind.packed_to_int (fst options)) (Device.to_int (snd options))
  |> with_tensor_gc
;;

let arange_start ~start ~end_ ~options =
  stubs_arange_start
    start
    end_
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let arange_start_step ?step ~start ~end_ ~options () =
  stubs_arange_start_step
    start
    end_
    (match step with
     | Some v -> v
     | None -> none_scalar)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let arccos self = stubs_arccos self |> with_tensor_gc
let arccos_ self = stubs_arccos_ self |> with_tensor_gc
let arccos_out ~out self = stubs_arccos_out out self |> with_tensor_gc
let arccosh self = stubs_arccosh self |> with_tensor_gc
let arccosh_ self = stubs_arccosh_ self |> with_tensor_gc
let arccosh_out ~out self = stubs_arccosh_out out self |> with_tensor_gc
let arcsin self = stubs_arcsin self |> with_tensor_gc
let arcsin_ self = stubs_arcsin_ self |> with_tensor_gc
let arcsin_out ~out self = stubs_arcsin_out out self |> with_tensor_gc
let arcsinh self = stubs_arcsinh self |> with_tensor_gc
let arcsinh_ self = stubs_arcsinh_ self |> with_tensor_gc
let arcsinh_out ~out self = stubs_arcsinh_out out self |> with_tensor_gc
let arctan self = stubs_arctan self |> with_tensor_gc
let arctan2 self other = stubs_arctan2 self other |> with_tensor_gc
let arctan2_ self other = stubs_arctan2_ self other |> with_tensor_gc
let arctan2_out ~out self other = stubs_arctan2_out out self other |> with_tensor_gc
let arctan_ self = stubs_arctan_ self |> with_tensor_gc
let arctan_out ~out self = stubs_arctan_out out self |> with_tensor_gc
let arctanh self = stubs_arctanh self |> with_tensor_gc
let arctanh_ self = stubs_arctanh_ self |> with_tensor_gc
let arctanh_out ~out self = stubs_arctanh_out out self |> with_tensor_gc

let argmax self ~dim ~keepdim =
  stubs_argmax
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let argmax_out ~out self ~dim ~keepdim =
  stubs_argmax_out
    out
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let argmin self ~dim ~keepdim =
  stubs_argmin
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let argmin_out ~out self ~dim ~keepdim =
  stubs_argmin_out
    out
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let argsort self ~dim ~descending =
  stubs_argsort self (Int64.of_int dim) (if descending then 1 else 0) |> with_tensor_gc
;;

let argsort_stable self ~stable ~dim ~descending =
  stubs_argsort_stable
    self
    (if stable then 1 else 0)
    (Int64.of_int dim)
    (if descending then 1 else 0)
  |> with_tensor_gc
;;

let argsort_stable_out ~out self ~stable ~dim ~descending =
  stubs_argsort_stable_out
    out
    self
    (if stable then 1 else 0)
    (Int64.of_int dim)
    (if descending then 1 else 0)
  |> with_tensor_gc
;;

let argwhere self = stubs_argwhere self |> with_tensor_gc

let as_strided self ~size ~stride ~storage_offset =
  stubs_as_strided
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (match storage_offset with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match storage_offset with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let as_strided_ self ~size ~stride ~storage_offset =
  stubs_as_strided_
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (match storage_offset with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match storage_offset with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let as_strided_copy self ~size ~stride ~storage_offset =
  stubs_as_strided_copy
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (match storage_offset with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match storage_offset with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let as_strided_copy_out ~out self ~size ~stride ~storage_offset =
  stubs_as_strided_copy_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (match storage_offset with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match storage_offset with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let as_strided_scatter self ~src ~size ~stride ~storage_offset =
  stubs_as_strided_scatter
    self
    src
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (match storage_offset with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match storage_offset with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let as_strided_scatter_out ~out self ~src ~size ~stride ~storage_offset =
  stubs_as_strided_scatter_out
    out
    self
    src
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (match storage_offset with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match storage_offset with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let asin self = stubs_asin self |> with_tensor_gc
let asin_ self = stubs_asin_ self |> with_tensor_gc
let asin_out ~out self = stubs_asin_out out self |> with_tensor_gc
let asinh self = stubs_asinh self |> with_tensor_gc
let asinh_ self = stubs_asinh_ self |> with_tensor_gc
let asinh_out ~out self = stubs_asinh_out out self |> with_tensor_gc
let atan self = stubs_atan self |> with_tensor_gc
let atan2 self other = stubs_atan2 self other |> with_tensor_gc
let atan2_ self other = stubs_atan2_ self other |> with_tensor_gc
let atan2_out ~out self other = stubs_atan2_out out self other |> with_tensor_gc
let atan_ self = stubs_atan_ self |> with_tensor_gc
let atan_out ~out self = stubs_atan_out out self |> with_tensor_gc
let atanh self = stubs_atanh self |> with_tensor_gc
let atanh_ self = stubs_atanh_ self |> with_tensor_gc
let atanh_out ~out self = stubs_atanh_out out self |> with_tensor_gc
let atleast_1d self = stubs_atleast_1d self |> with_tensor_gc

let atleast_1d_sequence tensors =
  let result =
    stubs_atleast_1d_sequence
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let atleast_2d self = stubs_atleast_2d self |> with_tensor_gc

let atleast_2d_sequence tensors =
  let result =
    stubs_atleast_2d_sequence
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let atleast_3d self = stubs_atleast_3d self |> with_tensor_gc

let atleast_3d_sequence tensors =
  let result =
    stubs_atleast_3d_sequence
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let avg_pool1d self ~kernel_size ~stride ~padding ~ceil_mode ~count_include_pad =
  stubs_avg_pool1d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
  |> with_tensor_gc
;;

let avg_pool1d_out ~out self ~kernel_size ~stride ~padding ~ceil_mode ~count_include_pad =
  stubs_avg_pool1d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
  |> with_tensor_gc
;;

let avg_pool2d
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool2d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool2d_backward
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool2d_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool2d_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool2d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool2d_out
  ~out
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool2d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool3d
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool3d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool3d_backward
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool3d_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool3d_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool3d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let avg_pool3d_out
  ~out
  self
  ~kernel_size
  ~stride
  ~padding
  ~ceil_mode
  ~count_include_pad
  ~divisor_override
  =
  stubs_avg_pool3d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (if ceil_mode then 1 else 0)
    (if count_include_pad then 1 else 0)
    (match divisor_override with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match divisor_override with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let baddbmm ?beta ?alpha self ~batch1 ~batch2 =
  stubs_baddbmm
    self
    batch1
    batch2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let baddbmm_ ?beta ?alpha self ~batch1 ~batch2 =
  stubs_baddbmm_
    self
    batch1
    batch2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let baddbmm_out ?beta ?alpha ~out self ~batch1 ~batch2 =
  stubs_baddbmm_out
    out
    self
    batch1
    batch2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let bartlett_window ~window_length ~options =
  stubs_bartlett_window
    (Int64.of_int window_length)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let bartlett_window_out ~out ~window_length =
  stubs_bartlett_window_out out (Int64.of_int window_length) |> with_tensor_gc
;;

let bartlett_window_periodic ~window_length ~periodic ~options =
  stubs_bartlett_window_periodic
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let bartlett_window_periodic_out ~out ~window_length ~periodic =
  stubs_bartlett_window_periodic_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
  |> with_tensor_gc
;;

let batch_norm
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~momentum
  ~eps
  ~cudnn_enabled
  =
  stubs_batch_norm
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    momentum
    eps
    (if cudnn_enabled then 1 else 0)
  |> with_tensor_gc
;;

let batch_norm_backward_elemt
  ~grad_out
  input
  ~mean
  ~invstd
  ~weight
  ~sum_dy
  ~sum_dy_xmu
  ~count
  =
  stubs_batch_norm_backward_elemt
    grad_out
    input
    mean
    invstd
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    sum_dy
    sum_dy_xmu
    count
  |> with_tensor_gc
;;

let batch_norm_backward_elemt_out
  ~out
  ~grad_out
  input
  ~mean
  ~invstd
  ~weight
  ~sum_dy
  ~sum_dy_xmu
  ~count
  =
  stubs_batch_norm_backward_elemt_out
    out
    grad_out
    input
    mean
    invstd
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    sum_dy
    sum_dy_xmu
    count
  |> with_tensor_gc
;;

let batch_norm_backward_reduce
  ~grad_out
  input
  ~mean
  ~invstd
  ~weight
  ~input_g
  ~weight_g
  ~bias_g
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_batch_norm_backward_reduce
    (CArray.start out__)
    grad_out
    input
    mean
    invstd
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (if input_g then 1 else 0)
    (if weight_g then 1 else 0)
    (if bias_g then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let batch_norm_backward_reduce_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~grad_out
  input
  ~mean
  ~invstd
  ~weight
  ~input_g
  ~weight_g
  ~bias_g
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_batch_norm_backward_reduce_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    grad_out
    input
    mean
    invstd
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (if input_g then 1 else 0)
    (if weight_g then 1 else 0)
    (if bias_g then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let batch_norm_elemt input ~weight ~bias ~mean ~invstd ~eps =
  stubs_batch_norm_elemt
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    mean
    invstd
    eps
  |> with_tensor_gc
;;

let batch_norm_elemt_out ~out input ~weight ~bias ~mean ~invstd ~eps =
  stubs_batch_norm_elemt_out
    out
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    mean
    invstd
    eps
  |> with_tensor_gc
;;

let batch_norm_gather_stats
  input
  ~mean
  ~invstd
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  ~count
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_gather_stats
    (CArray.start out__)
    input
    mean
    invstd
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum
    eps
    (Int64.of_int count);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_gather_stats_out
  ~out0
  ~out1
  input
  ~mean
  ~invstd
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  ~count
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_gather_stats_out
    (CArray.start out__)
    out0
    out1
    input
    mean
    invstd
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum
    eps
    (Int64.of_int count);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_gather_stats_with_counts
  input
  ~mean
  ~invstd
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  ~counts
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_gather_stats_with_counts
    (CArray.start out__)
    input
    mean
    invstd
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum
    eps
    counts;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_gather_stats_with_counts_out
  ~out0
  ~out1
  input
  ~mean
  ~invstd
  ~running_mean
  ~running_var
  ~momentum
  ~eps
  ~counts
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_gather_stats_with_counts_out
    (CArray.start out__)
    out0
    out1
    input
    mean
    invstd
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum
    eps
    counts;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_stats input ~eps =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_stats (CArray.start out__) input eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_stats_out ~out0 ~out1 input ~eps =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_stats_out (CArray.start out__) out0 out1 input eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_update_stats input ~running_mean ~running_var ~momentum =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_update_stats
    (CArray.start out__)
    input
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let batch_norm_update_stats_out ~out0 ~out1 input ~running_mean ~running_var ~momentum =
  let out__ = CArray.make raw_tensor 2 in
  stubs_batch_norm_update_stats_out
    (CArray.start out__)
    out0
    out1
    input
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    momentum;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let bernoulli self = stubs_bernoulli self |> with_tensor_gc
let bernoulli_ self ~p = stubs_bernoulli_ self p |> with_tensor_gc
let bernoulli_float_ self ~p = stubs_bernoulli_float_ self p |> with_tensor_gc
let bernoulli_p self ~p = stubs_bernoulli_p self p |> with_tensor_gc
let bernoulli_tensor self ~p = stubs_bernoulli_tensor self p |> with_tensor_gc

let bilinear ~input1 ~input2 ~weight ~bias =
  stubs_bilinear
    input1
    input2
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let binary_cross_entropy self ~target ~weight ~reduction =
  stubs_binary_cross_entropy
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let binary_cross_entropy_backward ~grad_output self ~target ~weight ~reduction =
  stubs_binary_cross_entropy_backward
    grad_output
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let binary_cross_entropy_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~target
  ~weight
  ~reduction
  =
  stubs_binary_cross_entropy_backward_grad_input
    grad_input
    grad_output
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let binary_cross_entropy_out ~out self ~target ~weight ~reduction =
  stubs_binary_cross_entropy_out
    out
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let binary_cross_entropy_with_logits self ~target ~weight ~pos_weight ~reduction =
  stubs_binary_cross_entropy_with_logits
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match pos_weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let binary_cross_entropy_with_logits_out ~out self ~target ~weight ~pos_weight ~reduction =
  stubs_binary_cross_entropy_with_logits_out
    out
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match pos_weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let bincount self ~weights ~minlength =
  stubs_bincount
    self
    (match weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int minlength)
  |> with_tensor_gc
;;

let bincount_out ~out self ~weights ~minlength =
  stubs_bincount_out
    out
    self
    (match weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int minlength)
  |> with_tensor_gc
;;

let binomial ~count ~prob = stubs_binomial count prob |> with_tensor_gc
let binomial_out ~out ~count ~prob = stubs_binomial_out out count prob |> with_tensor_gc
let bitwise_and self other = stubs_bitwise_and self other |> with_tensor_gc
let bitwise_and_ self other = stubs_bitwise_and_ self other |> with_tensor_gc

let bitwise_and_scalar_out ~out self other =
  stubs_bitwise_and_scalar_out out self other |> with_tensor_gc
;;

let bitwise_and_scalar_tensor self other =
  stubs_bitwise_and_scalar_tensor self other |> with_tensor_gc
;;

let bitwise_and_scalar_tensor_out ~out self other =
  stubs_bitwise_and_scalar_tensor_out out self other |> with_tensor_gc
;;

let bitwise_and_tensor self other = stubs_bitwise_and_tensor self other |> with_tensor_gc

let bitwise_and_tensor_ self other =
  stubs_bitwise_and_tensor_ self other |> with_tensor_gc
;;

let bitwise_and_tensor_out ~out self other =
  stubs_bitwise_and_tensor_out out self other |> with_tensor_gc
;;

let bitwise_left_shift self other = stubs_bitwise_left_shift self other |> with_tensor_gc

let bitwise_left_shift_ self other =
  stubs_bitwise_left_shift_ self other |> with_tensor_gc
;;

let bitwise_left_shift_scalar_tensor self other =
  stubs_bitwise_left_shift_scalar_tensor self other |> with_tensor_gc
;;

let bitwise_left_shift_scalar_tensor_out ~out self other =
  stubs_bitwise_left_shift_scalar_tensor_out out self other |> with_tensor_gc
;;

let bitwise_left_shift_tensor_out ~out self other =
  stubs_bitwise_left_shift_tensor_out out self other |> with_tensor_gc
;;

let bitwise_left_shift_tensor_scalar self other =
  stubs_bitwise_left_shift_tensor_scalar self other |> with_tensor_gc
;;

let bitwise_left_shift_tensor_scalar_ self other =
  stubs_bitwise_left_shift_tensor_scalar_ self other |> with_tensor_gc
;;

let bitwise_left_shift_tensor_scalar_out ~out self other =
  stubs_bitwise_left_shift_tensor_scalar_out out self other |> with_tensor_gc
;;

let bitwise_not self = stubs_bitwise_not self |> with_tensor_gc
let bitwise_not_ self = stubs_bitwise_not_ self |> with_tensor_gc
let bitwise_not_out ~out self = stubs_bitwise_not_out out self |> with_tensor_gc
let bitwise_or self other = stubs_bitwise_or self other |> with_tensor_gc
let bitwise_or_ self other = stubs_bitwise_or_ self other |> with_tensor_gc

let bitwise_or_scalar_out ~out self other =
  stubs_bitwise_or_scalar_out out self other |> with_tensor_gc
;;

let bitwise_or_scalar_tensor self other =
  stubs_bitwise_or_scalar_tensor self other |> with_tensor_gc
;;

let bitwise_or_scalar_tensor_out ~out self other =
  stubs_bitwise_or_scalar_tensor_out out self other |> with_tensor_gc
;;

let bitwise_or_tensor self other = stubs_bitwise_or_tensor self other |> with_tensor_gc
let bitwise_or_tensor_ self other = stubs_bitwise_or_tensor_ self other |> with_tensor_gc

let bitwise_or_tensor_out ~out self other =
  stubs_bitwise_or_tensor_out out self other |> with_tensor_gc
;;

let bitwise_right_shift self other =
  stubs_bitwise_right_shift self other |> with_tensor_gc
;;

let bitwise_right_shift_ self other =
  stubs_bitwise_right_shift_ self other |> with_tensor_gc
;;

let bitwise_right_shift_scalar_tensor self other =
  stubs_bitwise_right_shift_scalar_tensor self other |> with_tensor_gc
;;

let bitwise_right_shift_scalar_tensor_out ~out self other =
  stubs_bitwise_right_shift_scalar_tensor_out out self other |> with_tensor_gc
;;

let bitwise_right_shift_tensor_out ~out self other =
  stubs_bitwise_right_shift_tensor_out out self other |> with_tensor_gc
;;

let bitwise_right_shift_tensor_scalar self other =
  stubs_bitwise_right_shift_tensor_scalar self other |> with_tensor_gc
;;

let bitwise_right_shift_tensor_scalar_ self other =
  stubs_bitwise_right_shift_tensor_scalar_ self other |> with_tensor_gc
;;

let bitwise_right_shift_tensor_scalar_out ~out self other =
  stubs_bitwise_right_shift_tensor_scalar_out out self other |> with_tensor_gc
;;

let bitwise_xor self other = stubs_bitwise_xor self other |> with_tensor_gc
let bitwise_xor_ self other = stubs_bitwise_xor_ self other |> with_tensor_gc

let bitwise_xor_scalar_out ~out self other =
  stubs_bitwise_xor_scalar_out out self other |> with_tensor_gc
;;

let bitwise_xor_scalar_tensor self other =
  stubs_bitwise_xor_scalar_tensor self other |> with_tensor_gc
;;

let bitwise_xor_scalar_tensor_out ~out self other =
  stubs_bitwise_xor_scalar_tensor_out out self other |> with_tensor_gc
;;

let bitwise_xor_tensor self other = stubs_bitwise_xor_tensor self other |> with_tensor_gc

let bitwise_xor_tensor_ self other =
  stubs_bitwise_xor_tensor_ self other |> with_tensor_gc
;;

let bitwise_xor_tensor_out ~out self other =
  stubs_bitwise_xor_tensor_out out self other |> with_tensor_gc
;;

let blackman_window ~window_length ~options =
  stubs_blackman_window
    (Int64.of_int window_length)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let blackman_window_out ~out ~window_length =
  stubs_blackman_window_out out (Int64.of_int window_length) |> with_tensor_gc
;;

let blackman_window_periodic ~window_length ~periodic ~options =
  stubs_blackman_window_periodic
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let blackman_window_periodic_out ~out ~window_length ~periodic =
  stubs_blackman_window_periodic_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
  |> with_tensor_gc
;;

let block_diag tensors =
  let result =
    stubs_block_diag
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let block_diag_out ~out tensors =
  let result =
    stubs_block_diag_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let bmm self ~mat2 = stubs_bmm self mat2 |> with_tensor_gc
let bmm_out ~out self ~mat2 = stubs_bmm_out out self mat2 |> with_tensor_gc

let broadcast_tensors tensors =
  let result =
    stubs_broadcast_tensors
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let broadcast_to self ~size =
  stubs_broadcast_to
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let bucketize self ~boundaries ~out_int32 ~right =
  stubs_bucketize self boundaries (if out_int32 then 1 else 0) (if right then 1 else 0)
  |> with_tensor_gc
;;

let bucketize_scalar self ~boundaries ~out_int32 ~right =
  stubs_bucketize_scalar
    self
    boundaries
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
  |> with_tensor_gc
;;

let bucketize_scalar_out ~out self ~boundaries ~out_int32 ~right =
  stubs_bucketize_scalar_out
    out
    self
    boundaries
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
  |> with_tensor_gc
;;

let bucketize_tensor_out ~out self ~boundaries ~out_int32 ~right =
  stubs_bucketize_tensor_out
    out
    self
    boundaries
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
  |> with_tensor_gc
;;

let can_cast ~from_ ~to_ =
  stubs_can_cast (Kind.packed_to_int from_) (Kind.packed_to_int to_)
;;

let cartesian_prod tensors =
  let result =
    stubs_cartesian_prod
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let cat tensors ~dim =
  let result =
    stubs_cat
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let cat_out ~out tensors ~dim =
  let result =
    stubs_cat_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let cauchy self ~median ~sigma = stubs_cauchy self median sigma |> with_tensor_gc
let cauchy_ self ~median ~sigma = stubs_cauchy_ self median sigma |> with_tensor_gc

let cauchy_out ~out self ~median ~sigma =
  stubs_cauchy_out out self median sigma |> with_tensor_gc
;;

let ccol_indices self = stubs_ccol_indices self |> with_tensor_gc
let ccol_indices_copy self = stubs_ccol_indices_copy self |> with_tensor_gc

let ccol_indices_copy_out ~out self =
  stubs_ccol_indices_copy_out out self |> with_tensor_gc
;;

let cdist ~x1 ~x2 ~p ~compute_mode =
  stubs_cdist
    x1
    x2
    p
    (match compute_mode with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match compute_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let ceil self = stubs_ceil self |> with_tensor_gc
let ceil_ self = stubs_ceil_ self |> with_tensor_gc
let ceil_out ~out self = stubs_ceil_out out self |> with_tensor_gc

let celu ?alpha self =
  stubs_celu
    self
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let celu_ ?alpha self =
  stubs_celu_
    self
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let celu_out ?alpha ~out self =
  stubs_celu_out
    out
    self
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let chain_matmul ~matrices =
  let result =
    stubs_chain_matmul
      (CArray.of_list gc_tensor matrices |> CArray.start)
      (List.length matrices)
    |> with_tensor_gc
  in
  keep_values_alive matrices;
  result
;;

let chain_matmul_out ~out ~matrices =
  let result =
    stubs_chain_matmul_out
      out
      (CArray.of_list gc_tensor matrices |> CArray.start)
      (List.length matrices)
    |> with_tensor_gc
  in
  keep_values_alive matrices;
  result
;;

let chalf self = stubs_chalf self |> with_tensor_gc

let channel_shuffle self ~groups =
  stubs_channel_shuffle self (Int64.of_int groups) |> with_tensor_gc
;;

let channel_shuffle_out ~out self ~groups =
  stubs_channel_shuffle_out out self (Int64.of_int groups) |> with_tensor_gc
;;

let cholesky self ~upper = stubs_cholesky self (if upper then 1 else 0) |> with_tensor_gc

let cholesky_inverse self ~upper =
  stubs_cholesky_inverse self (if upper then 1 else 0) |> with_tensor_gc
;;

let cholesky_inverse_out ~out self ~upper =
  stubs_cholesky_inverse_out out self (if upper then 1 else 0) |> with_tensor_gc
;;

let cholesky_out ~out self ~upper =
  stubs_cholesky_out out self (if upper then 1 else 0) |> with_tensor_gc
;;

let cholesky_solve self ~input2 ~upper =
  stubs_cholesky_solve self input2 (if upper then 1 else 0) |> with_tensor_gc
;;

let cholesky_solve_out ~out self ~input2 ~upper =
  stubs_cholesky_solve_out out self input2 (if upper then 1 else 0) |> with_tensor_gc
;;

let choose_qparams_optimized input ~numel ~n_bins ~ratio ~bit_width =
  let out__ = CArray.make raw_tensor 2 in
  stubs_choose_qparams_optimized
    (CArray.start out__)
    input
    (Int64.of_int numel)
    (Int64.of_int n_bins)
    ratio
    (Int64.of_int bit_width);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let chunk self ~chunks ~dim =
  stubs_chunk self (Int64.of_int chunks) (Int64.of_int dim) |> to_tensor_list
;;

let clamp self ~min ~max = stubs_clamp self min max |> with_tensor_gc
let clamp_ self ~min ~max = stubs_clamp_ self min max |> with_tensor_gc
let clamp_max self ~max = stubs_clamp_max self max |> with_tensor_gc
let clamp_max_ self ~max = stubs_clamp_max_ self max |> with_tensor_gc
let clamp_max_out ~out self ~max = stubs_clamp_max_out out self max |> with_tensor_gc
let clamp_max_tensor self ~max = stubs_clamp_max_tensor self max |> with_tensor_gc
let clamp_max_tensor_ self ~max = stubs_clamp_max_tensor_ self max |> with_tensor_gc

let clamp_max_tensor_out ~out self ~max =
  stubs_clamp_max_tensor_out out self max |> with_tensor_gc
;;

let clamp_min self ~min = stubs_clamp_min self min |> with_tensor_gc
let clamp_min_ self ~min = stubs_clamp_min_ self min |> with_tensor_gc
let clamp_min_out ~out self ~min = stubs_clamp_min_out out self min |> with_tensor_gc
let clamp_min_tensor self ~min = stubs_clamp_min_tensor self min |> with_tensor_gc
let clamp_min_tensor_ self ~min = stubs_clamp_min_tensor_ self min |> with_tensor_gc

let clamp_min_tensor_out ~out self ~min =
  stubs_clamp_min_tensor_out out self min |> with_tensor_gc
;;

let clamp_out ~out self ~min ~max = stubs_clamp_out out self min max |> with_tensor_gc

let clamp_tensor self ~min ~max =
  stubs_clamp_tensor
    self
    (match min with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let clamp_tensor_ self ~min ~max =
  stubs_clamp_tensor_
    self
    (match min with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let clamp_tensor_out ~out self ~min ~max =
  stubs_clamp_tensor_out
    out
    self
    (match min with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let clip self ~min ~max = stubs_clip self min max |> with_tensor_gc
let clip_ self ~min ~max = stubs_clip_ self min max |> with_tensor_gc
let clip_out ~out self ~min ~max = stubs_clip_out out self min max |> with_tensor_gc

let clip_tensor self ~min ~max =
  stubs_clip_tensor
    self
    (match min with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let clip_tensor_ self ~min ~max =
  stubs_clip_tensor_
    self
    (match min with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let clip_tensor_out ~out self ~min ~max =
  stubs_clip_tensor_out
    out
    self
    (match min with
     | Some v -> v
     | None -> none_gc_tensor)
    (match max with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let clone self = stubs_clone self |> with_tensor_gc
let clone_out ~out self = stubs_clone_out out self |> with_tensor_gc
let coalesce self = stubs_coalesce self |> with_tensor_gc

let col2im self ~output_size ~kernel_size ~dilation ~padding ~stride =
  stubs_col2im
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let col2im_out ~out self ~output_size ~kernel_size ~dilation ~padding ~stride =
  stubs_col2im_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let col_indices self = stubs_col_indices self |> with_tensor_gc
let col_indices_copy self = stubs_col_indices_copy self |> with_tensor_gc
let col_indices_copy_out ~out self = stubs_col_indices_copy_out out self |> with_tensor_gc

let column_stack tensors =
  let result =
    stubs_column_stack
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let column_stack_out ~out tensors =
  let result =
    stubs_column_stack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let combinations self ~r ~with_replacement =
  stubs_combinations self (Int64.of_int r) (if with_replacement then 1 else 0)
  |> with_tensor_gc
;;

let complex ~real ~imag = stubs_complex real imag |> with_tensor_gc
let complex_out ~out ~real ~imag = stubs_complex_out out real imag |> with_tensor_gc

let concat tensors ~dim =
  let result =
    stubs_concat
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let concat_out ~out tensors ~dim =
  let result =
    stubs_concat_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let concatenate tensors ~dim =
  let result =
    stubs_concatenate
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let concatenate_out ~out tensors ~dim =
  let result =
    stubs_concatenate_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let conj self = stubs_conj self |> with_tensor_gc
let conj_physical self = stubs_conj_physical self |> with_tensor_gc
let conj_physical_ self = stubs_conj_physical_ self |> with_tensor_gc
let conj_physical_out ~out self = stubs_conj_physical_out out self |> with_tensor_gc

let constant_pad_nd ?value self ~pad =
  stubs_constant_pad_nd
    self
    (List.map Int64.of_int pad |> CArray.of_list int64_t |> CArray.start)
    (List.length pad)
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let constant_pad_nd_out ?value ~out self ~pad =
  stubs_constant_pad_nd_out
    out
    self
    (List.map Int64.of_int pad |> CArray.of_list int64_t |> CArray.start)
    (List.length pad)
    (match value with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let contiguous self = stubs_contiguous self |> with_tensor_gc

let conv1d input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_conv1d
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let conv1d_padding input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_conv1d_padding
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    padding
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let conv2d input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_conv2d
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let conv2d_padding input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_conv2d_padding
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    padding
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let conv3d input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_conv3d
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let conv3d_padding input ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_conv3d_padding
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    padding
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let conv_depthwise3d self ~weight ~kernel_size ~bias ~stride ~padding ~dilation =
  stubs_conv_depthwise3d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let conv_depthwise3d_out ~out self ~weight ~kernel_size ~bias ~stride ~padding ~dilation =
  stubs_conv_depthwise3d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let conv_tbc self ~weight ~bias ~pad =
  stubs_conv_tbc self weight bias (Int64.of_int pad) |> with_tensor_gc
;;

let conv_tbc_backward self input ~weight ~bias ~pad =
  let out__ = CArray.make raw_tensor 3 in
  stubs_conv_tbc_backward (CArray.start out__) self input weight bias (Int64.of_int pad);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let conv_tbc_out ~out self ~weight ~bias ~pad =
  stubs_conv_tbc_out out self weight bias (Int64.of_int pad) |> with_tensor_gc
;;

let conv_transpose1d
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~groups
  ~dilation
  =
  stubs_conv_transpose1d
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let conv_transpose2d
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~groups
  ~dilation
  =
  stubs_conv_transpose2d
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let conv_transpose3d
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~groups
  ~dilation
  =
  stubs_conv_transpose3d
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let convolution
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  =
  stubs_convolution
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let convolution_out
  ~out
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  =
  stubs_convolution_out
    out
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let convolution_overrideable
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  =
  stubs_convolution_overrideable
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let convolution_overrideable_out
  ~out
  input
  ~weight
  ~bias
  ~stride
  ~padding
  ~dilation
  ~transposed
  ~output_padding
  ~groups
  =
  stubs_convolution_overrideable_out
    out
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if transposed then 1 else 0)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let copy self ~src ~non_blocking =
  stubs_copy self src (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let copy_out ~out self ~src ~non_blocking =
  stubs_copy_out out self src (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let copy_sparse_to_sparse self ~src ~non_blocking =
  stubs_copy_sparse_to_sparse self src (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let copy_sparse_to_sparse_ self ~src ~non_blocking =
  stubs_copy_sparse_to_sparse_ self src (if non_blocking then 1 else 0) |> with_tensor_gc
;;

let copy_sparse_to_sparse_out ~out self ~src ~non_blocking =
  stubs_copy_sparse_to_sparse_out out self src (if non_blocking then 1 else 0)
  |> with_tensor_gc
;;

let copysign self other = stubs_copysign self other |> with_tensor_gc
let copysign_ self other = stubs_copysign_ self other |> with_tensor_gc
let copysign_out ~out self other = stubs_copysign_out out self other |> with_tensor_gc
let copysign_scalar self other = stubs_copysign_scalar self other |> with_tensor_gc
let copysign_scalar_ self other = stubs_copysign_scalar_ self other |> with_tensor_gc

let copysign_scalar_out ~out self other =
  stubs_copysign_scalar_out out self other |> with_tensor_gc
;;

let corrcoef self = stubs_corrcoef self |> with_tensor_gc
let cos self = stubs_cos self |> with_tensor_gc
let cos_ self = stubs_cos_ self |> with_tensor_gc
let cos_out ~out self = stubs_cos_out out self |> with_tensor_gc
let cosh self = stubs_cosh self |> with_tensor_gc
let cosh_ self = stubs_cosh_ self |> with_tensor_gc
let cosh_out ~out self = stubs_cosh_out out self |> with_tensor_gc

let cosine_embedding_loss ~input1 ~input2 ~target ~margin ~reduction =
  stubs_cosine_embedding_loss
    input1
    input2
    target
    margin
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let cosine_similarity ~x1 ~x2 ~dim ~eps =
  stubs_cosine_similarity x1 x2 (Int64.of_int dim) eps |> with_tensor_gc
;;

let count_nonzero ~out self ~dim =
  stubs_count_nonzero
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let count_nonzero_out ~out self ~dim =
  stubs_count_nonzero_out
    out
    self
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let cov self ~correction ~fweights ~aweights =
  stubs_cov
    self
    (Int64.of_int correction)
    (match fweights with
     | Some v -> v
     | None -> none_gc_tensor)
    (match aweights with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let cross self other ~dim =
  stubs_cross
    self
    other
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let cross_entropy_loss self ~target ~weight ~reduction ~ignore_index ~label_smoothing =
  stubs_cross_entropy_loss
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
    label_smoothing
  |> with_tensor_gc
;;

let cross_out ~out self other ~dim =
  stubs_cross_out
    out
    self
    other
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let crow_indices self = stubs_crow_indices self |> with_tensor_gc
let crow_indices_copy self = stubs_crow_indices_copy self |> with_tensor_gc

let crow_indices_copy_out ~out self =
  stubs_crow_indices_copy_out out self |> with_tensor_gc
;;

let ctc_loss
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~reduction
  ~zero_infinity
  =
  stubs_ctc_loss
    log_probs
    targets
    (List.map Int64.of_int input_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length input_lengths)
    (List.map Int64.of_int target_lengths |> CArray.of_list int64_t |> CArray.start)
    (List.length target_lengths)
    (Int64.of_int blank)
    (Reduction.to_int reduction |> Int64.of_int)
    (if zero_infinity then 1 else 0)
  |> with_tensor_gc
;;

let ctc_loss_tensor
  ~log_probs
  ~targets
  ~input_lengths
  ~target_lengths
  ~blank
  ~reduction
  ~zero_infinity
  =
  stubs_ctc_loss_tensor
    log_probs
    targets
    input_lengths
    target_lengths
    (Int64.of_int blank)
    (Reduction.to_int reduction |> Int64.of_int)
    (if zero_infinity then 1 else 0)
  |> with_tensor_gc
;;

let cudnn_affine_grid_generator ~theta ~n ~c ~h ~w =
  stubs_cudnn_affine_grid_generator
    theta
    (Int64.of_int n)
    (Int64.of_int c)
    (Int64.of_int h)
    (Int64.of_int w)
  |> with_tensor_gc
;;

let cudnn_affine_grid_generator_backward ~grad ~n ~c ~h ~w =
  stubs_cudnn_affine_grid_generator_backward
    grad
    (Int64.of_int n)
    (Int64.of_int c)
    (Int64.of_int h)
    (Int64.of_int w)
  |> with_tensor_gc
;;

let cudnn_affine_grid_generator_backward_out ~out ~grad ~n ~c ~h ~w =
  stubs_cudnn_affine_grid_generator_backward_out
    out
    grad
    (Int64.of_int n)
    (Int64.of_int c)
    (Int64.of_int h)
    (Int64.of_int w)
  |> with_tensor_gc
;;

let cudnn_affine_grid_generator_out ~out ~theta ~n ~c ~h ~w =
  stubs_cudnn_affine_grid_generator_out
    out
    theta
    (Int64.of_int n)
    (Int64.of_int c)
    (Int64.of_int h)
    (Int64.of_int w)
  |> with_tensor_gc
;;

let cudnn_batch_norm
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~exponential_average_factor
  ~epsilon
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_cudnn_batch_norm
    (CArray.start out__)
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    exponential_average_factor
    epsilon;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let cudnn_batch_norm_backward
  input
  ~grad_output
  ~weight
  ~running_mean
  ~running_var
  ~save_mean
  ~save_var
  ~epsilon
  ~reservespace
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_cudnn_batch_norm_backward
    (CArray.start out__)
    input
    grad_output
    weight
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_var with
     | Some v -> v
     | None -> none_gc_tensor)
    epsilon
    reservespace;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let cudnn_batch_norm_backward_out
  ~out0
  ~out1
  ~out2
  input
  ~grad_output
  ~weight
  ~running_mean
  ~running_var
  ~save_mean
  ~save_var
  ~epsilon
  ~reservespace
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_cudnn_batch_norm_backward_out
    (CArray.start out__)
    out0
    out1
    out2
    input
    grad_output
    weight
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_var with
     | Some v -> v
     | None -> none_gc_tensor)
    epsilon
    reservespace;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let cudnn_batch_norm_out
  ~out0
  ~out1
  ~out2
  ~out3
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~exponential_average_factor
  ~epsilon
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_cudnn_batch_norm_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    exponential_average_factor
    epsilon;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let cudnn_convolution
  self
  ~weight
  ~padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  ~allow_tf32
  =
  stubs_cudnn_convolution
    self
    weight
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if allow_tf32 then 1 else 0)
  |> with_tensor_gc
;;

let cudnn_convolution_add_relu
  self
  ~weight
  ~z
  ~alpha
  ~bias
  ~stride
  ~padding
  ~dilation
  ~groups
  =
  stubs_cudnn_convolution_add_relu
    self
    weight
    z
    alpha
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let cudnn_convolution_add_relu_out
  ~out
  self
  ~weight
  ~z
  ~alpha
  ~bias
  ~stride
  ~padding
  ~dilation
  ~groups
  =
  stubs_cudnn_convolution_add_relu_out
    out
    self
    weight
    z
    alpha
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let cudnn_convolution_out
  ~out
  self
  ~weight
  ~padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  ~allow_tf32
  =
  stubs_cudnn_convolution_out
    out
    self
    weight
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if allow_tf32 then 1 else 0)
  |> with_tensor_gc
;;

let cudnn_convolution_relu self ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_cudnn_convolution_relu
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let cudnn_convolution_relu_out ~out self ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_cudnn_convolution_relu_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let cudnn_convolution_transpose
  self
  ~weight
  ~padding
  ~output_padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  ~allow_tf32
  =
  stubs_cudnn_convolution_transpose
    self
    weight
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if allow_tf32 then 1 else 0)
  |> with_tensor_gc
;;

let cudnn_convolution_transpose_out
  ~out
  self
  ~weight
  ~padding
  ~output_padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  ~allow_tf32
  =
  stubs_cudnn_convolution_transpose_out
    out
    self
    weight
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
    (if allow_tf32 then 1 else 0)
  |> with_tensor_gc
;;

let cudnn_grid_sampler self ~grid = stubs_cudnn_grid_sampler self grid |> with_tensor_gc

let cudnn_grid_sampler_backward self ~grid ~grad_output =
  let out__ = CArray.make raw_tensor 2 in
  stubs_cudnn_grid_sampler_backward (CArray.start out__) self grid grad_output;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let cudnn_grid_sampler_backward_out ~out0 ~out1 self ~grid ~grad_output =
  let out__ = CArray.make raw_tensor 2 in
  stubs_cudnn_grid_sampler_backward_out
    (CArray.start out__)
    out0
    out1
    self
    grid
    grad_output;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let cudnn_grid_sampler_out ~out self ~grid =
  stubs_cudnn_grid_sampler_out out self grid |> with_tensor_gc
;;

let cudnn_is_acceptable self = stubs_cudnn_is_acceptable self

let cummax self ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_cummax (CArray.start out__) self (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let cummax_out ~values ~indices self ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_cummax_out (CArray.start out__) values indices self (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let cummaxmin_backward ~grad input ~indices ~dim =
  stubs_cummaxmin_backward grad input indices (Int64.of_int dim) |> with_tensor_gc
;;

let cummin self ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_cummin (CArray.start out__) self (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let cummin_out ~values ~indices self ~dim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_cummin_out (CArray.start out__) values indices self (Int64.of_int dim);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let cumprod self ~dim ~dtype =
  stubs_cumprod self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let cumprod_ self ~dim ~dtype =
  stubs_cumprod_ self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let cumprod_backward ~grad input ~dim ~output =
  stubs_cumprod_backward grad input (Int64.of_int dim) output |> with_tensor_gc
;;

let cumprod_out ~out self ~dim ~dtype =
  stubs_cumprod_out out self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let cumsum self ~dim ~dtype =
  stubs_cumsum self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let cumsum_ self ~dim ~dtype =
  stubs_cumsum_ self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let cumsum_out ~out self ~dim ~dtype =
  stubs_cumsum_out out self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let cumulative_trapezoid ~y ~x ~dim =
  stubs_cumulative_trapezoid y x (Int64.of_int dim) |> with_tensor_gc
;;

let cumulative_trapezoid_dx ?dx ~y ~dim () =
  stubs_cumulative_trapezoid_dx
    y
    (match dx with
     | Some v -> v
     | None -> none_scalar)
    (Int64.of_int dim)
  |> with_tensor_gc
;;

let data self = stubs_data self |> with_tensor_gc
let deg2rad self = stubs_deg2rad self |> with_tensor_gc
let deg2rad_ self = stubs_deg2rad_ self |> with_tensor_gc
let deg2rad_out ~out self = stubs_deg2rad_out out self |> with_tensor_gc
let dense_dim self = stubs_dense_dim self
let dequantize self = stubs_dequantize self |> with_tensor_gc
let dequantize_self_out ~out self = stubs_dequantize_self_out out self |> with_tensor_gc

let dequantize_tensors tensors =
  let result =
    stubs_dequantize_tensors
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let dequantize_tensors_out ~out tensors =
  let result =
    stubs_dequantize_tensors_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
  in
  keep_values_alive out;
  keep_values_alive tensors;
  result
;;

let det self = stubs_det self |> with_tensor_gc
let detach self = stubs_detach self |> with_tensor_gc
let detach_ self = stubs_detach_ self |> with_tensor_gc
let detach_copy self = stubs_detach_copy self |> with_tensor_gc
let detach_copy_out ~out self = stubs_detach_copy_out out self |> with_tensor_gc
let diag self ~diagonal = stubs_diag self (Int64.of_int diagonal) |> with_tensor_gc

let diag_embed self ~offset ~dim1 ~dim2 =
  stubs_diag_embed self (Int64.of_int offset) (Int64.of_int dim1) (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diag_embed_out ~out self ~offset ~dim1 ~dim2 =
  stubs_diag_embed_out
    out
    self
    (Int64.of_int offset)
    (Int64.of_int dim1)
    (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diag_out ~out self ~diagonal =
  stubs_diag_out out self (Int64.of_int diagonal) |> with_tensor_gc
;;

let diagflat self ~offset = stubs_diagflat self (Int64.of_int offset) |> with_tensor_gc

let diagonal self ~offset ~dim1 ~dim2 =
  stubs_diagonal self (Int64.of_int offset) (Int64.of_int dim1) (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diagonal_backward ~grad_output ~input_sizes ~offset ~dim1 ~dim2 =
  stubs_diagonal_backward
    grad_output
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int offset)
    (Int64.of_int dim1)
    (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diagonal_backward_out ~out ~grad_output ~input_sizes ~offset ~dim1 ~dim2 =
  stubs_diagonal_backward_out
    out
    grad_output
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int offset)
    (Int64.of_int dim1)
    (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diagonal_copy self ~offset ~dim1 ~dim2 =
  stubs_diagonal_copy self (Int64.of_int offset) (Int64.of_int dim1) (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diagonal_copy_out ~out self ~offset ~dim1 ~dim2 =
  stubs_diagonal_copy_out
    out
    self
    (Int64.of_int offset)
    (Int64.of_int dim1)
    (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diagonal_scatter self ~src ~offset ~dim1 ~dim2 =
  stubs_diagonal_scatter
    self
    src
    (Int64.of_int offset)
    (Int64.of_int dim1)
    (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diagonal_scatter_out ~out self ~src ~offset ~dim1 ~dim2 =
  stubs_diagonal_scatter_out
    out
    self
    src
    (Int64.of_int offset)
    (Int64.of_int dim1)
    (Int64.of_int dim2)
  |> with_tensor_gc
;;

let diff self ~n ~dim ~prepend ~append =
  stubs_diff
    self
    (Int64.of_int n)
    (Int64.of_int dim)
    (match prepend with
     | Some v -> v
     | None -> none_gc_tensor)
    (match append with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let diff_out ~out self ~n ~dim ~prepend ~append =
  stubs_diff_out
    out
    self
    (Int64.of_int n)
    (Int64.of_int dim)
    (match prepend with
     | Some v -> v
     | None -> none_gc_tensor)
    (match append with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let digamma self = stubs_digamma self |> with_tensor_gc
let digamma_ self = stubs_digamma_ self |> with_tensor_gc
let digamma_out ~out self = stubs_digamma_out out self |> with_tensor_gc

let dist ?p self other =
  stubs_dist
    self
    other
    (match p with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let dist_out ?p ~out self other =
  stubs_dist_out
    out
    self
    other
    (match p with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let div self other = stubs_div self other |> with_tensor_gc
let div_ self other = stubs_div_ self other |> with_tensor_gc
let div_out ~out self other = stubs_div_out out self other |> with_tensor_gc

let div_out_mode ~out self other ~rounding_mode =
  stubs_div_out_mode
    out
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let div_scalar self other = stubs_div_scalar self other |> with_tensor_gc
let div_scalar_ self other = stubs_div_scalar_ self other |> with_tensor_gc

let div_scalar_mode self other ~rounding_mode =
  stubs_div_scalar_mode
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let div_scalar_mode_ self other ~rounding_mode =
  stubs_div_scalar_mode_
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let div_scalar_mode_out ~out self other ~rounding_mode =
  stubs_div_scalar_mode_out
    out
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let div_scalar_out ~out self other = stubs_div_scalar_out out self other |> with_tensor_gc

let div_tensor_mode self other ~rounding_mode =
  stubs_div_tensor_mode
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let div_tensor_mode_ self other ~rounding_mode =
  stubs_div_tensor_mode_
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let divide self other = stubs_divide self other |> with_tensor_gc
let divide_ self other = stubs_divide_ self other |> with_tensor_gc
let divide_out ~out self other = stubs_divide_out out self other |> with_tensor_gc

let divide_out_mode ~out self other ~rounding_mode =
  stubs_divide_out_mode
    out
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let divide_scalar self other = stubs_divide_scalar self other |> with_tensor_gc
let divide_scalar_ self other = stubs_divide_scalar_ self other |> with_tensor_gc

let divide_scalar_mode self other ~rounding_mode =
  stubs_divide_scalar_mode
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let divide_scalar_mode_ self other ~rounding_mode =
  stubs_divide_scalar_mode_
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let divide_tensor_mode self other ~rounding_mode =
  stubs_divide_tensor_mode
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let divide_tensor_mode_ self other ~rounding_mode =
  stubs_divide_tensor_mode_
    self
    other
    (Option.value rounding_mode ~default:"")
    (match rounding_mode with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let dot self tensor = stubs_dot self tensor |> with_tensor_gc
let dot_out ~out self tensor = stubs_dot_out out self tensor |> with_tensor_gc

let dropout input ~p ~train =
  stubs_dropout input p (if train then 1 else 0) |> with_tensor_gc
;;

let dropout_ self ~p ~train =
  stubs_dropout_ self p (if train then 1 else 0) |> with_tensor_gc
;;

let dsplit self ~sections = stubs_dsplit self (Int64.of_int sections) |> to_tensor_list

let dsplit_array self ~indices =
  stubs_dsplit_array
    self
    (List.map Int64.of_int indices |> CArray.of_list int64_t |> CArray.start)
    (List.length indices)
  |> to_tensor_list
;;

let dstack tensors =
  let result =
    stubs_dstack (CArray.of_list gc_tensor tensors |> CArray.start) (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let dstack_out ~out tensors =
  let result =
    stubs_dstack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let einsum ~equation tensors ~path =
  let result =
    stubs_einsum
      equation
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (match path with
       | None -> from_voidp int64_t null
       | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
      (match path with
       | None -> -1
       | Some v -> List.length v)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let elu ?alpha ?scale ?input_scale self =
  stubs_elu
    self
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
    (match scale with
     | Some v -> v
     | None -> none_scalar)
    (match input_scale with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let elu_ ?alpha ?scale ?input_scale self =
  stubs_elu_
    self
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
    (match scale with
     | Some v -> v
     | None -> none_scalar)
    (match input_scale with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let elu_backward ~grad_output ~alpha ~scale ~input_scale ~is_result ~self_or_result =
  stubs_elu_backward
    grad_output
    alpha
    scale
    input_scale
    (if is_result then 1 else 0)
    self_or_result
  |> with_tensor_gc
;;

let elu_backward_grad_input
  ~grad_input
  ~grad_output
  ~alpha
  ~scale
  ~input_scale
  ~is_result
  ~self_or_result
  =
  stubs_elu_backward_grad_input
    grad_input
    grad_output
    alpha
    scale
    input_scale
    (if is_result then 1 else 0)
    self_or_result
  |> with_tensor_gc
;;

let elu_out ?alpha ?scale ?input_scale ~out self =
  stubs_elu_out
    out
    self
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
    (match scale with
     | Some v -> v
     | None -> none_scalar)
    (match input_scale with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let embedding ~weight ~indices ~padding_idx ~scale_grad_by_freq ~sparse =
  stubs_embedding
    weight
    indices
    (Int64.of_int padding_idx)
    (if scale_grad_by_freq then 1 else 0)
    (if sparse then 1 else 0)
  |> with_tensor_gc
;;

let embedding_backward
  ~grad
  ~indices
  ~num_weights
  ~padding_idx
  ~scale_grad_by_freq
  ~sparse
  =
  stubs_embedding_backward
    grad
    indices
    (Int64.of_int num_weights)
    (Int64.of_int padding_idx)
    (if scale_grad_by_freq then 1 else 0)
    (if sparse then 1 else 0)
  |> with_tensor_gc
;;

let embedding_bag
  ~weight
  ~indices
  ~offsets
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~include_last_offset
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_embedding_bag
    (CArray.start out__)
    weight
    indices
    offsets
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (if include_last_offset then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let embedding_bag_padding_idx
  ~weight
  ~indices
  ~offsets
  ~scale_grad_by_freq
  ~mode
  ~sparse
  ~per_sample_weights
  ~include_last_offset
  ~padding_idx
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_embedding_bag_padding_idx
    (CArray.start out__)
    weight
    indices
    offsets
    (if scale_grad_by_freq then 1 else 0)
    (Int64.of_int mode)
    (if sparse then 1 else 0)
    (match per_sample_weights with
     | Some v -> v
     | None -> none_gc_tensor)
    (if include_last_offset then 1 else 0)
    (match padding_idx with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match padding_idx with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let embedding_dense_backward
  ~grad_output
  ~indices
  ~num_weights
  ~padding_idx
  ~scale_grad_by_freq
  =
  stubs_embedding_dense_backward
    grad_output
    indices
    (Int64.of_int num_weights)
    (Int64.of_int padding_idx)
    (if scale_grad_by_freq then 1 else 0)
  |> with_tensor_gc
;;

let embedding_dense_backward_out
  ~out
  ~grad_output
  ~indices
  ~num_weights
  ~padding_idx
  ~scale_grad_by_freq
  =
  stubs_embedding_dense_backward_out
    out
    grad_output
    indices
    (Int64.of_int num_weights)
    (Int64.of_int padding_idx)
    (if scale_grad_by_freq then 1 else 0)
  |> with_tensor_gc
;;

let embedding_out ~out ~weight ~indices ~padding_idx ~scale_grad_by_freq ~sparse =
  stubs_embedding_out
    out
    weight
    indices
    (Int64.of_int padding_idx)
    (if scale_grad_by_freq then 1 else 0)
    (if sparse then 1 else 0)
  |> with_tensor_gc
;;

let embedding_renorm self ~indices ~max_norm ~norm_type =
  stubs_embedding_renorm self indices max_norm norm_type |> with_tensor_gc
;;

let embedding_renorm_ self ~indices ~max_norm ~norm_type =
  stubs_embedding_renorm_ self indices max_norm norm_type |> with_tensor_gc
;;

let embedding_renorm_out ~out self ~indices ~max_norm ~norm_type =
  stubs_embedding_renorm_out out self indices max_norm norm_type |> with_tensor_gc
;;

let embedding_sparse_backward ~grad ~indices ~num_weights ~padding_idx ~scale_grad_by_freq
  =
  stubs_embedding_sparse_backward
    grad
    indices
    (Int64.of_int num_weights)
    (Int64.of_int padding_idx)
    (if scale_grad_by_freq then 1 else 0)
  |> with_tensor_gc
;;

let empty ~size ~options =
  stubs_empty
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let empty_like self = stubs_empty_like self |> with_tensor_gc
let empty_like_out ~out self = stubs_empty_like_out out self |> with_tensor_gc

let empty_out ~out ~size =
  stubs_empty_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let empty_permuted ~size ~physical_layout ~options =
  stubs_empty_permuted
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int physical_layout |> CArray.of_list int64_t |> CArray.start)
    (List.length physical_layout)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let empty_permuted_out ~out ~size ~physical_layout =
  stubs_empty_permuted_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int physical_layout |> CArray.of_list int64_t |> CArray.start)
    (List.length physical_layout)
  |> with_tensor_gc
;;

let empty_quantized ~size ~qtensor ~options =
  stubs_empty_quantized
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    qtensor
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let empty_quantized_out ~out ~size ~qtensor =
  stubs_empty_quantized_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    qtensor
  |> with_tensor_gc
;;

let empty_strided ~size ~stride ~options =
  stubs_empty_strided
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let empty_strided_out ~out ~size ~stride =
  stubs_empty_strided_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let eq self other = stubs_eq self other |> with_tensor_gc
let eq_ self other = stubs_eq_ self other |> with_tensor_gc
let eq_scalar_out ~out self other = stubs_eq_scalar_out out self other |> with_tensor_gc
let eq_tensor self other = stubs_eq_tensor self other |> with_tensor_gc
let eq_tensor_ self other = stubs_eq_tensor_ self other |> with_tensor_gc
let eq_tensor_out ~out self other = stubs_eq_tensor_out out self other |> with_tensor_gc
let equal self other = stubs_equal self other
let erf self = stubs_erf self |> with_tensor_gc
let erf_ self = stubs_erf_ self |> with_tensor_gc
let erf_out ~out self = stubs_erf_out out self |> with_tensor_gc
let erfc self = stubs_erfc self |> with_tensor_gc
let erfc_ self = stubs_erfc_ self |> with_tensor_gc
let erfc_out ~out self = stubs_erfc_out out self |> with_tensor_gc
let erfinv self = stubs_erfinv self |> with_tensor_gc
let erfinv_ self = stubs_erfinv_ self |> with_tensor_gc
let erfinv_out ~out self = stubs_erfinv_out out self |> with_tensor_gc
let exp self = stubs_exp self |> with_tensor_gc
let exp2 self = stubs_exp2 self |> with_tensor_gc
let exp2_ self = stubs_exp2_ self |> with_tensor_gc
let exp2_out ~out self = stubs_exp2_out out self |> with_tensor_gc
let exp_ self = stubs_exp_ self |> with_tensor_gc
let exp_out ~out self = stubs_exp_out out self |> with_tensor_gc

let expand self ~size ~implicit =
  stubs_expand
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (if implicit then 1 else 0)
  |> with_tensor_gc
;;

let expand_as self other = stubs_expand_as self other |> with_tensor_gc

let expand_copy self ~size ~implicit =
  stubs_expand_copy
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (if implicit then 1 else 0)
  |> with_tensor_gc
;;

let expand_copy_out ~out self ~size ~implicit =
  stubs_expand_copy_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (if implicit then 1 else 0)
  |> with_tensor_gc
;;

let expm1 self = stubs_expm1 self |> with_tensor_gc
let expm1_ self = stubs_expm1_ self |> with_tensor_gc
let expm1_out ~out self = stubs_expm1_out out self |> with_tensor_gc
let exponential self ~lambd = stubs_exponential self lambd |> with_tensor_gc
let exponential_ self ~lambd = stubs_exponential_ self lambd |> with_tensor_gc

let exponential_out ~out self ~lambd =
  stubs_exponential_out out self lambd |> with_tensor_gc
;;

let eye ~n ~options =
  stubs_eye
    (Int64.of_int n)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let eye_m ~n ~m ~options =
  stubs_eye_m
    (Int64.of_int n)
    (Int64.of_int m)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let eye_m_out ~out ~n ~m =
  stubs_eye_m_out out (Int64.of_int n) (Int64.of_int m) |> with_tensor_gc
;;

let eye_out ~out ~n = stubs_eye_out out (Int64.of_int n) |> with_tensor_gc

let fake_quantize_per_channel_affine self ~scale ~zero_point ~axis ~quant_min ~quant_max =
  stubs_fake_quantize_per_channel_affine
    self
    scale
    zero_point
    (Int64.of_int axis)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
  |> with_tensor_gc
;;

let fake_quantize_per_channel_affine_cachemask
  self
  ~scale
  ~zero_point
  ~axis
  ~quant_min
  ~quant_max
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fake_quantize_per_channel_affine_cachemask
    (CArray.start out__)
    self
    scale
    zero_point
    (Int64.of_int axis)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fake_quantize_per_channel_affine_cachemask_backward ~grad ~mask =
  stubs_fake_quantize_per_channel_affine_cachemask_backward grad mask |> with_tensor_gc
;;

let fake_quantize_per_channel_affine_cachemask_out
  ~out0
  ~out1
  self
  ~scale
  ~zero_point
  ~axis
  ~quant_min
  ~quant_max
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fake_quantize_per_channel_affine_cachemask_out
    (CArray.start out__)
    out0
    out1
    self
    scale
    zero_point
    (Int64.of_int axis)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fake_quantize_per_tensor_affine self ~scale ~zero_point ~quant_min ~quant_max =
  stubs_fake_quantize_per_tensor_affine
    self
    scale
    (Int64.of_int zero_point)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
  |> with_tensor_gc
;;

let fake_quantize_per_tensor_affine_cachemask
  self
  ~scale
  ~zero_point
  ~quant_min
  ~quant_max
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fake_quantize_per_tensor_affine_cachemask
    (CArray.start out__)
    self
    scale
    (Int64.of_int zero_point)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fake_quantize_per_tensor_affine_cachemask_backward ~grad ~mask =
  stubs_fake_quantize_per_tensor_affine_cachemask_backward grad mask |> with_tensor_gc
;;

let fake_quantize_per_tensor_affine_cachemask_out
  ~out0
  ~out1
  self
  ~scale
  ~zero_point
  ~quant_min
  ~quant_max
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fake_quantize_per_tensor_affine_cachemask_out
    (CArray.start out__)
    out0
    out1
    self
    scale
    (Int64.of_int zero_point)
    (Int64.of_int quant_min)
    (Int64.of_int quant_max);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fake_quantize_per_tensor_affine_tensor_qparams
  self
  ~scale
  ~zero_point
  ~quant_min
  ~quant_max
  =
  stubs_fake_quantize_per_tensor_affine_tensor_qparams
    self
    scale
    zero_point
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
  |> with_tensor_gc
;;

let fbgemm_linear_fp16_weight input ~packed_weight ~bias =
  stubs_fbgemm_linear_fp16_weight input packed_weight bias |> with_tensor_gc
;;

let fbgemm_linear_fp16_weight_fp32_activation input ~packed_weight ~bias =
  stubs_fbgemm_linear_fp16_weight_fp32_activation input packed_weight bias
  |> with_tensor_gc
;;

let fbgemm_linear_int8_weight
  input
  ~weight
  ~packed
  ~col_offsets
  ~weight_scale
  ~weight_zero_point
  ~bias
  =
  stubs_fbgemm_linear_int8_weight
    input
    weight
    packed
    col_offsets
    weight_scale
    weight_zero_point
    bias
  |> with_tensor_gc
;;

let fbgemm_linear_int8_weight_fp32_activation
  input
  ~weight
  ~packed
  ~col_offsets
  ~weight_scale
  ~weight_zero_point
  ~bias
  =
  stubs_fbgemm_linear_int8_weight_fp32_activation
    input
    weight
    packed
    col_offsets
    weight_scale
    weight_zero_point
    bias
  |> with_tensor_gc
;;

let fbgemm_pack_gemm_matrix_fp16 input =
  stubs_fbgemm_pack_gemm_matrix_fp16 input |> with_tensor_gc
;;

let fbgemm_pack_quantized_matrix input =
  stubs_fbgemm_pack_quantized_matrix input |> with_tensor_gc
;;

let fbgemm_pack_quantized_matrix_kn input ~k ~n =
  stubs_fbgemm_pack_quantized_matrix_kn input (Int64.of_int k) (Int64.of_int n)
  |> with_tensor_gc
;;

let feature_alpha_dropout input ~p ~train =
  stubs_feature_alpha_dropout input p (if train then 1 else 0) |> with_tensor_gc
;;

let feature_alpha_dropout_ self ~p ~train =
  stubs_feature_alpha_dropout_ self p (if train then 1 else 0) |> with_tensor_gc
;;

let feature_dropout input ~p ~train =
  stubs_feature_dropout input p (if train then 1 else 0) |> with_tensor_gc
;;

let feature_dropout_ self ~p ~train =
  stubs_feature_dropout_ self p (if train then 1 else 0) |> with_tensor_gc
;;

let fft_fft self ~n ~dim ~norm =
  stubs_fft_fft
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_fft2 self ~s ~dim ~norm =
  stubs_fft_fft2
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_fft2_out ~out self ~s ~dim ~norm =
  stubs_fft_fft2_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_fft_out ~out self ~n ~dim ~norm =
  stubs_fft_fft_out
    out
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_fftfreq ~n ~d ~options =
  stubs_fft_fftfreq
    (Int64.of_int n)
    d
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let fft_fftfreq_out ~out ~n ~d =
  stubs_fft_fftfreq_out out (Int64.of_int n) d |> with_tensor_gc
;;

let fft_fftn self ~s ~dim ~norm =
  stubs_fft_fftn
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_fftn_out ~out self ~s ~dim ~norm =
  stubs_fft_fftn_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_fftshift self ~dim =
  stubs_fft_fftshift
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let fft_hfft self ~n ~dim ~norm =
  stubs_fft_hfft
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_hfft2 self ~s ~dim ~norm =
  stubs_fft_hfft2
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_hfft2_out ~out self ~s ~dim ~norm =
  stubs_fft_hfft2_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_hfft_out ~out self ~n ~dim ~norm =
  stubs_fft_hfft_out
    out
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_hfftn self ~s ~dim ~norm =
  stubs_fft_hfftn
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_hfftn_out ~out self ~s ~dim ~norm =
  stubs_fft_hfftn_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifft self ~n ~dim ~norm =
  stubs_fft_ifft
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifft2 self ~s ~dim ~norm =
  stubs_fft_ifft2
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifft2_out ~out self ~s ~dim ~norm =
  stubs_fft_ifft2_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifft_out ~out self ~n ~dim ~norm =
  stubs_fft_ifft_out
    out
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifftn self ~s ~dim ~norm =
  stubs_fft_ifftn
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifftn_out ~out self ~s ~dim ~norm =
  stubs_fft_ifftn_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ifftshift self ~dim =
  stubs_fft_ifftshift
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let fft_ihfft self ~n ~dim ~norm =
  stubs_fft_ihfft
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ihfft2 self ~s ~dim ~norm =
  stubs_fft_ihfft2
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ihfft2_out ~out self ~s ~dim ~norm =
  stubs_fft_ihfft2_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ihfft_out ~out self ~n ~dim ~norm =
  stubs_fft_ihfft_out
    out
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ihfftn self ~s ~dim ~norm =
  stubs_fft_ihfftn
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_ihfftn_out ~out self ~s ~dim ~norm =
  stubs_fft_ihfftn_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_irfft self ~n ~dim ~norm =
  stubs_fft_irfft
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_irfft2 self ~s ~dim ~norm =
  stubs_fft_irfft2
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_irfft2_out ~out self ~s ~dim ~norm =
  stubs_fft_irfft2_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_irfft_out ~out self ~n ~dim ~norm =
  stubs_fft_irfft_out
    out
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_irfftn self ~s ~dim ~norm =
  stubs_fft_irfftn
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_irfftn_out ~out self ~s ~dim ~norm =
  stubs_fft_irfftn_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_rfft self ~n ~dim ~norm =
  stubs_fft_rfft
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_rfft2 self ~s ~dim ~norm =
  stubs_fft_rfft2
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_rfft2_out ~out self ~s ~dim ~norm =
  stubs_fft_rfft2_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_rfft_out ~out self ~n ~dim ~norm =
  stubs_fft_rfft_out
    out
    self
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int dim)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_rfftfreq ~n ~d ~options =
  stubs_fft_rfftfreq
    (Int64.of_int n)
    d
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let fft_rfftfreq_out ~out ~n ~d =
  stubs_fft_rfftfreq_out out (Int64.of_int n) d |> with_tensor_gc
;;

let fft_rfftn self ~s ~dim ~norm =
  stubs_fft_rfftn
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fft_rfftn_out ~out self ~s ~dim ~norm =
  stubs_fft_rfftn_out
    out
    self
    (match s with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match s with
     | None -> -1
     | Some v -> List.length v)
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (Option.value norm ~default:"")
    (match norm with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let fill self ~value = stubs_fill self value |> with_tensor_gc
let fill_ self ~value = stubs_fill_ self value |> with_tensor_gc

let fill_diagonal_ self ~fill_value ~wrap =
  stubs_fill_diagonal_ self fill_value (if wrap then 1 else 0) |> with_tensor_gc
;;

let fill_scalar_out ~out self ~value =
  stubs_fill_scalar_out out self value |> with_tensor_gc
;;

let fill_tensor self ~value = stubs_fill_tensor self value |> with_tensor_gc
let fill_tensor_ self ~value = stubs_fill_tensor_ self value |> with_tensor_gc

let fill_tensor_out ~out self ~value =
  stubs_fill_tensor_out out self value |> with_tensor_gc
;;

let fix self = stubs_fix self |> with_tensor_gc
let fix_ self = stubs_fix_ self |> with_tensor_gc
let fix_out ~out self = stubs_fix_out out self |> with_tensor_gc

let flatten self ~start_dim ~end_dim =
  stubs_flatten self (Int64.of_int start_dim) (Int64.of_int end_dim) |> with_tensor_gc
;;

let flatten_dense_tensors tensors =
  let result =
    stubs_flatten_dense_tensors
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let flip self ~dims =
  stubs_flip
    self
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let flip_out ~out self ~dims =
  stubs_flip_out
    out
    self
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let fliplr self = stubs_fliplr self |> with_tensor_gc
let flipud self = stubs_flipud self |> with_tensor_gc
let float_power self ~exponent = stubs_float_power self exponent |> with_tensor_gc
let float_power_ self ~exponent = stubs_float_power_ self exponent |> with_tensor_gc

let float_power_scalar self ~exponent =
  stubs_float_power_scalar self exponent |> with_tensor_gc
;;

let float_power_scalar_out ~out self ~exponent =
  stubs_float_power_scalar_out out self exponent |> with_tensor_gc
;;

let float_power_tensor_ self ~exponent =
  stubs_float_power_tensor_ self exponent |> with_tensor_gc
;;

let float_power_tensor_scalar self ~exponent =
  stubs_float_power_tensor_scalar self exponent |> with_tensor_gc
;;

let float_power_tensor_scalar_out ~out self ~exponent =
  stubs_float_power_tensor_scalar_out out self exponent |> with_tensor_gc
;;

let float_power_tensor_tensor_out ~out self ~exponent =
  stubs_float_power_tensor_tensor_out out self exponent |> with_tensor_gc
;;

let floor self = stubs_floor self |> with_tensor_gc
let floor_ self = stubs_floor_ self |> with_tensor_gc
let floor_divide self other = stubs_floor_divide self other |> with_tensor_gc
let floor_divide_ self other = stubs_floor_divide_ self other |> with_tensor_gc

let floor_divide_out ~out self other =
  stubs_floor_divide_out out self other |> with_tensor_gc
;;

let floor_divide_scalar self other =
  stubs_floor_divide_scalar self other |> with_tensor_gc
;;

let floor_divide_scalar_ self other =
  stubs_floor_divide_scalar_ self other |> with_tensor_gc
;;

let floor_divide_scalar_out ~out self other =
  stubs_floor_divide_scalar_out out self other |> with_tensor_gc
;;

let floor_out ~out self = stubs_floor_out out self |> with_tensor_gc
let fmax self other = stubs_fmax self other |> with_tensor_gc
let fmax_out ~out self other = stubs_fmax_out out self other |> with_tensor_gc
let fmin self other = stubs_fmin self other |> with_tensor_gc
let fmin_out ~out self other = stubs_fmin_out out self other |> with_tensor_gc
let fmod self other = stubs_fmod self other |> with_tensor_gc
let fmod_ self other = stubs_fmod_ self other |> with_tensor_gc

let fmod_scalar_out ~out self other =
  stubs_fmod_scalar_out out self other |> with_tensor_gc
;;

let fmod_tensor self other = stubs_fmod_tensor self other |> with_tensor_gc
let fmod_tensor_ self other = stubs_fmod_tensor_ self other |> with_tensor_gc

let fmod_tensor_out ~out self other =
  stubs_fmod_tensor_out out self other |> with_tensor_gc
;;

let frac self = stubs_frac self |> with_tensor_gc
let frac_ self = stubs_frac_ self |> with_tensor_gc
let frac_out ~out self = stubs_frac_out out self |> with_tensor_gc

let fractional_max_pool2d self ~kernel_size ~output_size ~random_samples =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fractional_max_pool2d
    (CArray.start out__)
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    random_samples;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fractional_max_pool2d_backward ~grad_output self ~kernel_size ~output_size ~indices =
  stubs_fractional_max_pool2d_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    indices
  |> with_tensor_gc
;;

let fractional_max_pool2d_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~kernel_size
  ~output_size
  ~indices
  =
  stubs_fractional_max_pool2d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    indices
  |> with_tensor_gc
;;

let fractional_max_pool2d_output
  ~output
  ~indices
  self
  ~kernel_size
  ~output_size
  ~random_samples
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fractional_max_pool2d_output
    (CArray.start out__)
    output
    indices
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    random_samples;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fractional_max_pool3d self ~kernel_size ~output_size ~random_samples =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fractional_max_pool3d
    (CArray.start out__)
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    random_samples;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let fractional_max_pool3d_backward ~grad_output self ~kernel_size ~output_size ~indices =
  stubs_fractional_max_pool3d_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    indices
  |> with_tensor_gc
;;

let fractional_max_pool3d_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~kernel_size
  ~output_size
  ~indices
  =
  stubs_fractional_max_pool3d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    indices
  |> with_tensor_gc
;;

let fractional_max_pool3d_output
  ~output
  ~indices
  self
  ~kernel_size
  ~output_size
  ~random_samples
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_fractional_max_pool3d_output
    (CArray.start out__)
    output
    indices
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    random_samples;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let frexp self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_frexp (CArray.start out__) self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let frexp_tensor_out ~mantissa ~exponent self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_frexp_tensor_out (CArray.start out__) mantissa exponent self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let frobenius_norm self ~dim ~keepdim =
  stubs_frobenius_norm
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let frobenius_norm_out ~out self ~dim ~keepdim =
  stubs_frobenius_norm_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let from_file ~filename ~shared ~size ~options =
  stubs_from_file
    filename
    (if shared then 1 else 0)
    (match size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match size with
     | Some _ -> 0
     | None -> 1)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let from_file_out ~out ~filename ~shared ~size =
  stubs_from_file_out
    out
    filename
    (if shared then 1 else 0)
    (match size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match size with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let full ~size ~fill_value ~options =
  stubs_full
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    fill_value
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let full_like self ~fill_value = stubs_full_like self fill_value |> with_tensor_gc

let full_like_out ~out self ~fill_value =
  stubs_full_like_out out self fill_value |> with_tensor_gc
;;

let full_out ~out ~size ~fill_value =
  stubs_full_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    fill_value
  |> with_tensor_gc
;;

let fused_moving_avg_obs_fake_quant
  self
  ~observer_on
  ~fake_quant_on
  ~running_min
  ~running_max
  ~scale
  ~zero_point
  ~averaging_const
  ~quant_min
  ~quant_max
  ~ch_axis
  ~per_row_fake_quant
  ~symmetric_quant
  =
  stubs_fused_moving_avg_obs_fake_quant
    self
    observer_on
    fake_quant_on
    running_min
    running_max
    scale
    zero_point
    averaging_const
    (Int64.of_int quant_min)
    (Int64.of_int quant_max)
    (Int64.of_int ch_axis)
    (if per_row_fake_quant then 1 else 0)
    (if symmetric_quant then 1 else 0)
  |> with_tensor_gc
;;

let gather self ~dim ~index ~sparse_grad =
  stubs_gather self (Int64.of_int dim) index (if sparse_grad then 1 else 0)
  |> with_tensor_gc
;;

let gather_backward ~grad self ~dim ~index ~sparse_grad =
  stubs_gather_backward grad self (Int64.of_int dim) index (if sparse_grad then 1 else 0)
  |> with_tensor_gc
;;

let gather_out ~out self ~dim ~index ~sparse_grad =
  stubs_gather_out out self (Int64.of_int dim) index (if sparse_grad then 1 else 0)
  |> with_tensor_gc
;;

let gcd self other = stubs_gcd self other |> with_tensor_gc
let gcd_ self other = stubs_gcd_ self other |> with_tensor_gc
let gcd_out ~out self other = stubs_gcd_out out self other |> with_tensor_gc
let ge self other = stubs_ge self other |> with_tensor_gc
let ge_ self other = stubs_ge_ self other |> with_tensor_gc
let ge_scalar_out ~out self other = stubs_ge_scalar_out out self other |> with_tensor_gc
let ge_tensor self other = stubs_ge_tensor self other |> with_tensor_gc
let ge_tensor_ self other = stubs_ge_tensor_ self other |> with_tensor_gc
let ge_tensor_out ~out self other = stubs_ge_tensor_out out self other |> with_tensor_gc
let gelu self ~approximate = stubs_gelu self approximate |> with_tensor_gc
let gelu_ self ~approximate = stubs_gelu_ self approximate |> with_tensor_gc

let gelu_backward ~grad_output self ~approximate =
  stubs_gelu_backward grad_output self approximate |> with_tensor_gc
;;

let gelu_backward_grad_input ~grad_input ~grad_output self ~approximate =
  stubs_gelu_backward_grad_input grad_input grad_output self approximate |> with_tensor_gc
;;

let gelu_out ~out self ~approximate =
  stubs_gelu_out out self approximate |> with_tensor_gc
;;

let geometric self ~p = stubs_geometric self p |> with_tensor_gc
let geometric_ self ~p = stubs_geometric_ self p |> with_tensor_gc
let geometric_out ~out self ~p = stubs_geometric_out out self p |> with_tensor_gc

let geqrf self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_geqrf (CArray.start out__) self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let geqrf_a ~a ~tau self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_geqrf_a (CArray.start out__) a tau self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let ger self ~vec2 = stubs_ger self vec2 |> with_tensor_gc
let ger_out ~out self ~vec2 = stubs_ger_out out self vec2 |> with_tensor_gc
let glu self ~dim = stubs_glu self (Int64.of_int dim) |> with_tensor_gc

let glu_backward ~grad_output self ~dim =
  stubs_glu_backward grad_output self (Int64.of_int dim) |> with_tensor_gc
;;

let glu_backward_grad_input ~grad_input ~grad_output self ~dim =
  stubs_glu_backward_grad_input grad_input grad_output self (Int64.of_int dim)
  |> with_tensor_gc
;;

let glu_backward_jvp ~grad_x ~grad_glu ~x ~dgrad_glu ~dx ~dim =
  stubs_glu_backward_jvp grad_x grad_glu x dgrad_glu dx (Int64.of_int dim)
  |> with_tensor_gc
;;

let glu_backward_jvp_out ~out ~grad_x ~grad_glu ~x ~dgrad_glu ~dx ~dim =
  stubs_glu_backward_jvp_out out grad_x grad_glu x dgrad_glu dx (Int64.of_int dim)
  |> with_tensor_gc
;;

let glu_jvp ~glu ~x ~dx ~dim = stubs_glu_jvp glu x dx (Int64.of_int dim) |> with_tensor_gc

let glu_jvp_out ~out ~glu ~x ~dx ~dim =
  stubs_glu_jvp_out out glu x dx (Int64.of_int dim) |> with_tensor_gc
;;

let glu_out ~out self ~dim = stubs_glu_out out self (Int64.of_int dim) |> with_tensor_gc
let grad self = stubs_grad self |> with_tensor_gc
let greater self other = stubs_greater self other |> with_tensor_gc
let greater_ self other = stubs_greater_ self other |> with_tensor_gc
let greater_equal self other = stubs_greater_equal self other |> with_tensor_gc
let greater_equal_ self other = stubs_greater_equal_ self other |> with_tensor_gc

let greater_equal_scalar_out ~out self other =
  stubs_greater_equal_scalar_out out self other |> with_tensor_gc
;;

let greater_equal_tensor self other =
  stubs_greater_equal_tensor self other |> with_tensor_gc
;;

let greater_equal_tensor_ self other =
  stubs_greater_equal_tensor_ self other |> with_tensor_gc
;;

let greater_equal_tensor_out ~out self other =
  stubs_greater_equal_tensor_out out self other |> with_tensor_gc
;;

let greater_scalar_out ~out self other =
  stubs_greater_scalar_out out self other |> with_tensor_gc
;;

let greater_tensor self other = stubs_greater_tensor self other |> with_tensor_gc
let greater_tensor_ self other = stubs_greater_tensor_ self other |> with_tensor_gc

let greater_tensor_out ~out self other =
  stubs_greater_tensor_out out self other |> with_tensor_gc
;;

let grid_sampler input ~grid ~interpolation_mode ~padding_mode ~align_corners =
  stubs_grid_sampler
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let grid_sampler_2d input ~grid ~interpolation_mode ~padding_mode ~align_corners =
  stubs_grid_sampler_2d
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let grid_sampler_2d_out ~out input ~grid ~interpolation_mode ~padding_mode ~align_corners =
  stubs_grid_sampler_2d_out
    out
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let grid_sampler_3d input ~grid ~interpolation_mode ~padding_mode ~align_corners =
  stubs_grid_sampler_3d
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let grid_sampler_3d_out ~out input ~grid ~interpolation_mode ~padding_mode ~align_corners =
  stubs_grid_sampler_3d_out
    out
    input
    grid
    (Int64.of_int interpolation_mode)
    (Int64.of_int padding_mode)
    (if align_corners then 1 else 0)
  |> with_tensor_gc
;;

let group_norm input ~num_groups ~weight ~bias ~eps ~cudnn_enabled =
  stubs_group_norm
    input
    (Int64.of_int num_groups)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    eps
    (if cudnn_enabled then 1 else 0)
  |> with_tensor_gc
;;

let gru
  input
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_gru
    (CArray.start out__)
    input
    hx
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive params;
  t0, t1
;;

let gru_cell input ~hx ~w_ih ~w_hh ~b_ih ~b_hh =
  stubs_gru_cell
    input
    hx
    w_ih
    w_hh
    (match b_ih with
     | Some v -> v
     | None -> none_gc_tensor)
    (match b_hh with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let gru_data
  ~data
  ~batch_sizes
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_gru_data
    (CArray.start out__)
    data
    batch_sizes
    hx
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive params;
  t0, t1
;;

let gt self other = stubs_gt self other |> with_tensor_gc
let gt_ self other = stubs_gt_ self other |> with_tensor_gc
let gt_scalar_out ~out self other = stubs_gt_scalar_out out self other |> with_tensor_gc
let gt_tensor self other = stubs_gt_tensor self other |> with_tensor_gc
let gt_tensor_ self other = stubs_gt_tensor_ self other |> with_tensor_gc
let gt_tensor_out ~out self other = stubs_gt_tensor_out out self other |> with_tensor_gc

let hamming_window ~window_length ~options =
  stubs_hamming_window
    (Int64.of_int window_length)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let hamming_window_out ~out ~window_length =
  stubs_hamming_window_out out (Int64.of_int window_length) |> with_tensor_gc
;;

let hamming_window_periodic ~window_length ~periodic ~options =
  stubs_hamming_window_periodic
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let hamming_window_periodic_alpha ~window_length ~periodic ~alpha ~options =
  stubs_hamming_window_periodic_alpha
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    alpha
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let hamming_window_periodic_alpha_beta ~window_length ~periodic ~alpha ~beta ~options =
  stubs_hamming_window_periodic_alpha_beta
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    alpha
    beta
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let hamming_window_periodic_alpha_beta_out ~out ~window_length ~periodic ~alpha ~beta =
  stubs_hamming_window_periodic_alpha_beta_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    alpha
    beta
  |> with_tensor_gc
;;

let hamming_window_periodic_alpha_out ~out ~window_length ~periodic ~alpha =
  stubs_hamming_window_periodic_alpha_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    alpha
  |> with_tensor_gc
;;

let hamming_window_periodic_out ~out ~window_length ~periodic =
  stubs_hamming_window_periodic_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
  |> with_tensor_gc
;;

let hann_window ~window_length ~options =
  stubs_hann_window
    (Int64.of_int window_length)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let hann_window_out ~out ~window_length =
  stubs_hann_window_out out (Int64.of_int window_length) |> with_tensor_gc
;;

let hann_window_periodic ~window_length ~periodic ~options =
  stubs_hann_window_periodic
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let hann_window_periodic_out ~out ~window_length ~periodic =
  stubs_hann_window_periodic_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
  |> with_tensor_gc
;;

let hardshrink ?lambd self =
  stubs_hardshrink
    self
    (match lambd with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let hardshrink_backward ~grad_out self ~lambd =
  stubs_hardshrink_backward grad_out self lambd |> with_tensor_gc
;;

let hardshrink_backward_grad_input ~grad_input ~grad_out self ~lambd =
  stubs_hardshrink_backward_grad_input grad_input grad_out self lambd |> with_tensor_gc
;;

let hardshrink_out ?lambd ~out self =
  stubs_hardshrink_out
    out
    self
    (match lambd with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let hardsigmoid self = stubs_hardsigmoid self |> with_tensor_gc
let hardsigmoid_ self = stubs_hardsigmoid_ self |> with_tensor_gc

let hardsigmoid_backward ~grad_output self =
  stubs_hardsigmoid_backward grad_output self |> with_tensor_gc
;;

let hardsigmoid_backward_grad_input ~grad_input ~grad_output self =
  stubs_hardsigmoid_backward_grad_input grad_input grad_output self |> with_tensor_gc
;;

let hardsigmoid_out ~out self = stubs_hardsigmoid_out out self |> with_tensor_gc
let hardswish self = stubs_hardswish self |> with_tensor_gc
let hardswish_ self = stubs_hardswish_ self |> with_tensor_gc

let hardswish_backward ~grad_output self =
  stubs_hardswish_backward grad_output self |> with_tensor_gc
;;

let hardswish_backward_out ~out ~grad_output self =
  stubs_hardswish_backward_out out grad_output self |> with_tensor_gc
;;

let hardswish_out ~out self = stubs_hardswish_out out self |> with_tensor_gc

let hardtanh ?min_val ?max_val self =
  stubs_hardtanh
    self
    (match min_val with
     | Some v -> v
     | None -> none_scalar)
    (match max_val with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let hardtanh_ ?min_val ?max_val self =
  stubs_hardtanh_
    self
    (match min_val with
     | Some v -> v
     | None -> none_scalar)
    (match max_val with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let hardtanh_backward ~grad_output self ~min_val ~max_val =
  stubs_hardtanh_backward grad_output self min_val max_val |> with_tensor_gc
;;

let hardtanh_backward_grad_input ~grad_input ~grad_output self ~min_val ~max_val =
  stubs_hardtanh_backward_grad_input grad_input grad_output self min_val max_val
  |> with_tensor_gc
;;

let hardtanh_out ?min_val ?max_val ~out self =
  stubs_hardtanh_out
    out
    self
    (match min_val with
     | Some v -> v
     | None -> none_scalar)
    (match max_val with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let heaviside self ~values = stubs_heaviside self values |> with_tensor_gc
let heaviside_ self ~values = stubs_heaviside_ self values |> with_tensor_gc

let heaviside_out ~out self ~values =
  stubs_heaviside_out out self values |> with_tensor_gc
;;

let hinge_embedding_loss self ~target ~margin ~reduction =
  stubs_hinge_embedding_loss
    self
    target
    margin
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let histc ?min ?max self ~bins =
  stubs_histc
    self
    (Int64.of_int bins)
    (match min with
     | Some v -> v
     | None -> none_scalar)
    (match max with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let histc_out ?min ?max ~out self ~bins =
  stubs_histc_out
    out
    self
    (Int64.of_int bins)
    (match min with
     | Some v -> v
     | None -> none_scalar)
    (match max with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let hsplit self ~sections = stubs_hsplit self (Int64.of_int sections) |> to_tensor_list

let hsplit_array self ~indices =
  stubs_hsplit_array
    self
    (List.map Int64.of_int indices |> CArray.of_list int64_t |> CArray.start)
    (List.length indices)
  |> to_tensor_list
;;

let hspmm ~mat1 ~mat2 = stubs_hspmm mat1 mat2 |> with_tensor_gc
let hspmm_out ~out ~mat1 ~mat2 = stubs_hspmm_out out mat1 mat2 |> with_tensor_gc

let hstack tensors =
  let result =
    stubs_hstack (CArray.of_list gc_tensor tensors |> CArray.start) (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let hstack_out ~out tensors =
  let result =
    stubs_hstack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let huber_loss self ~target ~reduction ~delta =
  stubs_huber_loss self target (Reduction.to_int reduction |> Int64.of_int) delta
  |> with_tensor_gc
;;

let huber_loss_backward ~grad_output self ~target ~reduction ~delta =
  stubs_huber_loss_backward
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    delta
  |> with_tensor_gc
;;

let huber_loss_backward_out ~grad_input ~grad_output self ~target ~reduction ~delta =
  stubs_huber_loss_backward_out
    grad_input
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    delta
  |> with_tensor_gc
;;

let huber_loss_out ~out self ~target ~reduction ~delta =
  stubs_huber_loss_out out self target (Reduction.to_int reduction |> Int64.of_int) delta
  |> with_tensor_gc
;;

let hypot self other = stubs_hypot self other |> with_tensor_gc
let hypot_ self other = stubs_hypot_ self other |> with_tensor_gc
let hypot_out ~out self other = stubs_hypot_out out self other |> with_tensor_gc
let i0 self = stubs_i0 self |> with_tensor_gc
let i0_ self = stubs_i0_ self |> with_tensor_gc
let i0_out ~out self = stubs_i0_out out self |> with_tensor_gc
let igamma self other = stubs_igamma self other |> with_tensor_gc
let igamma_ self other = stubs_igamma_ self other |> with_tensor_gc
let igamma_out ~out self other = stubs_igamma_out out self other |> with_tensor_gc
let igammac self other = stubs_igammac self other |> with_tensor_gc
let igammac_ self other = stubs_igammac_ self other |> with_tensor_gc
let igammac_out ~out self other = stubs_igammac_out out self other |> with_tensor_gc

let im2col self ~kernel_size ~dilation ~padding ~stride =
  stubs_im2col
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let im2col_out ~out self ~kernel_size ~dilation ~padding ~stride =
  stubs_im2col_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let imag self = stubs_imag self |> with_tensor_gc

let index_add ?alpha self ~dim ~index ~source =
  stubs_index_add
    self
    (Int64.of_int dim)
    index
    source
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let index_add_ ?alpha self ~dim ~index ~source =
  stubs_index_add_
    self
    (Int64.of_int dim)
    index
    source
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let index_add_out ?alpha ~out self ~dim ~index ~source =
  stubs_index_add_out
    out
    self
    (Int64.of_int dim)
    index
    source
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let index_copy self ~dim ~index ~source =
  stubs_index_copy self (Int64.of_int dim) index source |> with_tensor_gc
;;

let index_copy_ self ~dim ~index ~source =
  stubs_index_copy_ self (Int64.of_int dim) index source |> with_tensor_gc
;;

let index_copy_out ~out self ~dim ~index ~source =
  stubs_index_copy_out out self (Int64.of_int dim) index source |> with_tensor_gc
;;

let index_fill self ~dim ~index ~value =
  stubs_index_fill self (Int64.of_int dim) index value |> with_tensor_gc
;;

let index_fill_ self ~dim ~index ~value =
  stubs_index_fill_ self (Int64.of_int dim) index value |> with_tensor_gc
;;

let index_fill_int_scalar_out ~out self ~dim ~index ~value =
  stubs_index_fill_int_scalar_out out self (Int64.of_int dim) index value
  |> with_tensor_gc
;;

let index_fill_int_tensor self ~dim ~index ~value =
  stubs_index_fill_int_tensor self (Int64.of_int dim) index value |> with_tensor_gc
;;

let index_fill_int_tensor_ self ~dim ~index ~value =
  stubs_index_fill_int_tensor_ self (Int64.of_int dim) index value |> with_tensor_gc
;;

let index_fill_int_tensor_out ~out self ~dim ~index ~value =
  stubs_index_fill_int_tensor_out out self (Int64.of_int dim) index value
  |> with_tensor_gc
;;

let index_reduce self ~dim ~index ~source ~reduce ~include_self =
  stubs_index_reduce
    self
    (Int64.of_int dim)
    index
    source
    reduce
    (if include_self then 1 else 0)
  |> with_tensor_gc
;;

let index_reduce_ self ~dim ~index ~source ~reduce ~include_self =
  stubs_index_reduce_
    self
    (Int64.of_int dim)
    index
    source
    reduce
    (if include_self then 1 else 0)
  |> with_tensor_gc
;;

let index_reduce_out ~out self ~dim ~index ~source ~reduce ~include_self =
  stubs_index_reduce_out
    out
    self
    (Int64.of_int dim)
    index
    source
    reduce
    (if include_self then 1 else 0)
  |> with_tensor_gc
;;

let index_select self ~dim ~index =
  stubs_index_select self (Int64.of_int dim) index |> with_tensor_gc
;;

let index_select_backward ~grad ~self_sizes ~dim ~index =
  stubs_index_select_backward
    grad
    (List.map Int64.of_int self_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length self_sizes)
    (Int64.of_int dim)
    index
  |> with_tensor_gc
;;

let index_select_out ~out self ~dim ~index =
  stubs_index_select_out out self (Int64.of_int dim) index |> with_tensor_gc
;;

let indices self = stubs_indices self |> with_tensor_gc
let indices_copy self = stubs_indices_copy self |> with_tensor_gc
let indices_copy_out ~out self = stubs_indices_copy_out out self |> with_tensor_gc

let infinitely_differentiable_gelu_backward ~grad self =
  stubs_infinitely_differentiable_gelu_backward grad self |> with_tensor_gc
;;

let inner self other = stubs_inner self other |> with_tensor_gc
let inner_out ~out self other = stubs_inner_out out self other |> with_tensor_gc

let instance_norm
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~use_input_stats
  ~momentum
  ~eps
  ~cudnn_enabled
  =
  stubs_instance_norm
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if use_input_stats then 1 else 0)
    momentum
    eps
    (if cudnn_enabled then 1 else 0)
  |> with_tensor_gc
;;

let int_repr self = stubs_int_repr self |> with_tensor_gc
let int_repr_out ~out self = stubs_int_repr_out out self |> with_tensor_gc
let inverse self = stubs_inverse self |> with_tensor_gc
let inverse_out ~out self = stubs_inverse_out out self |> with_tensor_gc
let is_coalesced self = stubs_is_coalesced self
let is_complex self = stubs_is_complex self
let is_conj self = stubs_is_conj self
let is_distributed self = stubs_is_distributed self
let is_floating_point self = stubs_is_floating_point self
let is_inference self = stubs_is_inference self
let is_leaf self = stubs_is_leaf self
let is_neg self = stubs_is_neg self
let is_nonzero self = stubs_is_nonzero self
let is_pinned self ~device = stubs_is_pinned self (Device.option_to_int device)
let is_same_size self other = stubs_is_same_size self other
let is_set_to self tensor = stubs_is_set_to self tensor
let is_signed self = stubs_is_signed self
let is_vulkan_available = stubs_is_vulkan_available

let isclose self other ~rtol ~atol ~equal_nan =
  stubs_isclose self other rtol atol (if equal_nan then 1 else 0) |> with_tensor_gc
;;

let isfinite self = stubs_isfinite self |> with_tensor_gc

let isin ~elements ~test_elements ~assume_unique ~invert =
  stubs_isin
    elements
    test_elements
    (if assume_unique then 1 else 0)
    (if invert then 1 else 0)
  |> with_tensor_gc
;;

let isin_scalar_tensor ~element ~test_elements ~assume_unique ~invert =
  stubs_isin_scalar_tensor
    element
    test_elements
    (if assume_unique then 1 else 0)
    (if invert then 1 else 0)
  |> with_tensor_gc
;;

let isin_scalar_tensor_out ~out ~element ~test_elements ~assume_unique ~invert =
  stubs_isin_scalar_tensor_out
    out
    element
    test_elements
    (if assume_unique then 1 else 0)
    (if invert then 1 else 0)
  |> with_tensor_gc
;;

let isin_tensor_scalar ~elements ~test_element ~assume_unique ~invert =
  stubs_isin_tensor_scalar
    elements
    test_element
    (if assume_unique then 1 else 0)
    (if invert then 1 else 0)
  |> with_tensor_gc
;;

let isin_tensor_scalar_out ~out ~elements ~test_element ~assume_unique ~invert =
  stubs_isin_tensor_scalar_out
    out
    elements
    test_element
    (if assume_unique then 1 else 0)
    (if invert then 1 else 0)
  |> with_tensor_gc
;;

let isin_tensor_tensor_out ~out ~elements ~test_elements ~assume_unique ~invert =
  stubs_isin_tensor_tensor_out
    out
    elements
    test_elements
    (if assume_unique then 1 else 0)
    (if invert then 1 else 0)
  |> with_tensor_gc
;;

let isinf self = stubs_isinf self |> with_tensor_gc
let isinf_out ~out self = stubs_isinf_out out self |> with_tensor_gc
let isnan self = stubs_isnan self |> with_tensor_gc
let isnan_out ~out self = stubs_isnan_out out self |> with_tensor_gc
let isneginf self = stubs_isneginf self |> with_tensor_gc
let isneginf_out ~out self = stubs_isneginf_out out self |> with_tensor_gc
let isposinf self = stubs_isposinf self |> with_tensor_gc
let isposinf_out ~out self = stubs_isposinf_out out self |> with_tensor_gc
let isreal self = stubs_isreal self |> with_tensor_gc

let istft
  self
  ~n_fft
  ~hop_length
  ~win_length
  ~window
  ~center
  ~normalized
  ~onesided
  ~length
  ~return_complex
  =
  stubs_istft
    self
    (Int64.of_int n_fft)
    (match hop_length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match hop_length with
     | Some _ -> 0
     | None -> 1)
    (match win_length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match win_length with
     | Some _ -> 0
     | None -> 1)
    (match window with
     | Some v -> v
     | None -> none_gc_tensor)
    (if center then 1 else 0)
    (if normalized then 1 else 0)
    (if onesided then 1 else 0)
    (match length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match length with
     | Some _ -> 0
     | None -> 1)
    (if return_complex then 1 else 0)
  |> with_tensor_gc
;;

let kaiser_window ~window_length ~options =
  stubs_kaiser_window
    (Int64.of_int window_length)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let kaiser_window_beta ~window_length ~periodic ~beta ~options =
  stubs_kaiser_window_beta
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    beta
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let kaiser_window_beta_out ~out ~window_length ~periodic ~beta =
  stubs_kaiser_window_beta_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    beta
  |> with_tensor_gc
;;

let kaiser_window_out ~out ~window_length =
  stubs_kaiser_window_out out (Int64.of_int window_length) |> with_tensor_gc
;;

let kaiser_window_periodic ~window_length ~periodic ~options =
  stubs_kaiser_window_periodic
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let kaiser_window_periodic_out ~out ~window_length ~periodic =
  stubs_kaiser_window_periodic_out
    out
    (Int64.of_int window_length)
    (if periodic then 1 else 0)
  |> with_tensor_gc
;;

let kl_div self ~target ~reduction ~log_target =
  stubs_kl_div
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    (if log_target then 1 else 0)
  |> with_tensor_gc
;;

let kron self other = stubs_kron self other |> with_tensor_gc
let kron_out ~out self other = stubs_kron_out out self other |> with_tensor_gc

let kthvalue self ~k ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_kthvalue
    (CArray.start out__)
    self
    (Int64.of_int k)
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let kthvalue_values ~values ~indices self ~k ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_kthvalue_values
    (CArray.start out__)
    values
    indices
    self
    (Int64.of_int k)
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let l1_loss self ~target ~reduction =
  stubs_l1_loss self target (Reduction.to_int reduction |> Int64.of_int) |> with_tensor_gc
;;

let layer_norm input ~normalized_shape ~weight ~bias ~eps ~cudnn_enable =
  stubs_layer_norm
    input
    (List.map Int64.of_int normalized_shape |> CArray.of_list int64_t |> CArray.start)
    (List.length normalized_shape)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    eps
    (if cudnn_enable then 1 else 0)
  |> with_tensor_gc
;;

let lcm self other = stubs_lcm self other |> with_tensor_gc
let lcm_ self other = stubs_lcm_ self other |> with_tensor_gc
let lcm_out ~out self other = stubs_lcm_out out self other |> with_tensor_gc
let ldexp self other = stubs_ldexp self other |> with_tensor_gc
let ldexp_ self other = stubs_ldexp_ self other |> with_tensor_gc
let ldexp_out ~out self other = stubs_ldexp_out out self other |> with_tensor_gc
let le self other = stubs_le self other |> with_tensor_gc
let le_ self other = stubs_le_ self other |> with_tensor_gc
let le_scalar_out ~out self other = stubs_le_scalar_out out self other |> with_tensor_gc
let le_tensor self other = stubs_le_tensor self other |> with_tensor_gc
let le_tensor_ self other = stubs_le_tensor_ self other |> with_tensor_gc
let le_tensor_out ~out self other = stubs_le_tensor_out out self other |> with_tensor_gc

let leaky_relu ?negative_slope self =
  stubs_leaky_relu
    self
    (match negative_slope with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let leaky_relu_ ?negative_slope self =
  stubs_leaky_relu_
    self
    (match negative_slope with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let leaky_relu_backward ~grad_output self ~negative_slope ~self_is_result =
  stubs_leaky_relu_backward
    grad_output
    self
    negative_slope
    (if self_is_result then 1 else 0)
  |> with_tensor_gc
;;

let leaky_relu_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~negative_slope
  ~self_is_result
  =
  stubs_leaky_relu_backward_grad_input
    grad_input
    grad_output
    self
    negative_slope
    (if self_is_result then 1 else 0)
  |> with_tensor_gc
;;

let leaky_relu_out ?negative_slope ~out self =
  stubs_leaky_relu_out
    out
    self
    (match negative_slope with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let lerp self ~end_ ~weight = stubs_lerp self end_ weight |> with_tensor_gc
let lerp_ self ~end_ ~weight = stubs_lerp_ self end_ weight |> with_tensor_gc

let lerp_scalar_out ~out self ~end_ ~weight =
  stubs_lerp_scalar_out out self end_ weight |> with_tensor_gc
;;

let lerp_tensor self ~end_ ~weight = stubs_lerp_tensor self end_ weight |> with_tensor_gc

let lerp_tensor_ self ~end_ ~weight =
  stubs_lerp_tensor_ self end_ weight |> with_tensor_gc
;;

let lerp_tensor_out ~out self ~end_ ~weight =
  stubs_lerp_tensor_out out self end_ weight |> with_tensor_gc
;;

let less self other = stubs_less self other |> with_tensor_gc
let less_ self other = stubs_less_ self other |> with_tensor_gc
let less_equal self other = stubs_less_equal self other |> with_tensor_gc
let less_equal_ self other = stubs_less_equal_ self other |> with_tensor_gc

let less_equal_scalar_out ~out self other =
  stubs_less_equal_scalar_out out self other |> with_tensor_gc
;;

let less_equal_tensor self other = stubs_less_equal_tensor self other |> with_tensor_gc
let less_equal_tensor_ self other = stubs_less_equal_tensor_ self other |> with_tensor_gc

let less_equal_tensor_out ~out self other =
  stubs_less_equal_tensor_out out self other |> with_tensor_gc
;;

let less_scalar_out ~out self other =
  stubs_less_scalar_out out self other |> with_tensor_gc
;;

let less_tensor self other = stubs_less_tensor self other |> with_tensor_gc
let less_tensor_ self other = stubs_less_tensor_ self other |> with_tensor_gc

let less_tensor_out ~out self other =
  stubs_less_tensor_out out self other |> with_tensor_gc
;;

let lgamma self = stubs_lgamma self |> with_tensor_gc
let lgamma_ self = stubs_lgamma_ self |> with_tensor_gc
let lgamma_out ~out self = stubs_lgamma_out out self |> with_tensor_gc
let lift self = stubs_lift self |> with_tensor_gc
let lift_fresh self = stubs_lift_fresh self |> with_tensor_gc
let lift_fresh_copy self = stubs_lift_fresh_copy self |> with_tensor_gc
let lift_fresh_copy_out ~out self = stubs_lift_fresh_copy_out out self |> with_tensor_gc
let lift_out ~out self = stubs_lift_out out self |> with_tensor_gc

let linalg_cholesky self ~upper =
  stubs_linalg_cholesky self (if upper then 1 else 0) |> with_tensor_gc
;;

let linalg_cholesky_ex self ~upper ~check_errors =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_cholesky_ex
    (CArray.start out__)
    self
    (if upper then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_cholesky_ex_l ~l ~info self ~upper ~check_errors =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_cholesky_ex_l
    (CArray.start out__)
    l
    info
    self
    (if upper then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_cholesky_out ~out self ~upper =
  stubs_linalg_cholesky_out out self (if upper then 1 else 0) |> with_tensor_gc
;;

let linalg_cond self ~p = stubs_linalg_cond self p |> with_tensor_gc
let linalg_cond_out ~out self ~p = stubs_linalg_cond_out out self p |> with_tensor_gc
let linalg_cond_p_str self ~p = stubs_linalg_cond_p_str self p |> with_tensor_gc

let linalg_cond_p_str_out ~out self ~p =
  stubs_linalg_cond_p_str_out out self p |> with_tensor_gc
;;

let linalg_cross self other ~dim =
  stubs_linalg_cross self other (Int64.of_int dim) |> with_tensor_gc
;;

let linalg_cross_out ~out self other ~dim =
  stubs_linalg_cross_out out self other (Int64.of_int dim) |> with_tensor_gc
;;

let linalg_det ~a = stubs_linalg_det a |> with_tensor_gc
let linalg_det_out ~out ~a = stubs_linalg_det_out out a |> with_tensor_gc

let linalg_diagonal ~a ~offset ~dim1 ~dim2 =
  stubs_linalg_diagonal a (Int64.of_int offset) (Int64.of_int dim1) (Int64.of_int dim2)
  |> with_tensor_gc
;;

let linalg_eig self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_eig (CArray.start out__) self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_eig_out ~eigenvalues ~eigenvectors self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_eig_out (CArray.start out__) eigenvalues eigenvectors self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_eigh self ~uplo =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_eigh (CArray.start out__) self uplo;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_eigh_eigvals ~eigvals ~eigvecs self ~uplo =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_eigh_eigvals (CArray.start out__) eigvals eigvecs self uplo;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_eigvals self = stubs_linalg_eigvals self |> with_tensor_gc
let linalg_eigvals_out ~out self = stubs_linalg_eigvals_out out self |> with_tensor_gc
let linalg_eigvalsh self ~uplo = stubs_linalg_eigvalsh self uplo |> with_tensor_gc

let linalg_eigvalsh_out ~out self ~uplo =
  stubs_linalg_eigvalsh_out out self uplo |> with_tensor_gc
;;

let linalg_householder_product input ~tau =
  stubs_linalg_householder_product input tau |> with_tensor_gc
;;

let linalg_householder_product_out ~out input ~tau =
  stubs_linalg_householder_product_out out input tau |> with_tensor_gc
;;

let linalg_inv ~a = stubs_linalg_inv a |> with_tensor_gc

let linalg_inv_ex ~a ~check_errors =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_inv_ex (CArray.start out__) a (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_inv_ex_inverse ~inverse ~info ~a ~check_errors =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_inv_ex_inverse
    (CArray.start out__)
    inverse
    info
    a
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_inv_out ~out ~a = stubs_linalg_inv_out out a |> with_tensor_gc

let linalg_ldl_factor self ~hermitian =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_ldl_factor (CArray.start out__) self (if hermitian then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_ldl_factor_ex self ~hermitian ~check_errors =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_ldl_factor_ex
    (CArray.start out__)
    self
    (if hermitian then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_ldl_factor_ex_out ~ld ~pivots ~info self ~hermitian ~check_errors =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_ldl_factor_ex_out
    (CArray.start out__)
    ld
    pivots
    info
    self
    (if hermitian then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_ldl_factor_out ~ld ~pivots self ~hermitian =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_ldl_factor_out
    (CArray.start out__)
    ld
    pivots
    self
    (if hermitian then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_ldl_solve ~ld ~pivots ~b ~hermitian =
  stubs_linalg_ldl_solve ld pivots b (if hermitian then 1 else 0) |> with_tensor_gc
;;

let linalg_ldl_solve_out ~out ~ld ~pivots ~b ~hermitian =
  stubs_linalg_ldl_solve_out out ld pivots b (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_lstsq self ~b ~rcond ~driver =
  let out__ = CArray.make raw_tensor 4 in
  stubs_linalg_lstsq
    (CArray.start out__)
    self
    b
    (Option.value rcond ~default:0.0)
    (match rcond with
     | Some _ -> 0
     | None -> 1)
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let linalg_lstsq_out ~solution ~residuals ~rank ~singular_values self ~b ~rcond ~driver =
  let out__ = CArray.make raw_tensor 4 in
  stubs_linalg_lstsq_out
    (CArray.start out__)
    solution
    residuals
    rank
    singular_values
    self
    b
    (Option.value rcond ~default:0.0)
    (match rcond with
     | Some _ -> 0
     | None -> 1)
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let linalg_lu ~a ~pivot =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_lu (CArray.start out__) a (if pivot then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_lu_factor ~a ~pivot =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_lu_factor (CArray.start out__) a (if pivot then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_lu_factor_ex ~a ~pivot ~check_errors =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_lu_factor_ex
    (CArray.start out__)
    a
    (if pivot then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_lu_factor_ex_out ~lu ~pivots ~info ~a ~pivot ~check_errors =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_lu_factor_ex_out
    (CArray.start out__)
    lu
    pivots
    info
    a
    (if pivot then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_lu_factor_out ~lu ~pivots ~a ~pivot =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_lu_factor_out (CArray.start out__) lu pivots a (if pivot then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_lu_out ~p ~l ~u ~a ~pivot =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_lu_out (CArray.start out__) p l u a (if pivot then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_lu_solve ~lu ~pivots ~b ~left ~adjoint =
  stubs_linalg_lu_solve lu pivots b (if left then 1 else 0) (if adjoint then 1 else 0)
  |> with_tensor_gc
;;

let linalg_lu_solve_out ~out ~lu ~pivots ~b ~left ~adjoint =
  stubs_linalg_lu_solve_out
    out
    lu
    pivots
    b
    (if left then 1 else 0)
    (if adjoint then 1 else 0)
  |> with_tensor_gc
;;

let linalg_matmul self other = stubs_linalg_matmul self other |> with_tensor_gc

let linalg_matmul_out ~out self other =
  stubs_linalg_matmul_out out self other |> with_tensor_gc
;;

let linalg_matrix_exp self = stubs_linalg_matrix_exp self |> with_tensor_gc

let linalg_matrix_exp_out ~out self =
  stubs_linalg_matrix_exp_out out self |> with_tensor_gc
;;

let linalg_matrix_power self ~n =
  stubs_linalg_matrix_power self (Int64.of_int n) |> with_tensor_gc
;;

let linalg_matrix_power_out ~out self ~n =
  stubs_linalg_matrix_power_out out self (Int64.of_int n) |> with_tensor_gc
;;

let linalg_matrix_rank self ~tol ~hermitian =
  stubs_linalg_matrix_rank self tol (if hermitian then 1 else 0) |> with_tensor_gc
;;

let linalg_matrix_rank_atol_rtol_float self ~atol ~rtol ~hermitian =
  stubs_linalg_matrix_rank_atol_rtol_float
    self
    (Option.value atol ~default:0.0)
    (match atol with
     | Some _ -> 0
     | None -> 1)
    (Option.value rtol ~default:0.0)
    (match rtol with
     | Some _ -> 0
     | None -> 1)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_matrix_rank_atol_rtol_float_out ~out self ~atol ~rtol ~hermitian =
  stubs_linalg_matrix_rank_atol_rtol_float_out
    out
    self
    (Option.value atol ~default:0.0)
    (match atol with
     | Some _ -> 0
     | None -> 1)
    (Option.value rtol ~default:0.0)
    (match rtol with
     | Some _ -> 0
     | None -> 1)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_matrix_rank_atol_rtol_tensor input ~atol ~rtol ~hermitian =
  stubs_linalg_matrix_rank_atol_rtol_tensor
    input
    (match atol with
     | Some v -> v
     | None -> none_gc_tensor)
    (match rtol with
     | Some v -> v
     | None -> none_gc_tensor)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_matrix_rank_atol_rtol_tensor_out ~out input ~atol ~rtol ~hermitian =
  stubs_linalg_matrix_rank_atol_rtol_tensor_out
    out
    input
    (match atol with
     | Some v -> v
     | None -> none_gc_tensor)
    (match rtol with
     | Some v -> v
     | None -> none_gc_tensor)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_matrix_rank_out ~out self ~tol ~hermitian =
  stubs_linalg_matrix_rank_out out self tol (if hermitian then 1 else 0) |> with_tensor_gc
;;

let linalg_matrix_rank_out_tol_tensor ~out input ~tol ~hermitian =
  stubs_linalg_matrix_rank_out_tol_tensor out input tol (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_matrix_rank_tol_tensor input ~tol ~hermitian =
  stubs_linalg_matrix_rank_tol_tensor input tol (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_multi_dot tensors =
  let result =
    stubs_linalg_multi_dot
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let linalg_multi_dot_out ~out tensors =
  let result =
    stubs_linalg_multi_dot_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let linalg_pinv self ~rcond ~hermitian =
  stubs_linalg_pinv self rcond (if hermitian then 1 else 0) |> with_tensor_gc
;;

let linalg_pinv_atol_rtol_float self ~atol ~rtol ~hermitian =
  stubs_linalg_pinv_atol_rtol_float
    self
    (Option.value atol ~default:0.0)
    (match atol with
     | Some _ -> 0
     | None -> 1)
    (Option.value rtol ~default:0.0)
    (match rtol with
     | Some _ -> 0
     | None -> 1)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_pinv_atol_rtol_float_out ~out self ~atol ~rtol ~hermitian =
  stubs_linalg_pinv_atol_rtol_float_out
    out
    self
    (Option.value atol ~default:0.0)
    (match atol with
     | Some _ -> 0
     | None -> 1)
    (Option.value rtol ~default:0.0)
    (match rtol with
     | Some _ -> 0
     | None -> 1)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_pinv_atol_rtol_tensor self ~atol ~rtol ~hermitian =
  stubs_linalg_pinv_atol_rtol_tensor
    self
    (match atol with
     | Some v -> v
     | None -> none_gc_tensor)
    (match rtol with
     | Some v -> v
     | None -> none_gc_tensor)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_pinv_atol_rtol_tensor_out ~out self ~atol ~rtol ~hermitian =
  stubs_linalg_pinv_atol_rtol_tensor_out
    out
    self
    (match atol with
     | Some v -> v
     | None -> none_gc_tensor)
    (match rtol with
     | Some v -> v
     | None -> none_gc_tensor)
    (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_pinv_out ~out self ~rcond ~hermitian =
  stubs_linalg_pinv_out out self rcond (if hermitian then 1 else 0) |> with_tensor_gc
;;

let linalg_pinv_out_rcond_tensor ~out self ~rcond ~hermitian =
  stubs_linalg_pinv_out_rcond_tensor out self rcond (if hermitian then 1 else 0)
  |> with_tensor_gc
;;

let linalg_pinv_rcond_tensor self ~rcond ~hermitian =
  stubs_linalg_pinv_rcond_tensor self rcond (if hermitian then 1 else 0) |> with_tensor_gc
;;

let linalg_qr ~a ~mode =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_qr (CArray.start out__) a mode;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_qr_out ~q ~r ~a ~mode =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_qr_out (CArray.start out__) q r a mode;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_slogdet ~a =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_slogdet (CArray.start out__) a;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_slogdet_out ~sign ~logabsdet ~a =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_slogdet_out (CArray.start out__) sign logabsdet a;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_solve ~a ~b ~left =
  stubs_linalg_solve a b (if left then 1 else 0) |> with_tensor_gc
;;

let linalg_solve_ex ~a ~b ~left ~check_errors =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_solve_ex
    (CArray.start out__)
    a
    b
    (if left then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_solve_ex_out result ~info ~a ~b ~left ~check_errors =
  let out__ = CArray.make raw_tensor 2 in
  stubs_linalg_solve_ex_out
    (CArray.start out__)
    result
    info
    a
    b
    (if left then 1 else 0)
    (if check_errors then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let linalg_solve_out ~out ~a ~b ~left =
  stubs_linalg_solve_out out a b (if left then 1 else 0) |> with_tensor_gc
;;

let linalg_solve_triangular self ~b ~upper ~left ~unitriangular =
  stubs_linalg_solve_triangular
    self
    b
    (if upper then 1 else 0)
    (if left then 1 else 0)
    (if unitriangular then 1 else 0)
  |> with_tensor_gc
;;

let linalg_solve_triangular_out ~out self ~b ~upper ~left ~unitriangular =
  stubs_linalg_solve_triangular_out
    out
    self
    b
    (if upper then 1 else 0)
    (if left then 1 else 0)
    (if unitriangular then 1 else 0)
  |> with_tensor_gc
;;

let linalg_svd ~a ~full_matrices ~driver =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_svd
    (CArray.start out__)
    a
    (if full_matrices then 1 else 0)
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_svd_u ~u ~s ~vh ~a ~full_matrices ~driver =
  let out__ = CArray.make raw_tensor 3 in
  stubs_linalg_svd_u
    (CArray.start out__)
    u
    s
    vh
    a
    (if full_matrices then 1 else 0)
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let linalg_svdvals ~a ~driver =
  stubs_linalg_svdvals
    a
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let linalg_svdvals_out ~out ~a ~driver =
  stubs_linalg_svdvals_out
    out
    a
    (Option.value driver ~default:"")
    (match driver with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let linalg_tensorinv self ~ind =
  stubs_linalg_tensorinv self (Int64.of_int ind) |> with_tensor_gc
;;

let linalg_tensorinv_out ~out self ~ind =
  stubs_linalg_tensorinv_out out self (Int64.of_int ind) |> with_tensor_gc
;;

let linalg_tensorsolve self other ~dims =
  stubs_linalg_tensorsolve
    self
    other
    (match dims with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dims with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let linalg_tensorsolve_out ~out self other ~dims =
  stubs_linalg_tensorsolve_out
    out
    self
    other
    (match dims with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dims with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let linalg_vander ~x ~n =
  stubs_linalg_vander
    x
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let linalg_vecdot ~x ~y ~dim =
  stubs_linalg_vecdot x y (Int64.of_int dim) |> with_tensor_gc
;;

let linalg_vecdot_out ~out ~x ~y ~dim =
  stubs_linalg_vecdot_out out x y (Int64.of_int dim) |> with_tensor_gc
;;

let linear input ~weight ~bias =
  stubs_linear
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let linear_out ~out input ~weight ~bias =
  stubs_linear_out
    out
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let linspace ~start ~end_ ~steps ~options =
  stubs_linspace
    start
    end_
    (Int64.of_int steps)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let linspace_out ~out ~start ~end_ ~steps =
  stubs_linspace_out out start end_ (Int64.of_int steps) |> with_tensor_gc
;;

let linspace_scalar_tensor ~start ~end_ ~steps ~options =
  stubs_linspace_scalar_tensor
    start
    end_
    (Int64.of_int steps)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let linspace_scalar_tensor_out ~out ~start ~end_ ~steps =
  stubs_linspace_scalar_tensor_out out start end_ (Int64.of_int steps) |> with_tensor_gc
;;

let linspace_tensor_scalar ~start ~end_ ~steps ~options =
  stubs_linspace_tensor_scalar
    start
    end_
    (Int64.of_int steps)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let linspace_tensor_scalar_out ~out ~start ~end_ ~steps =
  stubs_linspace_tensor_scalar_out out start end_ (Int64.of_int steps) |> with_tensor_gc
;;

let linspace_tensor_tensor ~start ~end_ ~steps ~options =
  stubs_linspace_tensor_tensor
    start
    end_
    (Int64.of_int steps)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let linspace_tensor_tensor_out ~out ~start ~end_ ~steps =
  stubs_linspace_tensor_tensor_out out start end_ (Int64.of_int steps) |> with_tensor_gc
;;

let log self = stubs_log self |> with_tensor_gc
let log10 self = stubs_log10 self |> with_tensor_gc
let log10_ self = stubs_log10_ self |> with_tensor_gc
let log10_out ~out self = stubs_log10_out out self |> with_tensor_gc
let log1p self = stubs_log1p self |> with_tensor_gc
let log1p_ self = stubs_log1p_ self |> with_tensor_gc
let log1p_out ~out self = stubs_log1p_out out self |> with_tensor_gc
let log2 self = stubs_log2 self |> with_tensor_gc
let log2_ self = stubs_log2_ self |> with_tensor_gc
let log2_out ~out self = stubs_log2_out out self |> with_tensor_gc
let log_ self = stubs_log_ self |> with_tensor_gc
let log_normal self ~mean ~std = stubs_log_normal self mean std |> with_tensor_gc
let log_normal_ self ~mean ~std = stubs_log_normal_ self mean std |> with_tensor_gc

let log_normal_out ~out self ~mean ~std =
  stubs_log_normal_out out self mean std |> with_tensor_gc
;;

let log_out ~out self = stubs_log_out out self |> with_tensor_gc
let log_sigmoid self = stubs_log_sigmoid self |> with_tensor_gc

let log_sigmoid_backward ~grad_output self ~buffer =
  stubs_log_sigmoid_backward grad_output self buffer |> with_tensor_gc
;;

let log_sigmoid_backward_grad_input ~grad_input ~grad_output self ~buffer =
  stubs_log_sigmoid_backward_grad_input grad_input grad_output self buffer
  |> with_tensor_gc
;;

let log_sigmoid_out ~out self = stubs_log_sigmoid_out out self |> with_tensor_gc

let log_softmax self ~dim ~dtype =
  stubs_log_softmax self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let log_softmax_int_out ~out self ~dim ~dtype =
  stubs_log_softmax_int_out out self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let logaddexp self other = stubs_logaddexp self other |> with_tensor_gc
let logaddexp2 self other = stubs_logaddexp2 self other |> with_tensor_gc
let logaddexp2_out ~out self other = stubs_logaddexp2_out out self other |> with_tensor_gc
let logaddexp_out ~out self other = stubs_logaddexp_out out self other |> with_tensor_gc
let logcumsumexp self ~dim = stubs_logcumsumexp self (Int64.of_int dim) |> with_tensor_gc

let logcumsumexp_out ~out self ~dim =
  stubs_logcumsumexp_out out self (Int64.of_int dim) |> with_tensor_gc
;;

let logdet self = stubs_logdet self |> with_tensor_gc
let logical_and self other = stubs_logical_and self other |> with_tensor_gc
let logical_and_ self other = stubs_logical_and_ self other |> with_tensor_gc

let logical_and_out ~out self other =
  stubs_logical_and_out out self other |> with_tensor_gc
;;

let logical_not self = stubs_logical_not self |> with_tensor_gc
let logical_not_ self = stubs_logical_not_ self |> with_tensor_gc
let logical_not_out ~out self = stubs_logical_not_out out self |> with_tensor_gc
let logical_or self other = stubs_logical_or self other |> with_tensor_gc
let logical_or_ self other = stubs_logical_or_ self other |> with_tensor_gc
let logical_or_out ~out self other = stubs_logical_or_out out self other |> with_tensor_gc
let logical_xor self other = stubs_logical_xor self other |> with_tensor_gc
let logical_xor_ self other = stubs_logical_xor_ self other |> with_tensor_gc

let logical_xor_out ~out self other =
  stubs_logical_xor_out out self other |> with_tensor_gc
;;

let logit self ~eps =
  stubs_logit
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let logit_ self ~eps =
  stubs_logit_
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let logit_backward ~grad_output self ~eps =
  stubs_logit_backward
    grad_output
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let logit_backward_grad_input ~grad_input ~grad_output self ~eps =
  stubs_logit_backward_grad_input
    grad_input
    grad_output
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let logit_out ~out self ~eps =
  stubs_logit_out
    out
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let logspace ~start ~end_ ~steps ~base ~options =
  stubs_logspace
    start
    end_
    (Int64.of_int steps)
    base
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let logspace_out ~out ~start ~end_ ~steps ~base =
  stubs_logspace_out out start end_ (Int64.of_int steps) base |> with_tensor_gc
;;

let logspace_scalar_tensor ~start ~end_ ~steps ~base ~options =
  stubs_logspace_scalar_tensor
    start
    end_
    (Int64.of_int steps)
    base
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let logspace_scalar_tensor_out ~out ~start ~end_ ~steps ~base =
  stubs_logspace_scalar_tensor_out out start end_ (Int64.of_int steps) base
  |> with_tensor_gc
;;

let logspace_tensor_scalar ~start ~end_ ~steps ~base ~options =
  stubs_logspace_tensor_scalar
    start
    end_
    (Int64.of_int steps)
    base
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let logspace_tensor_scalar_out ~out ~start ~end_ ~steps ~base =
  stubs_logspace_tensor_scalar_out out start end_ (Int64.of_int steps) base
  |> with_tensor_gc
;;

let logspace_tensor_tensor ~start ~end_ ~steps ~base ~options =
  stubs_logspace_tensor_tensor
    start
    end_
    (Int64.of_int steps)
    base
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let logspace_tensor_tensor_out ~out ~start ~end_ ~steps ~base =
  stubs_logspace_tensor_tensor_out out start end_ (Int64.of_int steps) base
  |> with_tensor_gc
;;

let logsumexp self ~dim ~keepdim =
  stubs_logsumexp
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let logsumexp_out ~out self ~dim ~keepdim =
  stubs_logsumexp_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let lstm
  input
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_lstm
    (CArray.start out__)
    input
    (CArray.of_list gc_tensor hx |> CArray.start)
    (List.length hx)
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  keep_values_alive hx;
  keep_values_alive params;
  t0, t1, t2
;;

let lstm_cell input ~hx ~w_ih ~w_hh ~b_ih ~b_hh =
  let out__ = CArray.make raw_tensor 2 in
  stubs_lstm_cell
    (CArray.start out__)
    input
    (CArray.of_list gc_tensor hx |> CArray.start)
    (List.length hx)
    w_ih
    w_hh
    (match b_ih with
     | Some v -> v
     | None -> none_gc_tensor)
    (match b_hh with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive hx;
  t0, t1
;;

let lstm_data
  ~data
  ~batch_sizes
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_lstm_data
    (CArray.start out__)
    data
    batch_sizes
    (CArray.of_list gc_tensor hx |> CArray.start)
    (List.length hx)
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  keep_values_alive hx;
  keep_values_alive params;
  t0, t1, t2
;;

let lstm_mps_backward
  ~out0
  ~out1
  ~out2
  ~grad_y
  ~grad_hy
  ~grad_cy
  ~z_state
  ~cell_state_fwd
  input
  ~layersoutputs
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let result =
    stubs_lstm_mps_backward
      out0
      (CArray.of_list gc_tensor out1 |> CArray.start)
      (List.length out1)
      (CArray.of_list gc_tensor out2 |> CArray.start)
      (List.length out2)
      (match grad_y with
       | Some v -> v
       | None -> none_gc_tensor)
      (match grad_hy with
       | Some v -> v
       | None -> none_gc_tensor)
      (match grad_cy with
       | Some v -> v
       | None -> none_gc_tensor)
      z_state
      cell_state_fwd
      input
      layersoutputs
      (CArray.of_list gc_tensor hx |> CArray.start)
      (List.length hx)
      (CArray.of_list gc_tensor params |> CArray.start)
      (List.length params)
      (if has_biases then 1 else 0)
      (Int64.of_int num_layers)
      dropout
      (if train then 1 else 0)
      (if bidirectional then 1 else 0)
      (if batch_first then 1 else 0)
  in
  keep_values_alive out1;
  keep_values_alive out2;
  keep_values_alive hx;
  keep_values_alive params;
  result
;;

let lt self other = stubs_lt self other |> with_tensor_gc
let lt_ self other = stubs_lt_ self other |> with_tensor_gc
let lt_scalar_out ~out self other = stubs_lt_scalar_out out self other |> with_tensor_gc
let lt_tensor self other = stubs_lt_tensor self other |> with_tensor_gc
let lt_tensor_ self other = stubs_lt_tensor_ self other |> with_tensor_gc
let lt_tensor_out ~out self other = stubs_lt_tensor_out out self other |> with_tensor_gc

let lu_solve self ~lu_data ~lu_pivots =
  stubs_lu_solve self lu_data lu_pivots |> with_tensor_gc
;;

let lu_solve_out ~out self ~lu_data ~lu_pivots =
  stubs_lu_solve_out out self lu_data lu_pivots |> with_tensor_gc
;;

let lu_unpack ~lu_data ~lu_pivots ~unpack_data ~unpack_pivots =
  let out__ = CArray.make raw_tensor 3 in
  stubs_lu_unpack
    (CArray.start out__)
    lu_data
    lu_pivots
    (if unpack_data then 1 else 0)
    (if unpack_pivots then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let lu_unpack_out ~p ~l ~u ~lu_data ~lu_pivots ~unpack_data ~unpack_pivots =
  let out__ = CArray.make raw_tensor 3 in
  stubs_lu_unpack_out
    (CArray.start out__)
    p
    l
    u
    lu_data
    lu_pivots
    (if unpack_data then 1 else 0)
    (if unpack_pivots then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let margin_ranking_loss ~input1 ~input2 ~target ~margin ~reduction =
  stubs_margin_ranking_loss
    input1
    input2
    target
    margin
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let masked_fill self ~mask ~value = stubs_masked_fill self mask value |> with_tensor_gc
let masked_fill_ self ~mask ~value = stubs_masked_fill_ self mask value |> with_tensor_gc

let masked_fill_scalar_out ~out self ~mask ~value =
  stubs_masked_fill_scalar_out out self mask value |> with_tensor_gc
;;

let masked_fill_tensor self ~mask ~value =
  stubs_masked_fill_tensor self mask value |> with_tensor_gc
;;

let masked_fill_tensor_ self ~mask ~value =
  stubs_masked_fill_tensor_ self mask value |> with_tensor_gc
;;

let masked_fill_tensor_out ~out self ~mask ~value =
  stubs_masked_fill_tensor_out out self mask value |> with_tensor_gc
;;

let masked_scatter self ~mask ~source =
  stubs_masked_scatter self mask source |> with_tensor_gc
;;

let masked_scatter_ self ~mask ~source =
  stubs_masked_scatter_ self mask source |> with_tensor_gc
;;

let masked_scatter_backward ~grad_output ~mask ~sizes =
  stubs_masked_scatter_backward
    grad_output
    mask
    (List.map Int64.of_int sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length sizes)
  |> with_tensor_gc
;;

let masked_scatter_out ~out self ~mask ~source =
  stubs_masked_scatter_out out self mask source |> with_tensor_gc
;;

let masked_select self ~mask = stubs_masked_select self mask |> with_tensor_gc

let masked_select_backward ~grad input ~mask =
  stubs_masked_select_backward grad input mask |> with_tensor_gc
;;

let masked_select_out ~out self ~mask =
  stubs_masked_select_out out self mask |> with_tensor_gc
;;

let matmul self other = stubs_matmul self other |> with_tensor_gc
let matmul_out ~out self other = stubs_matmul_out out self other |> with_tensor_gc
let matrix_exp self = stubs_matrix_exp self |> with_tensor_gc
let matrix_exp_backward self ~grad = stubs_matrix_exp_backward self grad |> with_tensor_gc
let matrix_h self = stubs_matrix_h self |> with_tensor_gc
let matrix_power self ~n = stubs_matrix_power self (Int64.of_int n) |> with_tensor_gc

let matrix_power_out ~out self ~n =
  stubs_matrix_power_out out self (Int64.of_int n) |> with_tensor_gc
;;

let max self = stubs_max self |> with_tensor_gc

let max_dim self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_dim (CArray.start out__) self (Int64.of_int dim) (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_dim_max ~max ~max_values self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_dim_max
    (CArray.start out__)
    max
    max_values
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_other self other = stubs_max_other self other |> with_tensor_gc
let max_out ~out self other = stubs_max_out out self other |> with_tensor_gc

let max_pool1d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_max_pool1d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let max_pool1d_with_indices self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_pool1d_with_indices
    (CArray.start out__)
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_pool2d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_max_pool2d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let max_pool2d_backward
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  stubs_max_pool2d_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let max_pool2d_backward_out
  ~out
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  stubs_max_pool2d_backward_out
    out
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let max_pool2d_with_indices self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_pool2d_with_indices
    (CArray.start out__)
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_pool2d_with_indices_backward
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  ~indices
  =
  stubs_max_pool2d_with_indices_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
    indices
  |> with_tensor_gc
;;

let max_pool2d_with_indices_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  ~indices
  =
  stubs_max_pool2d_with_indices_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
    indices
  |> with_tensor_gc
;;

let max_pool2d_with_indices_out
  ~out
  ~indices
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_pool2d_with_indices_out
    (CArray.start out__)
    out
    indices
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_pool3d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_max_pool3d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let max_pool3d_with_indices self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_pool3d_with_indices
    (CArray.start out__)
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_pool3d_with_indices_backward
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  ~indices
  =
  stubs_max_pool3d_with_indices_backward
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
    indices
  |> with_tensor_gc
;;

let max_pool3d_with_indices_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  ~indices
  =
  stubs_max_pool3d_with_indices_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
    indices
  |> with_tensor_gc
;;

let max_pool3d_with_indices_out
  ~out
  ~indices
  self
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_max_pool3d_with_indices_out
    (CArray.start out__)
    out
    indices
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let max_unary_out ~out self = stubs_max_unary_out out self |> with_tensor_gc

let max_unpool2d self ~indices ~output_size =
  stubs_max_unpool2d
    self
    indices
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let max_unpool2d_out ~out self ~indices ~output_size =
  stubs_max_unpool2d_out
    out
    self
    indices
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let max_unpool3d self ~indices ~output_size ~stride ~padding =
  stubs_max_unpool3d
    self
    indices
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let max_unpool3d_out ~out self ~indices ~output_size ~stride ~padding =
  stubs_max_unpool3d_out
    out
    self
    indices
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let maximum self other = stubs_maximum self other |> with_tensor_gc
let maximum_out ~out self other = stubs_maximum_out out self other |> with_tensor_gc
let mean self ~dtype = stubs_mean self (Kind.packed_to_int dtype) |> with_tensor_gc

let mean_dim self ~dim ~keepdim ~dtype =
  stubs_mean_dim
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let mean_dtype_out ~out self ~dtype =
  stubs_mean_dtype_out out self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let mean_out ~out self ~dim ~keepdim ~dtype =
  stubs_mean_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let median self = stubs_median self |> with_tensor_gc

let median_dim self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_median_dim (CArray.start out__) self (Int64.of_int dim) (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let median_dim_values ~values ~indices self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_median_dim_values
    (CArray.start out__)
    values
    indices
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let median_out ~out self = stubs_median_out out self |> with_tensor_gc

let meshgrid tensors =
  let result =
    stubs_meshgrid
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let meshgrid_indexing tensors ~indexing =
  let result =
    stubs_meshgrid_indexing
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      indexing
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let mh self = stubs_mh self |> with_tensor_gc
let min self = stubs_min self |> with_tensor_gc

let min_dim self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_min_dim (CArray.start out__) self (Int64.of_int dim) (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let min_dim_min ~min ~min_indices self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_min_dim_min
    (CArray.start out__)
    min
    min_indices
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let min_other self other = stubs_min_other self other |> with_tensor_gc
let min_out ~out self other = stubs_min_out out self other |> with_tensor_gc
let min_unary_out ~out self = stubs_min_unary_out out self |> with_tensor_gc
let minimum self other = stubs_minimum self other |> with_tensor_gc
let minimum_out ~out self other = stubs_minimum_out out self other |> with_tensor_gc

let miopen_batch_norm
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~exponential_average_factor
  ~epsilon
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_miopen_batch_norm
    (CArray.start out__)
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    exponential_average_factor
    epsilon;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let miopen_batch_norm_backward
  input
  ~grad_output
  ~weight
  ~running_mean
  ~running_var
  ~save_mean
  ~save_var
  ~epsilon
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_miopen_batch_norm_backward
    (CArray.start out__)
    input
    grad_output
    weight
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_var with
     | Some v -> v
     | None -> none_gc_tensor)
    epsilon;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let miopen_batch_norm_backward_out
  ~out0
  ~out1
  ~out2
  input
  ~grad_output
  ~weight
  ~running_mean
  ~running_var
  ~save_mean
  ~save_var
  ~epsilon
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_miopen_batch_norm_backward_out
    (CArray.start out__)
    out0
    out1
    out2
    input
    grad_output
    weight
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match save_var with
     | Some v -> v
     | None -> none_gc_tensor)
    epsilon;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let miopen_batch_norm_out
  ~out0
  ~out1
  ~out2
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~exponential_average_factor
  ~epsilon
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_miopen_batch_norm_out
    (CArray.start out__)
    out0
    out1
    out2
    input
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    exponential_average_factor
    epsilon;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let miopen_convolution
  self
  ~weight
  ~bias
  ~padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  =
  stubs_miopen_convolution
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
  |> with_tensor_gc
;;

let miopen_convolution_add_relu
  self
  ~weight
  ~z
  ~alpha
  ~bias
  ~stride
  ~padding
  ~dilation
  ~groups
  =
  stubs_miopen_convolution_add_relu
    self
    weight
    z
    alpha
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let miopen_convolution_out
  ~out
  self
  ~weight
  ~bias
  ~padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  =
  stubs_miopen_convolution_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
  |> with_tensor_gc
;;

let miopen_convolution_relu self ~weight ~bias ~stride ~padding ~dilation ~groups =
  stubs_miopen_convolution_relu
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let miopen_convolution_transpose
  self
  ~weight
  ~bias
  ~padding
  ~output_padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  =
  stubs_miopen_convolution_transpose
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
  |> with_tensor_gc
;;

let miopen_convolution_transpose_out
  ~out
  self
  ~weight
  ~bias
  ~padding
  ~output_padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  =
  stubs_miopen_convolution_transpose_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
  |> with_tensor_gc
;;

let miopen_depthwise_convolution
  self
  ~weight
  ~bias
  ~padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  =
  stubs_miopen_depthwise_convolution
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
  |> with_tensor_gc
;;

let miopen_depthwise_convolution_out
  ~out
  self
  ~weight
  ~bias
  ~padding
  ~stride
  ~dilation
  ~groups
  ~benchmark
  ~deterministic
  =
  stubs_miopen_depthwise_convolution_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (if benchmark then 1 else 0)
    (if deterministic then 1 else 0)
  |> with_tensor_gc
;;

let miopen_rnn
  input
  ~weight
  ~weight_stride0
  ~hx
  ~cx
  ~mode
  ~hidden_size
  ~num_layers
  ~batch_first
  ~dropout
  ~train
  ~bidirectional
  ~batch_sizes
  ~dropout_state
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs_miopen_rnn
    (CArray.start out__)
    input
    (CArray.of_list gc_tensor weight |> CArray.start)
    (List.length weight)
    (Int64.of_int weight_stride0)
    hx
    (match cx with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int num_layers)
    (if batch_first then 1 else 0)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (match dropout_state with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  keep_values_alive weight;
  t0, t1, t2, t3, t4
;;

let miopen_rnn_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~out4
  input
  ~weight
  ~weight_stride0
  ~hx
  ~cx
  ~mode
  ~hidden_size
  ~num_layers
  ~batch_first
  ~dropout
  ~train
  ~bidirectional
  ~batch_sizes
  ~dropout_state
  =
  let out__ = CArray.make raw_tensor 5 in
  stubs_miopen_rnn_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    out4
    input
    (CArray.of_list gc_tensor weight |> CArray.start)
    (List.length weight)
    (Int64.of_int weight_stride0)
    hx
    (match cx with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int num_layers)
    (if batch_first then 1 else 0)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (match dropout_state with
     | Some v -> v
     | None -> none_gc_tensor);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  keep_values_alive weight;
  t0, t1, t2, t3, t4
;;

let mish self = stubs_mish self |> with_tensor_gc
let mish_ self = stubs_mish_ self |> with_tensor_gc

let mish_backward ~grad_output self =
  stubs_mish_backward grad_output self |> with_tensor_gc
;;

let mish_out ~out self = stubs_mish_out out self |> with_tensor_gc

let mkldnn_adaptive_avg_pool2d self ~output_size =
  stubs_mkldnn_adaptive_avg_pool2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let mkldnn_adaptive_avg_pool2d_backward ~grad_output self =
  stubs_mkldnn_adaptive_avg_pool2d_backward grad_output self |> with_tensor_gc
;;

let mkldnn_adaptive_avg_pool2d_backward_out ~out ~grad_output self =
  stubs_mkldnn_adaptive_avg_pool2d_backward_out out grad_output self |> with_tensor_gc
;;

let mkldnn_adaptive_avg_pool2d_out ~out self ~output_size =
  stubs_mkldnn_adaptive_avg_pool2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
  |> with_tensor_gc
;;

let mkldnn_convolution self ~weight ~bias ~padding ~stride ~dilation ~groups =
  stubs_mkldnn_convolution
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let mkldnn_convolution_out ~out self ~weight ~bias ~padding ~stride ~dilation ~groups =
  stubs_mkldnn_convolution_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
  |> with_tensor_gc
;;

let mkldnn_linear self ~weight ~bias =
  stubs_mkldnn_linear
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let mkldnn_linear_backward_input ~input_size ~grad_output ~weight =
  stubs_mkldnn_linear_backward_input
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    grad_output
    weight
  |> with_tensor_gc
;;

let mkldnn_linear_backward_input_out ~out ~input_size ~grad_output ~weight =
  stubs_mkldnn_linear_backward_input_out
    out
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    grad_output
    weight
  |> with_tensor_gc
;;

let mkldnn_linear_backward_weights ~grad_output input ~weight ~bias_defined =
  let out__ = CArray.make raw_tensor 2 in
  stubs_mkldnn_linear_backward_weights
    (CArray.start out__)
    grad_output
    input
    weight
    (if bias_defined then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let mkldnn_linear_backward_weights_out
  ~out0
  ~out1
  ~grad_output
  input
  ~weight
  ~bias_defined
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_mkldnn_linear_backward_weights_out
    (CArray.start out__)
    out0
    out1
    grad_output
    input
    weight
    (if bias_defined then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let mkldnn_linear_out ~out self ~weight ~bias =
  stubs_mkldnn_linear_out
    out
    self
    weight
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let mkldnn_max_pool2d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_mkldnn_max_pool2d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool2d_backward
  ~grad_output
  ~output
  input
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  stubs_mkldnn_max_pool2d_backward
    grad_output
    output
    input
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool2d_backward_out
  ~out
  ~grad_output
  ~output
  input
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  stubs_mkldnn_max_pool2d_backward_out
    out
    grad_output
    output
    input
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool2d_out ~out self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_mkldnn_max_pool2d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool3d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_mkldnn_max_pool3d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool3d_backward
  ~grad_output
  ~output
  input
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  stubs_mkldnn_max_pool3d_backward
    grad_output
    output
    input
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool3d_backward_out
  ~out
  ~grad_output
  ~output
  input
  ~kernel_size
  ~stride
  ~padding
  ~dilation
  ~ceil_mode
  =
  stubs_mkldnn_max_pool3d_backward_out
    out
    grad_output
    output
    input
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_max_pool3d_out ~out self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_mkldnn_max_pool3d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let mkldnn_reorder_conv2d_weight self ~padding ~stride ~dilation ~groups ~input_size =
  stubs_mkldnn_reorder_conv2d_weight
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (match input_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match input_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let mkldnn_reorder_conv2d_weight_out
  ~out
  self
  ~padding
  ~stride
  ~dilation
  ~groups
  ~input_size
  =
  stubs_mkldnn_reorder_conv2d_weight_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (match input_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match input_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let mkldnn_reorder_conv3d_weight self ~padding ~stride ~dilation ~groups ~input_size =
  stubs_mkldnn_reorder_conv3d_weight
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (match input_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match input_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let mkldnn_reorder_conv3d_weight_out
  ~out
  self
  ~padding
  ~stride
  ~dilation
  ~groups
  ~input_size
  =
  stubs_mkldnn_reorder_conv3d_weight_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (Int64.of_int groups)
    (match input_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match input_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let mkldnn_rnn_layer
  input
  ~weight0
  ~weight1
  ~weight2
  ~weight3
  ~hx_
  ~cx_
  ~reverse
  ~batch_sizes
  ~mode
  ~hidden_size
  ~num_layers
  ~has_biases
  ~bidirectional
  ~batch_first
  ~train
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_mkldnn_rnn_layer
    (CArray.start out__)
    input
    weight0
    weight1
    weight2
    weight3
    hx_
    cx_
    (if reverse then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int num_layers)
    (if has_biases then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0)
    (if train then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let mkldnn_rnn_layer_backward
  input
  ~weight1
  ~weight2
  ~weight3
  ~weight4
  ~hx_
  ~cx_tmp
  ~output
  ~hy_
  ~cy_
  ~grad_output
  ~grad_hy
  ~grad_cy
  ~reverse
  ~mode
  ~hidden_size
  ~num_layers
  ~has_biases
  ~train
  ~bidirectional
  ~batch_sizes
  ~batch_first
  ~workspace
  =
  let out__ = CArray.make raw_tensor 7 in
  stubs_mkldnn_rnn_layer_backward
    (CArray.start out__)
    input
    weight1
    weight2
    weight3
    weight4
    hx_
    cx_tmp
    output
    hy_
    cy_
    (match grad_output with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_hy with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_cy with
     | Some v -> v
     | None -> none_gc_tensor)
    (if reverse then 1 else 0)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int num_layers)
    (if has_biases then 1 else 0)
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (if batch_first then 1 else 0)
    workspace;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  let t5 = CArray.get out__ 5 |> with_tensor_gc in
  let t6 = CArray.get out__ 6 |> with_tensor_gc in
  t0, t1, t2, t3, t4, t5, t6
;;

let mkldnn_rnn_layer_backward_out
  ~out0
  ~out1
  ~out2
  ~out3
  ~out4
  ~out5
  ~out6
  input
  ~weight1
  ~weight2
  ~weight3
  ~weight4
  ~hx_
  ~cx_tmp
  ~output
  ~hy_
  ~cy_
  ~grad_output
  ~grad_hy
  ~grad_cy
  ~reverse
  ~mode
  ~hidden_size
  ~num_layers
  ~has_biases
  ~train
  ~bidirectional
  ~batch_sizes
  ~batch_first
  ~workspace
  =
  let out__ = CArray.make raw_tensor 7 in
  stubs_mkldnn_rnn_layer_backward_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    out4
    out5
    out6
    input
    weight1
    weight2
    weight3
    weight4
    hx_
    cx_tmp
    output
    hy_
    cy_
    (match grad_output with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_hy with
     | Some v -> v
     | None -> none_gc_tensor)
    (match grad_cy with
     | Some v -> v
     | None -> none_gc_tensor)
    (if reverse then 1 else 0)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int num_layers)
    (if has_biases then 1 else 0)
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (if batch_first then 1 else 0)
    workspace;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  let t4 = CArray.get out__ 4 |> with_tensor_gc in
  let t5 = CArray.get out__ 5 |> with_tensor_gc in
  let t6 = CArray.get out__ 6 |> with_tensor_gc in
  t0, t1, t2, t3, t4, t5, t6
;;

let mkldnn_rnn_layer_out
  ~out0
  ~out1
  ~out2
  ~out3
  input
  ~weight0
  ~weight1
  ~weight2
  ~weight3
  ~hx_
  ~cx_
  ~reverse
  ~batch_sizes
  ~mode
  ~hidden_size
  ~num_layers
  ~has_biases
  ~bidirectional
  ~batch_first
  ~train
  =
  let out__ = CArray.make raw_tensor 4 in
  stubs_mkldnn_rnn_layer_out
    (CArray.start out__)
    out0
    out1
    out2
    out3
    input
    weight0
    weight1
    weight2
    weight3
    hx_
    cx_
    (if reverse then 1 else 0)
    (List.map Int64.of_int batch_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length batch_sizes)
    (Int64.of_int mode)
    (Int64.of_int hidden_size)
    (Int64.of_int num_layers)
    (if has_biases then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0)
    (if train then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  let t3 = CArray.get out__ 3 |> with_tensor_gc in
  t0, t1, t2, t3
;;

let mm self ~mat2 = stubs_mm self mat2 |> with_tensor_gc
let mm_out ~out self ~mat2 = stubs_mm_out out self mat2 |> with_tensor_gc

let mode self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_mode (CArray.start out__) self (Int64.of_int dim) (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let mode_values ~values ~indices self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_mode_values
    (CArray.start out__)
    values
    indices
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let moveaxis self ~source ~destination =
  stubs_moveaxis
    self
    (List.map Int64.of_int source |> CArray.of_list int64_t |> CArray.start)
    (List.length source)
    (List.map Int64.of_int destination |> CArray.of_list int64_t |> CArray.start)
    (List.length destination)
  |> with_tensor_gc
;;

let moveaxis_int self ~source ~destination =
  stubs_moveaxis_int self (Int64.of_int source) (Int64.of_int destination)
  |> with_tensor_gc
;;

let movedim self ~source ~destination =
  stubs_movedim
    self
    (List.map Int64.of_int source |> CArray.of_list int64_t |> CArray.start)
    (List.length source)
    (List.map Int64.of_int destination |> CArray.of_list int64_t |> CArray.start)
    (List.length destination)
  |> with_tensor_gc
;;

let movedim_int self ~source ~destination =
  stubs_movedim_int self (Int64.of_int source) (Int64.of_int destination)
  |> with_tensor_gc
;;

let mse_loss self ~target ~reduction =
  stubs_mse_loss self target (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let mse_loss_backward ~grad_output self ~target ~reduction =
  stubs_mse_loss_backward
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let mse_loss_backward_grad_input ~grad_input ~grad_output self ~target ~reduction =
  stubs_mse_loss_backward_grad_input
    grad_input
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let mse_loss_out ~out self ~target ~reduction =
  stubs_mse_loss_out out self target (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let msort self = stubs_msort self |> with_tensor_gc
let msort_out ~out self = stubs_msort_out out self |> with_tensor_gc
let mt self = stubs_mt self |> with_tensor_gc
let mul self other = stubs_mul self other |> with_tensor_gc
let mul_ self other = stubs_mul_ self other |> with_tensor_gc
let mul_out ~out self other = stubs_mul_out out self other |> with_tensor_gc
let mul_scalar self other = stubs_mul_scalar self other |> with_tensor_gc
let mul_scalar_ self other = stubs_mul_scalar_ self other |> with_tensor_gc
let mul_scalar_out ~out self other = stubs_mul_scalar_out out self other |> with_tensor_gc

let multi_margin_loss_backward ~grad_output self ~target ~p ~margin ~weight ~reduction =
  stubs_multi_margin_loss_backward
    grad_output
    self
    target
    p
    margin
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let multi_margin_loss_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~target
  ~p
  ~margin
  ~weight
  ~reduction
  =
  stubs_multi_margin_loss_backward_grad_input
    grad_input
    grad_output
    self
    target
    p
    margin
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let multilabel_margin_loss self ~target ~reduction =
  stubs_multilabel_margin_loss self target (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let multilabel_margin_loss_backward ~grad_output self ~target ~reduction ~is_target =
  stubs_multilabel_margin_loss_backward
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    is_target
  |> with_tensor_gc
;;

let multilabel_margin_loss_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~target
  ~reduction
  ~is_target
  =
  stubs_multilabel_margin_loss_backward_grad_input
    grad_input
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    is_target
  |> with_tensor_gc
;;

let multilabel_margin_loss_out ~out self ~target ~reduction =
  stubs_multilabel_margin_loss_out
    out
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let multinomial self ~num_samples ~replacement =
  stubs_multinomial self (Int64.of_int num_samples) (if replacement then 1 else 0)
  |> with_tensor_gc
;;

let multinomial_out ~out self ~num_samples ~replacement =
  stubs_multinomial_out out self (Int64.of_int num_samples) (if replacement then 1 else 0)
  |> with_tensor_gc
;;

let multiply self other = stubs_multiply self other |> with_tensor_gc
let multiply_ self other = stubs_multiply_ self other |> with_tensor_gc
let multiply_out ~out self other = stubs_multiply_out out self other |> with_tensor_gc
let multiply_scalar self other = stubs_multiply_scalar self other |> with_tensor_gc
let multiply_scalar_ self other = stubs_multiply_scalar_ self other |> with_tensor_gc
let mv self ~vec = stubs_mv self vec |> with_tensor_gc
let mv_out ~out self ~vec = stubs_mv_out out self vec |> with_tensor_gc
let mvlgamma self ~p = stubs_mvlgamma self (Int64.of_int p) |> with_tensor_gc
let mvlgamma_ self ~p = stubs_mvlgamma_ self (Int64.of_int p) |> with_tensor_gc

let mvlgamma_out ~out self ~p =
  stubs_mvlgamma_out out self (Int64.of_int p) |> with_tensor_gc
;;

let nan_to_num self ~nan ~posinf ~neginf =
  stubs_nan_to_num
    self
    (Option.value nan ~default:0.0)
    (match nan with
     | Some _ -> 0
     | None -> 1)
    (Option.value posinf ~default:0.0)
    (match posinf with
     | Some _ -> 0
     | None -> 1)
    (Option.value neginf ~default:0.0)
    (match neginf with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let nan_to_num_ self ~nan ~posinf ~neginf =
  stubs_nan_to_num_
    self
    (Option.value nan ~default:0.0)
    (match nan with
     | Some _ -> 0
     | None -> 1)
    (Option.value posinf ~default:0.0)
    (match posinf with
     | Some _ -> 0
     | None -> 1)
    (Option.value neginf ~default:0.0)
    (match neginf with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let nan_to_num_out ~out self ~nan ~posinf ~neginf =
  stubs_nan_to_num_out
    out
    self
    (Option.value nan ~default:0.0)
    (match nan with
     | Some _ -> 0
     | None -> 1)
    (Option.value posinf ~default:0.0)
    (match posinf with
     | Some _ -> 0
     | None -> 1)
    (Option.value neginf ~default:0.0)
    (match neginf with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let nanmean self ~dim ~keepdim ~dtype =
  stubs_nanmean
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let nanmean_out ~out self ~dim ~keepdim ~dtype =
  stubs_nanmean_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let nanmedian self = stubs_nanmedian self |> with_tensor_gc

let nanmedian_dim self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_nanmedian_dim
    (CArray.start out__)
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let nanmedian_dim_values ~values ~indices self ~dim ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_nanmedian_dim_values
    (CArray.start out__)
    values
    indices
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let nanmedian_out ~out self = stubs_nanmedian_out out self |> with_tensor_gc

let nanquantile self ~q ~dim ~keepdim ~interpolation =
  stubs_nanquantile
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let nanquantile_out ~out self ~q ~dim ~keepdim ~interpolation =
  stubs_nanquantile_out
    out
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let nanquantile_scalar self ~q ~dim ~keepdim ~interpolation =
  stubs_nanquantile_scalar
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let nanquantile_scalar_out ~out self ~q ~dim ~keepdim ~interpolation =
  stubs_nanquantile_scalar_out
    out
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let nansum self ~dim ~keepdim ~dtype =
  stubs_nansum
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let nansum_out ~out self ~dim ~keepdim ~dtype =
  stubs_nansum_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let narrow self ~dim ~start ~length =
  stubs_narrow self (Int64.of_int dim) (Int64.of_int start) (Int64.of_int length)
  |> with_tensor_gc
;;

let narrow_copy self ~dim ~start ~length =
  stubs_narrow_copy self (Int64.of_int dim) (Int64.of_int start) (Int64.of_int length)
  |> with_tensor_gc
;;

let narrow_copy_out ~out self ~dim ~start ~length =
  stubs_narrow_copy_out
    out
    self
    (Int64.of_int dim)
    (Int64.of_int start)
    (Int64.of_int length)
  |> with_tensor_gc
;;

let narrow_tensor self ~dim ~start ~length =
  stubs_narrow_tensor self (Int64.of_int dim) start (Int64.of_int length)
  |> with_tensor_gc
;;

let native_batch_norm
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_native_batch_norm
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let native_batch_norm_out
  ~out
  ~save_mean
  ~save_invstd
  input
  ~weight
  ~bias
  ~running_mean
  ~running_var
  ~training
  ~momentum
  ~eps
  =
  let out__ = CArray.make raw_tensor 3 in
  stubs_native_batch_norm_out
    (CArray.start out__)
    out
    save_mean
    save_invstd
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_mean with
     | Some v -> v
     | None -> none_gc_tensor)
    (match running_var with
     | Some v -> v
     | None -> none_gc_tensor)
    (if training then 1 else 0)
    momentum
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let native_channel_shuffle self ~groups =
  stubs_native_channel_shuffle self (Int64.of_int groups) |> with_tensor_gc
;;

let native_dropout input ~p ~train =
  let out__ = CArray.make raw_tensor 2 in
  stubs_native_dropout (CArray.start out__) input p (if train then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let native_dropout_backward ~grad_output ~mask ~scale =
  stubs_native_dropout_backward grad_output mask scale |> with_tensor_gc
;;

let native_dropout_backward_out ~out ~grad_output ~mask ~scale =
  stubs_native_dropout_backward_out out grad_output mask scale |> with_tensor_gc
;;

let native_dropout_out ~out0 ~out1 input ~p ~train =
  let out__ = CArray.make raw_tensor 2 in
  stubs_native_dropout_out (CArray.start out__) out0 out1 input p (if train then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let native_group_norm input ~weight ~bias ~n ~c ~hxw ~group ~eps =
  let out__ = CArray.make raw_tensor 3 in
  stubs_native_group_norm
    (CArray.start out__)
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int n)
    (Int64.of_int c)
    (Int64.of_int hxw)
    (Int64.of_int group)
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let native_group_norm_out ~out0 ~out1 ~out2 input ~weight ~bias ~n ~c ~hxw ~group ~eps =
  let out__ = CArray.make raw_tensor 3 in
  stubs_native_group_norm_out
    (CArray.start out__)
    out0
    out1
    out2
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int n)
    (Int64.of_int c)
    (Int64.of_int hxw)
    (Int64.of_int group)
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let native_layer_norm input ~normalized_shape ~weight ~bias ~eps =
  let out__ = CArray.make raw_tensor 3 in
  stubs_native_layer_norm
    (CArray.start out__)
    input
    (List.map Int64.of_int normalized_shape |> CArray.of_list int64_t |> CArray.start)
    (List.length normalized_shape)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let native_layer_norm_out ~out0 ~out1 ~out2 input ~normalized_shape ~weight ~bias ~eps =
  let out__ = CArray.make raw_tensor 3 in
  stubs_native_layer_norm_out
    (CArray.start out__)
    out0
    out1
    out2
    input
    (List.map Int64.of_int normalized_shape |> CArray.of_list int64_t |> CArray.start)
    (List.length normalized_shape)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    eps;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let native_norm ?p self =
  stubs_native_norm
    self
    (match p with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let native_norm_out ?p ~out self =
  stubs_native_norm_out
    out
    self
    (match p with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let native_norm_scalaropt_dim_dtype self ~p ~dim ~keepdim ~dtype =
  stubs_native_norm_scalaropt_dim_dtype
    self
    p
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let native_norm_scalaropt_dim_dtype_out ~out self ~p ~dim ~keepdim ~dtype =
  stubs_native_norm_scalaropt_dim_dtype_out
    out
    self
    p
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let ne self other = stubs_ne self other |> with_tensor_gc
let ne_ self other = stubs_ne_ self other |> with_tensor_gc
let ne_scalar_out ~out self other = stubs_ne_scalar_out out self other |> with_tensor_gc
let ne_tensor self other = stubs_ne_tensor self other |> with_tensor_gc
let ne_tensor_ self other = stubs_ne_tensor_ self other |> with_tensor_gc
let ne_tensor_out ~out self other = stubs_ne_tensor_out out self other |> with_tensor_gc
let neg self = stubs_neg self |> with_tensor_gc
let neg_ self = stubs_neg_ self |> with_tensor_gc
let neg_out ~out self = stubs_neg_out out self |> with_tensor_gc
let negative self = stubs_negative self |> with_tensor_gc
let negative_ self = stubs_negative_ self |> with_tensor_gc
let negative_out ~out self = stubs_negative_out out self |> with_tensor_gc

let nested_to_padded_tensor self ~padding ~output_size =
  stubs_nested_to_padded_tensor
    self
    padding
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let new_empty self ~size ~options =
  stubs_new_empty
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let new_empty_out ~out self ~size =
  stubs_new_empty_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let new_empty_strided self ~size ~stride ~options =
  stubs_new_empty_strided
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let new_empty_strided_out ~out self ~size ~stride =
  stubs_new_empty_strided_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let new_full self ~size ~fill_value ~options =
  stubs_new_full
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    fill_value
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let new_full_out ~out self ~size ~fill_value =
  stubs_new_full_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    fill_value
  |> with_tensor_gc
;;

let new_ones self ~size ~options =
  stubs_new_ones
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let new_ones_out ~out self ~size =
  stubs_new_ones_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let new_zeros self ~size ~options =
  stubs_new_zeros
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let new_zeros_out ~out self ~size =
  stubs_new_zeros_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let nextafter self other = stubs_nextafter self other |> with_tensor_gc
let nextafter_ self other = stubs_nextafter_ self other |> with_tensor_gc
let nextafter_out ~out self other = stubs_nextafter_out out self other |> with_tensor_gc

let nll_loss self ~target ~weight ~reduction ~ignore_index =
  stubs_nll_loss
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
  |> with_tensor_gc
;;

let nll_loss2d self ~target ~weight ~reduction ~ignore_index =
  stubs_nll_loss2d
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
  |> with_tensor_gc
;;

let nll_loss2d_backward
  ~grad_output
  self
  ~target
  ~weight
  ~reduction
  ~ignore_index
  ~total_weight
  =
  stubs_nll_loss2d_backward
    grad_output
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
    total_weight
  |> with_tensor_gc
;;

let nll_loss2d_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~target
  ~weight
  ~reduction
  ~ignore_index
  ~total_weight
  =
  stubs_nll_loss2d_backward_grad_input
    grad_input
    grad_output
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
    total_weight
  |> with_tensor_gc
;;

let nll_loss2d_out ~out self ~target ~weight ~reduction ~ignore_index =
  stubs_nll_loss2d_out
    out
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
  |> with_tensor_gc
;;

let nll_loss_backward
  ~grad_output
  self
  ~target
  ~weight
  ~reduction
  ~ignore_index
  ~total_weight
  =
  stubs_nll_loss_backward
    grad_output
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
    total_weight
  |> with_tensor_gc
;;

let nll_loss_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~target
  ~weight
  ~reduction
  ~ignore_index
  ~total_weight
  =
  stubs_nll_loss_backward_grad_input
    grad_input
    grad_output
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
    total_weight
  |> with_tensor_gc
;;

let nll_loss_nd self ~target ~weight ~reduction ~ignore_index =
  stubs_nll_loss_nd
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
  |> with_tensor_gc
;;

let nll_loss_out ~out self ~target ~weight ~reduction ~ignore_index =
  stubs_nll_loss_out
    out
    self
    target
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Reduction.to_int reduction |> Int64.of_int)
    (Int64.of_int ignore_index)
  |> with_tensor_gc
;;

let nonzero self = stubs_nonzero self |> with_tensor_gc
let nonzero_numpy self = stubs_nonzero_numpy self |> to_tensor_list
let nonzero_out ~out self = stubs_nonzero_out out self |> with_tensor_gc

let nonzero_static self ~size ~fill_value =
  stubs_nonzero_static self (Int64.of_int size) (Int64.of_int fill_value)
  |> with_tensor_gc
;;

let nonzero_static_out ~out self ~size ~fill_value =
  stubs_nonzero_static_out out self (Int64.of_int size) (Int64.of_int fill_value)
  |> with_tensor_gc
;;

let norm ?p self =
  stubs_norm
    self
    (match p with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let norm_dtype_out ~out self ~p ~dim ~keepdim ~dtype =
  stubs_norm_dtype_out
    out
    self
    p
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let norm_except_dim ~v ~pow ~dim =
  stubs_norm_except_dim v (Int64.of_int pow) (Int64.of_int dim) |> with_tensor_gc
;;

let norm_out ~out self ~p ~dim ~keepdim =
  stubs_norm_out
    out
    self
    p
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let norm_scalar_out ?p ~out self =
  stubs_norm_scalar_out
    out
    self
    (match p with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let norm_scalaropt_dim self ~p ~dim ~keepdim =
  stubs_norm_scalaropt_dim
    self
    p
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let norm_scalaropt_dim_dtype self ~p ~dim ~keepdim ~dtype =
  stubs_norm_scalaropt_dim_dtype
    self
    p
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let norm_scalaropt_dtype self ~p ~dtype =
  stubs_norm_scalaropt_dtype self p (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let norm_scalaropt_dtype_out ~out self ~p ~dtype =
  stubs_norm_scalaropt_dtype_out out self p (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let normal_ self ~mean ~std = stubs_normal_ self mean std |> with_tensor_gc

let normal_functional self ~mean ~std =
  stubs_normal_functional self mean std |> with_tensor_gc
;;

let not_equal self other = stubs_not_equal self other |> with_tensor_gc
let not_equal_ self other = stubs_not_equal_ self other |> with_tensor_gc

let not_equal_scalar_out ~out self other =
  stubs_not_equal_scalar_out out self other |> with_tensor_gc
;;

let not_equal_tensor self other = stubs_not_equal_tensor self other |> with_tensor_gc
let not_equal_tensor_ self other = stubs_not_equal_tensor_ self other |> with_tensor_gc

let not_equal_tensor_out ~out self other =
  stubs_not_equal_tensor_out out self other |> with_tensor_gc
;;

let nuclear_norm self ~keepdim =
  stubs_nuclear_norm self (if keepdim then 1 else 0) |> with_tensor_gc
;;

let nuclear_norm_dim self ~dim ~keepdim =
  stubs_nuclear_norm_dim
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let nuclear_norm_dim_out ~out self ~dim ~keepdim =
  stubs_nuclear_norm_dim_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let nuclear_norm_out ~out self ~keepdim =
  stubs_nuclear_norm_out out self (if keepdim then 1 else 0) |> with_tensor_gc
;;

let numpy_t self = stubs_numpy_t self |> with_tensor_gc

let one_hot self ~num_classes =
  stubs_one_hot self (Int64.of_int num_classes) |> with_tensor_gc
;;

let ones ~size ~options =
  stubs_ones
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let ones_like self = stubs_ones_like self |> with_tensor_gc
let ones_like_out ~out self = stubs_ones_like_out out self |> with_tensor_gc

let ones_out ~out ~size =
  stubs_ones_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let orgqr self ~input2 = stubs_orgqr self input2 |> with_tensor_gc
let orgqr_out ~out self ~input2 = stubs_orgqr_out out self input2 |> with_tensor_gc

let ormqr self ~input2 ~input3 ~left ~transpose =
  stubs_ormqr self input2 input3 (if left then 1 else 0) (if transpose then 1 else 0)
  |> with_tensor_gc
;;

let ormqr_out ~out self ~input2 ~input3 ~left ~transpose =
  stubs_ormqr_out
    out
    self
    input2
    input3
    (if left then 1 else 0)
    (if transpose then 1 else 0)
  |> with_tensor_gc
;;

let outer self ~vec2 = stubs_outer self vec2 |> with_tensor_gc
let outer_out ~out self ~vec2 = stubs_outer_out out self vec2 |> with_tensor_gc
let output_nr self = stubs_output_nr self

let pad self ~pad ~mode ~value =
  stubs_pad
    self
    (List.map Int64.of_int pad |> CArray.of_list int64_t |> CArray.start)
    (List.length pad)
    mode
    (Option.value value ~default:0.0)
    (match value with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let pad_sequence ~sequences ~batch_first ~padding_value ~padding_side =
  let result =
    stubs_pad_sequence
      (CArray.of_list gc_tensor sequences |> CArray.start)
      (List.length sequences)
      (if batch_first then 1 else 0)
      padding_value
      padding_side
    |> with_tensor_gc
  in
  keep_values_alive sequences;
  result
;;

let pairwise_distance ~x1 ~x2 ~p ~eps ~keepdim =
  stubs_pairwise_distance x1 x2 p eps (if keepdim then 1 else 0) |> with_tensor_gc
;;

let pdist self ~p = stubs_pdist self p |> with_tensor_gc

let permute self ~dims =
  stubs_permute
    self
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let permute_copy self ~dims =
  stubs_permute_copy
    self
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let permute_copy_out ~out self ~dims =
  stubs_permute_copy_out
    out
    self
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let pin_memory self ~device =
  stubs_pin_memory self (Device.option_to_int device) |> with_tensor_gc
;;

let pinverse self ~rcond = stubs_pinverse self rcond |> with_tensor_gc

let pixel_shuffle self ~upscale_factor =
  stubs_pixel_shuffle self (Int64.of_int upscale_factor) |> with_tensor_gc
;;

let pixel_shuffle_out ~out self ~upscale_factor =
  stubs_pixel_shuffle_out out self (Int64.of_int upscale_factor) |> with_tensor_gc
;;

let pixel_unshuffle self ~downscale_factor =
  stubs_pixel_unshuffle self (Int64.of_int downscale_factor) |> with_tensor_gc
;;

let pixel_unshuffle_out ~out self ~downscale_factor =
  stubs_pixel_unshuffle_out out self (Int64.of_int downscale_factor) |> with_tensor_gc
;;

let poisson self = stubs_poisson self |> with_tensor_gc

let poisson_nll_loss input ~target ~log_input ~full ~eps ~reduction =
  stubs_poisson_nll_loss
    input
    target
    (if log_input then 1 else 0)
    (if full then 1 else 0)
    eps
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let poisson_out ~out self = stubs_poisson_out out self |> with_tensor_gc
let polar ~abs ~angle = stubs_polar abs angle |> with_tensor_gc
let polar_out ~out ~abs ~angle = stubs_polar_out out abs angle |> with_tensor_gc
let polygamma ~n self = stubs_polygamma (Int64.of_int n) self |> with_tensor_gc
let polygamma_ self ~n = stubs_polygamma_ self (Int64.of_int n) |> with_tensor_gc

let polygamma_out ~out ~n self =
  stubs_polygamma_out out (Int64.of_int n) self |> with_tensor_gc
;;

let positive self = stubs_positive self |> with_tensor_gc
let pow self ~exponent = stubs_pow self exponent |> with_tensor_gc
let pow_ self ~exponent = stubs_pow_ self exponent |> with_tensor_gc
let pow_scalar self ~exponent = stubs_pow_scalar self exponent |> with_tensor_gc

let pow_scalar_out ~out self ~exponent =
  stubs_pow_scalar_out out self exponent |> with_tensor_gc
;;

let pow_tensor_ self ~exponent = stubs_pow_tensor_ self exponent |> with_tensor_gc

let pow_tensor_scalar self ~exponent =
  stubs_pow_tensor_scalar self exponent |> with_tensor_gc
;;

let pow_tensor_scalar_out ~out self ~exponent =
  stubs_pow_tensor_scalar_out out self exponent |> with_tensor_gc
;;

let pow_tensor_tensor_out ~out self ~exponent =
  stubs_pow_tensor_tensor_out out self exponent |> with_tensor_gc
;;

let prelu self ~weight = stubs_prelu self weight |> with_tensor_gc
let prod self ~dtype = stubs_prod self (Kind.packed_to_int dtype) |> with_tensor_gc

let prod_dim_int self ~dim ~keepdim ~dtype =
  stubs_prod_dim_int
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let prod_int_out ~out self ~dim ~keepdim ~dtype =
  stubs_prod_int_out
    out
    self
    (Int64.of_int dim)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let prod_out ~out self ~dtype =
  stubs_prod_out out self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let put self ~index ~source ~accumulate =
  stubs_put self index source (if accumulate then 1 else 0) |> with_tensor_gc
;;

let put_ self ~index ~source ~accumulate =
  stubs_put_ self index source (if accumulate then 1 else 0) |> with_tensor_gc
;;

let put_out ~out self ~index ~source ~accumulate =
  stubs_put_out out self index source (if accumulate then 1 else 0) |> with_tensor_gc
;;

let q_per_channel_axis self = stubs_q_per_channel_axis self
let q_per_channel_scales self = stubs_q_per_channel_scales self |> with_tensor_gc

let q_per_channel_scales_out ~out self =
  stubs_q_per_channel_scales_out out self |> with_tensor_gc
;;

let q_per_channel_zero_points self =
  stubs_q_per_channel_zero_points self |> with_tensor_gc
;;

let q_per_channel_zero_points_out ~out self =
  stubs_q_per_channel_zero_points_out out self |> with_tensor_gc
;;

let q_scale self = stubs_q_scale self
let q_zero_point self = stubs_q_zero_point self

let qr self ~some =
  let out__ = CArray.make raw_tensor 2 in
  stubs_qr (CArray.start out__) self (if some then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let qr_q ~q ~r self ~some =
  let out__ = CArray.make raw_tensor 2 in
  stubs_qr_q (CArray.start out__) q r self (if some then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let quantile self ~q ~dim ~keepdim ~interpolation =
  stubs_quantile
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let quantile_out ~out self ~q ~dim ~keepdim ~interpolation =
  stubs_quantile_out
    out
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let quantile_scalar self ~q ~dim ~keepdim ~interpolation =
  stubs_quantile_scalar
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let quantile_scalar_out ~out self ~q ~dim ~keepdim ~interpolation =
  stubs_quantile_scalar_out
    out
    self
    q
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (if keepdim then 1 else 0)
    interpolation
  |> with_tensor_gc
;;

let quantize_per_channel self ~scales ~zero_points ~axis ~dtype =
  stubs_quantize_per_channel
    self
    scales
    zero_points
    (Int64.of_int axis)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let quantize_per_channel_out ~out self ~scales ~zero_points ~axis ~dtype =
  stubs_quantize_per_channel_out
    out
    self
    scales
    zero_points
    (Int64.of_int axis)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let quantize_per_tensor self ~scale ~zero_point ~dtype =
  stubs_quantize_per_tensor
    self
    scale
    (Int64.of_int zero_point)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let quantize_per_tensor_dynamic self ~dtype ~reduce_range =
  stubs_quantize_per_tensor_dynamic
    self
    (Kind.packed_to_int dtype)
    (if reduce_range then 1 else 0)
  |> with_tensor_gc
;;

let quantize_per_tensor_dynamic_out ~out self ~dtype ~reduce_range =
  stubs_quantize_per_tensor_dynamic_out
    out
    self
    (Kind.packed_to_int dtype)
    (if reduce_range then 1 else 0)
  |> with_tensor_gc
;;

let quantize_per_tensor_out ~out self ~scale ~zero_point ~dtype =
  stubs_quantize_per_tensor_out
    out
    self
    scale
    (Int64.of_int zero_point)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let quantize_per_tensor_tensor_qparams self ~scale ~zero_point ~dtype =
  stubs_quantize_per_tensor_tensor_qparams
    self
    scale
    zero_point
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let quantize_per_tensor_tensor_qparams_out ~out self ~scale ~zero_point ~dtype =
  stubs_quantize_per_tensor_tensor_qparams_out
    out
    self
    scale
    zero_point
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let quantize_per_tensor_tensors tensors ~scales ~zero_points ~dtype =
  let result =
    stubs_quantize_per_tensor_tensors
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      scales
      zero_points
      (Kind.packed_to_int dtype)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let quantize_per_tensor_tensors_out ~out tensors ~scales ~zero_points ~dtype =
  let result =
    stubs_quantize_per_tensor_tensors_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      scales
      zero_points
      (Kind.packed_to_int dtype)
  in
  keep_values_alive out;
  keep_values_alive tensors;
  result
;;

let quantized_batch_norm
  input
  ~weight
  ~bias
  ~mean
  ~var
  ~eps
  ~output_scale
  ~output_zero_point
  =
  stubs_quantized_batch_norm
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    mean
    var
    eps
    output_scale
    (Int64.of_int output_zero_point)
  |> with_tensor_gc
;;

let quantized_batch_norm_out
  ~out
  input
  ~weight
  ~bias
  ~mean
  ~var
  ~eps
  ~output_scale
  ~output_zero_point
  =
  stubs_quantized_batch_norm_out
    out
    input
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    mean
    var
    eps
    output_scale
    (Int64.of_int output_zero_point)
  |> with_tensor_gc
;;

let quantized_gru_cell
  input
  ~hx
  ~w_ih
  ~w_hh
  ~b_ih
  ~b_hh
  ~packed_ih
  ~packed_hh
  ~col_offsets_ih
  ~col_offsets_hh
  ~scale_ih
  ~scale_hh
  ~zero_point_ih
  ~zero_point_hh
  =
  stubs_quantized_gru_cell
    input
    hx
    w_ih
    w_hh
    b_ih
    b_hh
    packed_ih
    packed_hh
    col_offsets_ih
    col_offsets_hh
    scale_ih
    scale_hh
    zero_point_ih
    zero_point_hh
  |> with_tensor_gc
;;

let quantized_lstm_cell
  input
  ~hx
  ~w_ih
  ~w_hh
  ~b_ih
  ~b_hh
  ~packed_ih
  ~packed_hh
  ~col_offsets_ih
  ~col_offsets_hh
  ~scale_ih
  ~scale_hh
  ~zero_point_ih
  ~zero_point_hh
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_quantized_lstm_cell
    (CArray.start out__)
    input
    (CArray.of_list gc_tensor hx |> CArray.start)
    (List.length hx)
    w_ih
    w_hh
    b_ih
    b_hh
    packed_ih
    packed_hh
    col_offsets_ih
    col_offsets_hh
    scale_ih
    scale_hh
    zero_point_ih
    zero_point_hh;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive hx;
  t0, t1
;;

let quantized_max_pool1d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_quantized_max_pool1d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let quantized_max_pool1d_out ~out self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_quantized_max_pool1d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let quantized_max_pool2d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_quantized_max_pool2d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let quantized_max_pool2d_out ~out self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_quantized_max_pool2d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let quantized_max_pool3d self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_quantized_max_pool3d
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let quantized_max_pool3d_out ~out self ~kernel_size ~stride ~padding ~dilation ~ceil_mode =
  stubs_quantized_max_pool3d_out
    out
    self
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
    (if ceil_mode then 1 else 0)
  |> with_tensor_gc
;;

let quantized_rnn_relu_cell
  input
  ~hx
  ~w_ih
  ~w_hh
  ~b_ih
  ~b_hh
  ~packed_ih
  ~packed_hh
  ~col_offsets_ih
  ~col_offsets_hh
  ~scale_ih
  ~scale_hh
  ~zero_point_ih
  ~zero_point_hh
  =
  stubs_quantized_rnn_relu_cell
    input
    hx
    w_ih
    w_hh
    b_ih
    b_hh
    packed_ih
    packed_hh
    col_offsets_ih
    col_offsets_hh
    scale_ih
    scale_hh
    zero_point_ih
    zero_point_hh
  |> with_tensor_gc
;;

let quantized_rnn_tanh_cell
  input
  ~hx
  ~w_ih
  ~w_hh
  ~b_ih
  ~b_hh
  ~packed_ih
  ~packed_hh
  ~col_offsets_ih
  ~col_offsets_hh
  ~scale_ih
  ~scale_hh
  ~zero_point_ih
  ~zero_point_hh
  =
  stubs_quantized_rnn_tanh_cell
    input
    hx
    w_ih
    w_hh
    b_ih
    b_hh
    packed_ih
    packed_hh
    col_offsets_ih
    col_offsets_hh
    scale_ih
    scale_hh
    zero_point_ih
    zero_point_hh
  |> with_tensor_gc
;;

let rad2deg self = stubs_rad2deg self |> with_tensor_gc
let rad2deg_ self = stubs_rad2deg_ self |> with_tensor_gc
let rad2deg_out ~out self = stubs_rad2deg_out out self |> with_tensor_gc

let rand ~size ~options =
  stubs_rand
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let rand_like self = stubs_rand_like self |> with_tensor_gc
let rand_like_out ~out self = stubs_rand_like_out out self |> with_tensor_gc

let rand_out ~out ~size =
  stubs_rand_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let randint ~high ~size ~options =
  stubs_randint
    (Int64.of_int high)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let randint_like self ~high =
  stubs_randint_like self (Int64.of_int high) |> with_tensor_gc
;;

let randint_like_low_dtype self ~low ~high =
  stubs_randint_like_low_dtype self (Int64.of_int low) (Int64.of_int high)
  |> with_tensor_gc
;;

let randint_like_low_dtype_out ~out self ~low ~high =
  stubs_randint_like_low_dtype_out out self (Int64.of_int low) (Int64.of_int high)
  |> with_tensor_gc
;;

let randint_like_out ~out self ~high =
  stubs_randint_like_out out self (Int64.of_int high) |> with_tensor_gc
;;

let randint_low ~low ~high ~size ~options =
  stubs_randint_low
    (Int64.of_int low)
    (Int64.of_int high)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let randint_low_out ~out ~low ~high ~size =
  stubs_randint_low_out
    out
    (Int64.of_int low)
    (Int64.of_int high)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let randint_out ~out ~high ~size =
  stubs_randint_out
    out
    (Int64.of_int high)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let randn ~size ~options =
  stubs_randn
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let randn_like self = stubs_randn_like self |> with_tensor_gc
let randn_like_out ~out self = stubs_randn_like_out out self |> with_tensor_gc

let randn_out ~out ~size =
  stubs_randn_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let random self = stubs_random self |> with_tensor_gc
let random_ self = stubs_random_ self |> with_tensor_gc

let random_from self ~from ~to_ =
  stubs_random_from
    self
    (Int64.of_int from)
    (match to_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match to_ with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let random_from_ self ~from ~to_ =
  stubs_random_from_
    self
    (Int64.of_int from)
    (match to_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match to_ with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let random_from_out ~out self ~from ~to_ =
  stubs_random_from_out
    out
    self
    (Int64.of_int from)
    (match to_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match to_ with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let random_out ~out self = stubs_random_out out self |> with_tensor_gc
let random_to self ~to_ = stubs_random_to self (Int64.of_int to_) |> with_tensor_gc
let random_to_ self ~to_ = stubs_random_to_ self (Int64.of_int to_) |> with_tensor_gc

let random_to_out ~out self ~to_ =
  stubs_random_to_out out self (Int64.of_int to_) |> with_tensor_gc
;;

let randperm ~n ~options =
  stubs_randperm
    (Int64.of_int n)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let randperm_out ~out ~n = stubs_randperm_out out (Int64.of_int n) |> with_tensor_gc

let range ~start ~end_ ~options =
  stubs_range start end_ (Kind.packed_to_int (fst options)) (Device.to_int (snd options))
  |> with_tensor_gc
;;

let range_out ?step ~out ~start ~end_ () =
  stubs_range_out
    out
    start
    end_
    (match step with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let range_out_ ~out ~start ~end_ = stubs_range_out_ out start end_ |> with_tensor_gc

let range_step ?step ~start ~end_ ~options () =
  stubs_range_step
    start
    end_
    (match step with
     | Some v -> v
     | None -> none_scalar)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let ravel self = stubs_ravel self |> with_tensor_gc
let real self = stubs_real self |> with_tensor_gc
let reciprocal self = stubs_reciprocal self |> with_tensor_gc
let reciprocal_ self = stubs_reciprocal_ self |> with_tensor_gc
let reciprocal_out ~out self = stubs_reciprocal_out out self |> with_tensor_gc

let reflection_pad1d self ~padding =
  stubs_reflection_pad1d
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad1d_backward ~grad_output self ~padding =
  stubs_reflection_pad1d_backward
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad1d_backward_grad_input ~grad_input ~grad_output self ~padding =
  stubs_reflection_pad1d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad1d_out ~out self ~padding =
  stubs_reflection_pad1d_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad2d self ~padding =
  stubs_reflection_pad2d
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad2d_backward ~grad_output self ~padding =
  stubs_reflection_pad2d_backward
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad2d_backward_grad_input ~grad_input ~grad_output self ~padding =
  stubs_reflection_pad2d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad2d_out ~out self ~padding =
  stubs_reflection_pad2d_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad3d self ~padding =
  stubs_reflection_pad3d
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad3d_backward ~grad_output self ~padding =
  stubs_reflection_pad3d_backward
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad3d_backward_grad_input ~grad_input ~grad_output self ~padding =
  stubs_reflection_pad3d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let reflection_pad3d_out ~out self ~padding =
  stubs_reflection_pad3d_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let relu self = stubs_relu self |> with_tensor_gc
let relu6 self = stubs_relu6 self |> with_tensor_gc
let relu6_ self = stubs_relu6_ self |> with_tensor_gc
let relu_ self = stubs_relu_ self |> with_tensor_gc
let relu_out ~out self = stubs_relu_out out self |> with_tensor_gc
let remainder self other = stubs_remainder self other |> with_tensor_gc
let remainder_ self other = stubs_remainder_ self other |> with_tensor_gc

let remainder_scalar_out ~out self other =
  stubs_remainder_scalar_out out self other |> with_tensor_gc
;;

let remainder_scalar_tensor self other =
  stubs_remainder_scalar_tensor self other |> with_tensor_gc
;;

let remainder_scalar_tensor_out ~out self other =
  stubs_remainder_scalar_tensor_out out self other |> with_tensor_gc
;;

let remainder_tensor self other = stubs_remainder_tensor self other |> with_tensor_gc
let remainder_tensor_ self other = stubs_remainder_tensor_ self other |> with_tensor_gc

let remainder_tensor_out ~out self other =
  stubs_remainder_tensor_out out self other |> with_tensor_gc
;;

let renorm self ~p ~dim ~maxnorm =
  stubs_renorm self p (Int64.of_int dim) maxnorm |> with_tensor_gc
;;

let renorm_ self ~p ~dim ~maxnorm =
  stubs_renorm_ self p (Int64.of_int dim) maxnorm |> with_tensor_gc
;;

let renorm_out ~out self ~p ~dim ~maxnorm =
  stubs_renorm_out out self p (Int64.of_int dim) maxnorm |> with_tensor_gc
;;

let repeat self ~repeats =
  stubs_repeat
    self
    (List.map Int64.of_int repeats |> CArray.of_list int64_t |> CArray.start)
    (List.length repeats)
  |> with_tensor_gc
;;

let repeat_interleave ~repeats ~output_size =
  stubs_repeat_interleave
    repeats
    (match output_size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match output_size with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let repeat_interleave_self_int self ~repeats ~dim ~output_size =
  stubs_repeat_interleave_self_int
    self
    (Int64.of_int repeats)
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (match output_size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match output_size with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let repeat_interleave_self_tensor self ~repeats ~dim ~output_size =
  stubs_repeat_interleave_self_tensor
    self
    repeats
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
    (match output_size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match output_size with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let repeat_interleave_tensor_out ~out ~repeats ~output_size =
  stubs_repeat_interleave_tensor_out
    out
    repeats
    (match output_size with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match output_size with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let repeat_out ~out self ~repeats =
  stubs_repeat_out
    out
    self
    (List.map Int64.of_int repeats |> CArray.of_list int64_t |> CArray.start)
    (List.length repeats)
  |> with_tensor_gc
;;

let replication_pad1d self ~padding =
  stubs_replication_pad1d
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad1d_backward ~grad_output self ~padding =
  stubs_replication_pad1d_backward
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad1d_backward_grad_input ~grad_input ~grad_output self ~padding =
  stubs_replication_pad1d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad1d_out ~out self ~padding =
  stubs_replication_pad1d_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad2d self ~padding =
  stubs_replication_pad2d
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad2d_backward ~grad_output self ~padding =
  stubs_replication_pad2d_backward
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad2d_backward_grad_input ~grad_input ~grad_output self ~padding =
  stubs_replication_pad2d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad2d_out ~out self ~padding =
  stubs_replication_pad2d_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad3d self ~padding =
  stubs_replication_pad3d
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad3d_backward ~grad_output self ~padding =
  stubs_replication_pad3d_backward
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad3d_backward_grad_input ~grad_input ~grad_output self ~padding =
  stubs_replication_pad3d_backward_grad_input
    grad_input
    grad_output
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let replication_pad3d_out ~out self ~padding =
  stubs_replication_pad3d_out
    out
    self
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let requires_grad_ self ~requires_grad =
  stubs_requires_grad_ self (if requires_grad then 1 else 0) |> with_tensor_gc
;;

let reshape self ~shape =
  stubs_reshape
    self
    (List.map Int64.of_int shape |> CArray.of_list int64_t |> CArray.start)
    (List.length shape)
  |> with_tensor_gc
;;

let reshape_as self other = stubs_reshape_as self other |> with_tensor_gc

let resize self ~size =
  stubs_resize
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let resize_ self ~size =
  stubs_resize_
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let resize_as self ~the_template = stubs_resize_as self the_template |> with_tensor_gc
let resize_as_ self ~the_template = stubs_resize_as_ self the_template |> with_tensor_gc

let resize_as_out ~out self ~the_template =
  stubs_resize_as_out out self the_template |> with_tensor_gc
;;

let resize_as_sparse self ~the_template =
  stubs_resize_as_sparse self the_template |> with_tensor_gc
;;

let resize_as_sparse_ self ~the_template =
  stubs_resize_as_sparse_ self the_template |> with_tensor_gc
;;

let resize_as_sparse_out ~out self ~the_template =
  stubs_resize_as_sparse_out out self the_template |> with_tensor_gc
;;

let resize_out ~out self ~size =
  stubs_resize_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let resolve_conj self = stubs_resolve_conj self |> with_tensor_gc
let resolve_neg self = stubs_resolve_neg self |> with_tensor_gc
let retains_grad self = stubs_retains_grad self

let rms_norm input ~normalized_shape ~weight ~eps =
  stubs_rms_norm
    input
    (List.map Int64.of_int normalized_shape |> CArray.of_list int64_t |> CArray.start)
    (List.length normalized_shape)
    (match weight with
     | Some v -> v
     | None -> none_gc_tensor)
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let rnn_relu
  input
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_rnn_relu
    (CArray.start out__)
    input
    hx
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive params;
  t0, t1
;;

let rnn_relu_cell input ~hx ~w_ih ~w_hh ~b_ih ~b_hh =
  stubs_rnn_relu_cell
    input
    hx
    w_ih
    w_hh
    (match b_ih with
     | Some v -> v
     | None -> none_gc_tensor)
    (match b_hh with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let rnn_relu_data
  ~data
  ~batch_sizes
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_rnn_relu_data
    (CArray.start out__)
    data
    batch_sizes
    hx
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive params;
  t0, t1
;;

let rnn_tanh
  input
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  ~batch_first
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_rnn_tanh
    (CArray.start out__)
    input
    hx
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0)
    (if batch_first then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive params;
  t0, t1
;;

let rnn_tanh_cell input ~hx ~w_ih ~w_hh ~b_ih ~b_hh =
  stubs_rnn_tanh_cell
    input
    hx
    w_ih
    w_hh
    (match b_ih with
     | Some v -> v
     | None -> none_gc_tensor)
    (match b_hh with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let rnn_tanh_data
  ~data
  ~batch_sizes
  ~hx
  ~params
  ~has_biases
  ~num_layers
  ~dropout
  ~train
  ~bidirectional
  =
  let out__ = CArray.make raw_tensor 2 in
  stubs_rnn_tanh_data
    (CArray.start out__)
    data
    batch_sizes
    hx
    (CArray.of_list gc_tensor params |> CArray.start)
    (List.length params)
    (if has_biases then 1 else 0)
    (Int64.of_int num_layers)
    dropout
    (if train then 1 else 0)
    (if bidirectional then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  keep_values_alive params;
  t0, t1
;;

let roll self ~shifts ~dims =
  stubs_roll
    self
    (List.map Int64.of_int shifts |> CArray.of_list int64_t |> CArray.start)
    (List.length shifts)
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let roll_out ~out self ~shifts ~dims =
  stubs_roll_out
    out
    self
    (List.map Int64.of_int shifts |> CArray.of_list int64_t |> CArray.start)
    (List.length shifts)
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let rot90 self ~k ~dims =
  stubs_rot90
    self
    (Int64.of_int k)
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let rot90_out ~out self ~k ~dims =
  stubs_rot90_out
    out
    self
    (Int64.of_int k)
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let round self = stubs_round self |> with_tensor_gc
let round_ self = stubs_round_ self |> with_tensor_gc

let round_decimals self ~decimals =
  stubs_round_decimals self (Int64.of_int decimals) |> with_tensor_gc
;;

let round_decimals_ self ~decimals =
  stubs_round_decimals_ self (Int64.of_int decimals) |> with_tensor_gc
;;

let round_decimals_out ~out self ~decimals =
  stubs_round_decimals_out out self (Int64.of_int decimals) |> with_tensor_gc
;;

let round_out ~out self = stubs_round_out out self |> with_tensor_gc
let row_indices self = stubs_row_indices self |> with_tensor_gc
let row_indices_copy self = stubs_row_indices_copy self |> with_tensor_gc
let row_indices_copy_out ~out self = stubs_row_indices_copy_out out self |> with_tensor_gc

let row_stack tensors =
  let result =
    stubs_row_stack
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let row_stack_out ~out tensors =
  let result =
    stubs_row_stack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let rrelu ?lower ?upper self ~training =
  stubs_rrelu
    self
    (match lower with
     | Some v -> v
     | None -> none_scalar)
    (match upper with
     | Some v -> v
     | None -> none_scalar)
    (if training then 1 else 0)
  |> with_tensor_gc
;;

let rrelu_ ?lower ?upper self ~training =
  stubs_rrelu_
    self
    (match lower with
     | Some v -> v
     | None -> none_scalar)
    (match upper with
     | Some v -> v
     | None -> none_scalar)
    (if training then 1 else 0)
  |> with_tensor_gc
;;

let rrelu_with_noise ?lower ?upper self ~noise ~training =
  stubs_rrelu_with_noise
    self
    noise
    (match lower with
     | Some v -> v
     | None -> none_scalar)
    (match upper with
     | Some v -> v
     | None -> none_scalar)
    (if training then 1 else 0)
  |> with_tensor_gc
;;

let rrelu_with_noise_ ?lower ?upper self ~noise ~training =
  stubs_rrelu_with_noise_
    self
    noise
    (match lower with
     | Some v -> v
     | None -> none_scalar)
    (match upper with
     | Some v -> v
     | None -> none_scalar)
    (if training then 1 else 0)
  |> with_tensor_gc
;;

let rrelu_with_noise_backward
  ~grad_output
  self
  ~noise
  ~lower
  ~upper
  ~training
  ~self_is_result
  =
  stubs_rrelu_with_noise_backward
    grad_output
    self
    noise
    lower
    upper
    (if training then 1 else 0)
    (if self_is_result then 1 else 0)
  |> with_tensor_gc
;;

let rrelu_with_noise_backward_out
  ~out
  ~grad_output
  self
  ~noise
  ~lower
  ~upper
  ~training
  ~self_is_result
  =
  stubs_rrelu_with_noise_backward_out
    out
    grad_output
    self
    noise
    lower
    upper
    (if training then 1 else 0)
    (if self_is_result then 1 else 0)
  |> with_tensor_gc
;;

let rrelu_with_noise_functional ?lower ?upper self ~noise ~training =
  let out__ = CArray.make raw_tensor 2 in
  stubs_rrelu_with_noise_functional
    (CArray.start out__)
    self
    noise
    (match lower with
     | Some v -> v
     | None -> none_scalar)
    (match upper with
     | Some v -> v
     | None -> none_scalar)
    (if training then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let rrelu_with_noise_out ?lower ?upper ~out self ~noise ~training =
  stubs_rrelu_with_noise_out
    out
    self
    noise
    (match lower with
     | Some v -> v
     | None -> none_scalar)
    (match upper with
     | Some v -> v
     | None -> none_scalar)
    (if training then 1 else 0)
  |> with_tensor_gc
;;

let rsqrt self = stubs_rsqrt self |> with_tensor_gc
let rsqrt_ self = stubs_rsqrt_ self |> with_tensor_gc
let rsqrt_out ~out self = stubs_rsqrt_out out self |> with_tensor_gc

let rsub ?alpha self other =
  stubs_rsub
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let rsub_scalar ?alpha self other =
  stubs_rsub_scalar
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let rsub_scalar_out ?alpha ~out self other =
  stubs_rsub_scalar_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let rsub_tensor_out ?alpha ~out self other =
  stubs_rsub_tensor_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let scalar_tensor ~s ~options =
  stubs_scalar_tensor s (Kind.packed_to_int (fst options)) (Device.to_int (snd options))
  |> with_tensor_gc
;;

let scalar_tensor_out ~out ~s = stubs_scalar_tensor_out out s |> with_tensor_gc

let scaled_dot_product_attention
  ~query
  ~key
  ~value
  ~attn_mask
  ~dropout_p
  ~is_causal
  ~scale
  ~enable_gqa
  =
  stubs_scaled_dot_product_attention
    query
    key
    value
    (match attn_mask with
     | Some v -> v
     | None -> none_gc_tensor)
    dropout_p
    (if is_causal then 1 else 0)
    (Option.value scale ~default:0.0)
    (match scale with
     | Some _ -> 0
     | None -> 1)
    (if enable_gqa then 1 else 0)
  |> with_tensor_gc
;;

let scatter self ~dim ~index ~src =
  stubs_scatter self (Int64.of_int dim) index src |> with_tensor_gc
;;

let scatter_ self ~dim ~index ~src =
  stubs_scatter_ self (Int64.of_int dim) index src |> with_tensor_gc
;;

let scatter_add self ~dim ~index ~src =
  stubs_scatter_add self (Int64.of_int dim) index src |> with_tensor_gc
;;

let scatter_add_ self ~dim ~index ~src =
  stubs_scatter_add_ self (Int64.of_int dim) index src |> with_tensor_gc
;;

let scatter_add_out ~out self ~dim ~index ~src =
  stubs_scatter_add_out out self (Int64.of_int dim) index src |> with_tensor_gc
;;

let scatter_reduce self ~dim ~index ~src ~reduce =
  stubs_scatter_reduce self (Int64.of_int dim) index src reduce |> with_tensor_gc
;;

let scatter_reduce_ self ~dim ~index ~src ~reduce =
  stubs_scatter_reduce_ self (Int64.of_int dim) index src reduce |> with_tensor_gc
;;

let scatter_reduce_out ~out self ~dim ~index ~src ~reduce =
  stubs_scatter_reduce_out out self (Int64.of_int dim) index src reduce |> with_tensor_gc
;;

let scatter_src_out ~out self ~dim ~index ~src =
  stubs_scatter_src_out out self (Int64.of_int dim) index src |> with_tensor_gc
;;

let scatter_value self ~dim ~index ~value =
  stubs_scatter_value self (Int64.of_int dim) index value |> with_tensor_gc
;;

let scatter_value_ self ~dim ~index ~value =
  stubs_scatter_value_ self (Int64.of_int dim) index value |> with_tensor_gc
;;

let scatter_value_out ~out self ~dim ~index ~value =
  stubs_scatter_value_out out self (Int64.of_int dim) index value |> with_tensor_gc
;;

let scatter_value_reduce self ~dim ~index ~value ~reduce =
  stubs_scatter_value_reduce self (Int64.of_int dim) index value reduce |> with_tensor_gc
;;

let scatter_value_reduce_ self ~dim ~index ~value ~reduce =
  stubs_scatter_value_reduce_ self (Int64.of_int dim) index value reduce |> with_tensor_gc
;;

let scatter_value_reduce_out ~out self ~dim ~index ~value ~reduce =
  stubs_scatter_value_reduce_out out self (Int64.of_int dim) index value reduce
  |> with_tensor_gc
;;

let searchsorted ~sorted_sequence self ~out_int32 ~right ~side ~sorter =
  stubs_searchsorted
    sorted_sequence
    self
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
    (Option.value side ~default:"")
    (match side with
     | Some _ -> 0
     | None -> 1)
    (match sorter with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let searchsorted_scalar ~sorted_sequence self ~out_int32 ~right ~side ~sorter =
  stubs_searchsorted_scalar
    sorted_sequence
    self
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
    (Option.value side ~default:"")
    (match side with
     | Some _ -> 0
     | None -> 1)
    (match sorter with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let searchsorted_scalar_out ~out ~sorted_sequence self ~out_int32 ~right ~side ~sorter =
  stubs_searchsorted_scalar_out
    out
    sorted_sequence
    self
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
    (Option.value side ~default:"")
    (match side with
     | Some _ -> 0
     | None -> 1)
    (match sorter with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let searchsorted_tensor_out ~out ~sorted_sequence self ~out_int32 ~right ~side ~sorter =
  stubs_searchsorted_tensor_out
    out
    sorted_sequence
    self
    (if out_int32 then 1 else 0)
    (if right then 1 else 0)
    (Option.value side ~default:"")
    (match side with
     | Some _ -> 0
     | None -> 1)
    (match sorter with
     | Some v -> v
     | None -> none_gc_tensor)
  |> with_tensor_gc
;;

let segment_reduce ~data ~reduce ~lengths ~indices ~offsets ~axis ~unsafe ~initial =
  stubs_segment_reduce
    data
    reduce
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (match indices with
     | Some v -> v
     | None -> none_gc_tensor)
    (match offsets with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int axis)
    (if unsafe then 1 else 0)
    initial
  |> with_tensor_gc
;;

let segment_reduce_out
  ~out
  ~data
  ~reduce
  ~lengths
  ~indices
  ~offsets
  ~axis
  ~unsafe
  ~initial
  =
  stubs_segment_reduce_out
    out
    data
    reduce
    (match lengths with
     | Some v -> v
     | None -> none_gc_tensor)
    (match indices with
     | Some v -> v
     | None -> none_gc_tensor)
    (match offsets with
     | Some v -> v
     | None -> none_gc_tensor)
    (Int64.of_int axis)
    (if unsafe then 1 else 0)
    initial
  |> with_tensor_gc
;;

let select self ~dim ~index =
  stubs_select self (Int64.of_int dim) (Int64.of_int index) |> with_tensor_gc
;;

let select_backward ~grad_output ~input_sizes ~dim ~index =
  stubs_select_backward
    grad_output
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int dim)
    (Int64.of_int index)
  |> with_tensor_gc
;;

let select_backward_out ~out ~grad_output ~input_sizes ~dim ~index =
  stubs_select_backward_out
    out
    grad_output
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int dim)
    (Int64.of_int index)
  |> with_tensor_gc
;;

let select_copy self ~dim ~index =
  stubs_select_copy self (Int64.of_int dim) (Int64.of_int index) |> with_tensor_gc
;;

let select_copy_int_out ~out self ~dim ~index =
  stubs_select_copy_int_out out self (Int64.of_int dim) (Int64.of_int index)
  |> with_tensor_gc
;;

let select_scatter self ~src ~dim ~index =
  stubs_select_scatter self src (Int64.of_int dim) (Int64.of_int index) |> with_tensor_gc
;;

let select_scatter_out ~out self ~src ~dim ~index =
  stubs_select_scatter_out out self src (Int64.of_int dim) (Int64.of_int index)
  |> with_tensor_gc
;;

let selu self = stubs_selu self |> with_tensor_gc
let selu_ self = stubs_selu_ self |> with_tensor_gc
let set self = stubs_set self |> with_tensor_gc
let set_ self = stubs_set_ self |> with_tensor_gc
let set_out ~out self = stubs_set_out out self |> with_tensor_gc

let set_requires_grad self ~r =
  stubs_set_requires_grad self (if r then 1 else 0) |> with_tensor_gc
;;

let set_source_tensor self ~source = stubs_set_source_tensor self source |> with_tensor_gc

let set_source_tensor_ self ~source =
  stubs_set_source_tensor_ self source |> with_tensor_gc
;;

let set_source_tensor_out ~out self ~source =
  stubs_set_source_tensor_out out self source |> with_tensor_gc
;;

let set_source_tensor_storage_offset_ self ~source ~storage_offset ~size ~stride =
  stubs_set_source_tensor_storage_offset_
    self
    source
    (Int64.of_int storage_offset)
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
  |> with_tensor_gc
;;

let sgn self = stubs_sgn self |> with_tensor_gc
let sgn_ self = stubs_sgn_ self |> with_tensor_gc
let sgn_out ~out self = stubs_sgn_out out self |> with_tensor_gc
let sigmoid self = stubs_sigmoid self |> with_tensor_gc
let sigmoid_ self = stubs_sigmoid_ self |> with_tensor_gc

let sigmoid_backward ~grad_output ~output =
  stubs_sigmoid_backward grad_output output |> with_tensor_gc
;;

let sigmoid_backward_grad_input ~grad_input ~grad_output ~output =
  stubs_sigmoid_backward_grad_input grad_input grad_output output |> with_tensor_gc
;;

let sigmoid_out ~out self = stubs_sigmoid_out out self |> with_tensor_gc
let sign self = stubs_sign self |> with_tensor_gc
let sign_ self = stubs_sign_ self |> with_tensor_gc
let sign_out ~out self = stubs_sign_out out self |> with_tensor_gc
let signbit self = stubs_signbit self |> with_tensor_gc
let signbit_out ~out self = stubs_signbit_out out self |> with_tensor_gc
let silu self = stubs_silu self |> with_tensor_gc
let silu_ self = stubs_silu_ self |> with_tensor_gc

let silu_backward ~grad_output self =
  stubs_silu_backward grad_output self |> with_tensor_gc
;;

let silu_backward_grad_input ~grad_input ~grad_output self =
  stubs_silu_backward_grad_input grad_input grad_output self |> with_tensor_gc
;;

let silu_out ~out self = stubs_silu_out out self |> with_tensor_gc
let sin self = stubs_sin self |> with_tensor_gc
let sin_ self = stubs_sin_ self |> with_tensor_gc
let sin_out ~out self = stubs_sin_out out self |> with_tensor_gc
let sinc self = stubs_sinc self |> with_tensor_gc
let sinc_ self = stubs_sinc_ self |> with_tensor_gc
let sinc_out ~out self = stubs_sinc_out out self |> with_tensor_gc
let sinh self = stubs_sinh self |> with_tensor_gc
let sinh_ self = stubs_sinh_ self |> with_tensor_gc
let sinh_out ~out self = stubs_sinh_out out self |> with_tensor_gc
let size self ~dim = stubs_size self (Int64.of_int dim)

let slice self ~dim ~start ~end_ ~step =
  stubs_slice
    self
    (Int64.of_int dim)
    (match start with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match start with
     | Some _ -> 0
     | None -> 1)
    (match end_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match end_ with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_backward ~grad_output ~input_sizes ~dim ~start ~end_ ~step =
  stubs_slice_backward
    grad_output
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int dim)
    (Int64.of_int start)
    (Int64.of_int end_)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_backward_out ~out ~grad_output ~input_sizes ~dim ~start ~end_ ~step =
  stubs_slice_backward_out
    out
    grad_output
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int dim)
    (Int64.of_int start)
    (Int64.of_int end_)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_copy self ~dim ~start ~end_ ~step =
  stubs_slice_copy
    self
    (Int64.of_int dim)
    (match start with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match start with
     | Some _ -> 0
     | None -> 1)
    (match end_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match end_ with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_copy_tensor_out ~out self ~dim ~start ~end_ ~step =
  stubs_slice_copy_tensor_out
    out
    self
    (Int64.of_int dim)
    (match start with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match start with
     | Some _ -> 0
     | None -> 1)
    (match end_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match end_ with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_inverse self ~src ~dim ~start ~end_ ~step =
  stubs_slice_inverse
    self
    src
    (Int64.of_int dim)
    (match start with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match start with
     | Some _ -> 0
     | None -> 1)
    (match end_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match end_ with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_scatter self ~src ~dim ~start ~end_ ~step =
  stubs_slice_scatter
    self
    src
    (Int64.of_int dim)
    (match start with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match start with
     | Some _ -> 0
     | None -> 1)
    (match end_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match end_ with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slice_scatter_out ~out self ~src ~dim ~start ~end_ ~step =
  stubs_slice_scatter_out
    out
    self
    src
    (Int64.of_int dim)
    (match start with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match start with
     | Some _ -> 0
     | None -> 1)
    (match end_ with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match end_ with
     | Some _ -> 0
     | None -> 1)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let slogdet self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_slogdet (CArray.start out__) self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let slogdet_out ~sign ~logabsdet self =
  let out__ = CArray.make raw_tensor 2 in
  stubs_slogdet_out (CArray.start out__) sign logabsdet self;
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let slow_conv3d self ~weight ~kernel_size ~bias ~stride ~padding =
  stubs_slow_conv3d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let slow_conv3d_out ~out self ~weight ~kernel_size ~bias ~stride ~padding =
  stubs_slow_conv3d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
  |> with_tensor_gc
;;

let slow_conv_dilated2d self ~weight ~kernel_size ~bias ~stride ~padding ~dilation =
  stubs_slow_conv_dilated2d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_dilated2d_out
  ~out
  self
  ~weight
  ~kernel_size
  ~bias
  ~stride
  ~padding
  ~dilation
  =
  stubs_slow_conv_dilated2d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_dilated3d self ~weight ~kernel_size ~bias ~stride ~padding ~dilation =
  stubs_slow_conv_dilated3d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_dilated3d_out
  ~out
  self
  ~weight
  ~kernel_size
  ~bias
  ~stride
  ~padding
  ~dilation
  =
  stubs_slow_conv_dilated3d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_transpose2d
  self
  ~weight
  ~kernel_size
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~dilation
  =
  stubs_slow_conv_transpose2d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_transpose2d_out
  ~out
  self
  ~weight
  ~kernel_size
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~dilation
  =
  stubs_slow_conv_transpose2d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_transpose3d
  self
  ~weight
  ~kernel_size
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~dilation
  =
  stubs_slow_conv_transpose3d
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let slow_conv_transpose3d_out
  ~out
  self
  ~weight
  ~kernel_size
  ~bias
  ~stride
  ~padding
  ~output_padding
  ~dilation
  =
  stubs_slow_conv_transpose3d_out
    out
    self
    weight
    (List.map Int64.of_int kernel_size |> CArray.of_list int64_t |> CArray.start)
    (List.length kernel_size)
    (match bias with
     | Some v -> v
     | None -> none_gc_tensor)
    (List.map Int64.of_int stride |> CArray.of_list int64_t |> CArray.start)
    (List.length stride)
    (List.map Int64.of_int padding |> CArray.of_list int64_t |> CArray.start)
    (List.length padding)
    (List.map Int64.of_int output_padding |> CArray.of_list int64_t |> CArray.start)
    (List.length output_padding)
    (List.map Int64.of_int dilation |> CArray.of_list int64_t |> CArray.start)
    (List.length dilation)
  |> with_tensor_gc
;;

let smm self ~mat2 = stubs_smm self mat2 |> with_tensor_gc

let smooth_l1_loss self ~target ~reduction ~beta =
  stubs_smooth_l1_loss self target (Reduction.to_int reduction |> Int64.of_int) beta
  |> with_tensor_gc
;;

let smooth_l1_loss_backward ~grad_output self ~target ~reduction ~beta =
  stubs_smooth_l1_loss_backward
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    beta
  |> with_tensor_gc
;;

let smooth_l1_loss_backward_grad_input
  ~grad_input
  ~grad_output
  self
  ~target
  ~reduction
  ~beta
  =
  stubs_smooth_l1_loss_backward_grad_input
    grad_input
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    beta
  |> with_tensor_gc
;;

let smooth_l1_loss_out ~out self ~target ~reduction ~beta =
  stubs_smooth_l1_loss_out
    out
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
    beta
  |> with_tensor_gc
;;

let soft_margin_loss self ~target ~reduction =
  stubs_soft_margin_loss self target (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let soft_margin_loss_backward ~grad_output self ~target ~reduction =
  stubs_soft_margin_loss_backward
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let soft_margin_loss_backward_grad_input ~grad_input ~grad_output self ~target ~reduction =
  stubs_soft_margin_loss_backward_grad_input
    grad_input
    grad_output
    self
    target
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let soft_margin_loss_out ~out self ~target ~reduction =
  stubs_soft_margin_loss_out out self target (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let softmax self ~dim ~dtype =
  stubs_softmax self (Int64.of_int dim) (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let softmax_int_out ~out self ~dim ~dtype =
  stubs_softmax_int_out out self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let softplus ?beta ?threshold self =
  stubs_softplus
    self
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match threshold with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let softplus_backward ~grad_output self ~beta ~threshold =
  stubs_softplus_backward grad_output self beta threshold |> with_tensor_gc
;;

let softplus_backward_grad_input ~grad_input ~grad_output self ~beta ~threshold =
  stubs_softplus_backward_grad_input grad_input grad_output self beta threshold
  |> with_tensor_gc
;;

let softplus_out ?beta ?threshold ~out self =
  stubs_softplus_out
    out
    self
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match threshold with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let softshrink ?lambd self =
  stubs_softshrink
    self
    (match lambd with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let softshrink_backward ~grad_output self ~lambd =
  stubs_softshrink_backward grad_output self lambd |> with_tensor_gc
;;

let softshrink_backward_grad_input ~grad_input ~grad_output self ~lambd =
  stubs_softshrink_backward_grad_input grad_input grad_output self lambd |> with_tensor_gc
;;

let softshrink_out ?lambd ~out self =
  stubs_softshrink_out
    out
    self
    (match lambd with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sort self ~dim ~descending =
  let out__ = CArray.make raw_tensor 2 in
  stubs_sort (CArray.start out__) self (Int64.of_int dim) (if descending then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let sort_stable self ~stable ~dim ~descending =
  let out__ = CArray.make raw_tensor 2 in
  stubs_sort_stable
    (CArray.start out__)
    self
    (if stable then 1 else 0)
    (Int64.of_int dim)
    (if descending then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let sort_values ~values ~indices self ~dim ~descending =
  let out__ = CArray.make raw_tensor 2 in
  stubs_sort_values
    (CArray.start out__)
    values
    indices
    self
    (Int64.of_int dim)
    (if descending then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let sort_values_stable ~values ~indices self ~stable ~dim ~descending =
  let out__ = CArray.make raw_tensor 2 in
  stubs_sort_values_stable
    (CArray.start out__)
    values
    indices
    self
    (if stable then 1 else 0)
    (Int64.of_int dim)
    (if descending then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let sparse_bsc_tensor ~ccol_indices ~row_indices ~values ~options =
  stubs_sparse_bsc_tensor
    ccol_indices
    row_indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_bsc_tensor_ccol_row_value_size
  ~ccol_indices
  ~row_indices
  ~values
  ~size
  ~options
  =
  stubs_sparse_bsc_tensor_ccol_row_value_size
    ccol_indices
    row_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_bsr_tensor ~crow_indices ~col_indices ~values ~options =
  stubs_sparse_bsr_tensor
    crow_indices
    col_indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_bsr_tensor_crow_col_value_size
  ~crow_indices
  ~col_indices
  ~values
  ~size
  ~options
  =
  stubs_sparse_bsr_tensor_crow_col_value_size
    crow_indices
    col_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_compressed_tensor ~compressed_indices ~plain_indices ~values ~options =
  stubs_sparse_compressed_tensor
    compressed_indices
    plain_indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_compressed_tensor_comp_plain_value_size
  ~compressed_indices
  ~plain_indices
  ~values
  ~size
  ~options
  =
  stubs_sparse_compressed_tensor_comp_plain_value_size
    compressed_indices
    plain_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_coo_tensor ~size ~options =
  stubs_sparse_coo_tensor
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_coo_tensor_indices ~indices ~values ~options ~is_coalesced =
  stubs_sparse_coo_tensor_indices
    indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    (if is_coalesced then 1 else 0)
  |> with_tensor_gc
;;

let sparse_coo_tensor_indices_size ~indices ~values ~size ~options ~is_coalesced =
  stubs_sparse_coo_tensor_indices_size
    indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    (if is_coalesced then 1 else 0)
  |> with_tensor_gc
;;

let sparse_coo_tensor_size_out ~out ~size =
  stubs_sparse_coo_tensor_size_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let sparse_csc_tensor ~ccol_indices ~row_indices ~values ~options =
  stubs_sparse_csc_tensor
    ccol_indices
    row_indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_csc_tensor_ccol_row_value_size
  ~ccol_indices
  ~row_indices
  ~values
  ~size
  ~options
  =
  stubs_sparse_csc_tensor_ccol_row_value_size
    ccol_indices
    row_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_csr_tensor ~crow_indices ~col_indices ~values ~options =
  stubs_sparse_csr_tensor
    crow_indices
    col_indices
    values
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_csr_tensor_crow_col_value_size
  ~crow_indices
  ~col_indices
  ~values
  ~size
  ~options
  =
  stubs_sparse_csr_tensor_crow_col_value_size
    crow_indices
    col_indices
    values
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let sparse_dim self = stubs_sparse_dim self
let sparse_mask self ~mask = stubs_sparse_mask self mask |> with_tensor_gc

let sparse_mask_out ~out self ~mask =
  stubs_sparse_mask_out out self mask |> with_tensor_gc
;;

let sparse_resize self ~size ~sparse_dim ~dense_dim =
  stubs_sparse_resize
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
  |> with_tensor_gc
;;

let sparse_resize_ self ~size ~sparse_dim ~dense_dim =
  stubs_sparse_resize_
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
  |> with_tensor_gc
;;

let sparse_resize_and_clear self ~size ~sparse_dim ~dense_dim =
  stubs_sparse_resize_and_clear
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
  |> with_tensor_gc
;;

let sparse_resize_and_clear_ self ~size ~sparse_dim ~dense_dim =
  stubs_sparse_resize_and_clear_
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
  |> with_tensor_gc
;;

let sparse_resize_and_clear_out ~out self ~size ~sparse_dim ~dense_dim =
  stubs_sparse_resize_and_clear_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
  |> with_tensor_gc
;;

let sparse_resize_out ~out self ~size ~sparse_dim ~dense_dim =
  stubs_sparse_resize_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Int64.of_int sparse_dim)
    (Int64.of_int dense_dim)
  |> with_tensor_gc
;;

let sparse_sampled_addmm ?beta ?alpha self ~mat1 ~mat2 =
  stubs_sparse_sampled_addmm
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sparse_sampled_addmm_out ?beta ?alpha ~out self ~mat1 ~mat2 =
  stubs_sparse_sampled_addmm_out
    out
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let special_airy_ai ~x = stubs_special_airy_ai x |> with_tensor_gc
let special_airy_ai_out ~out ~x = stubs_special_airy_ai_out out x |> with_tensor_gc
let special_bessel_j0 self = stubs_special_bessel_j0 self |> with_tensor_gc

let special_bessel_j0_out ~out self =
  stubs_special_bessel_j0_out out self |> with_tensor_gc
;;

let special_bessel_j1 self = stubs_special_bessel_j1 self |> with_tensor_gc

let special_bessel_j1_out ~out self =
  stubs_special_bessel_j1_out out self |> with_tensor_gc
;;

let special_bessel_y0 self = stubs_special_bessel_y0 self |> with_tensor_gc

let special_bessel_y0_out ~out self =
  stubs_special_bessel_y0_out out self |> with_tensor_gc
;;

let special_bessel_y1 self = stubs_special_bessel_y1 self |> with_tensor_gc

let special_bessel_y1_out ~out self =
  stubs_special_bessel_y1_out out self |> with_tensor_gc
;;

let special_chebyshev_polynomial_t ~x ~n =
  stubs_special_chebyshev_polynomial_t x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_t_n_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_t_n_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_t_n_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_t_n_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_t_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_t_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_t_x_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_t_x_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_t_x_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_t_x_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_u ~x ~n =
  stubs_special_chebyshev_polynomial_u x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_u_n_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_u_n_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_u_n_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_u_n_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_u_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_u_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_u_x_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_u_x_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_u_x_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_u_x_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_v ~x ~n =
  stubs_special_chebyshev_polynomial_v x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_v_n_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_v_n_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_v_n_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_v_n_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_v_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_v_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_v_x_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_v_x_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_v_x_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_v_x_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_w ~x ~n =
  stubs_special_chebyshev_polynomial_w x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_w_n_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_w_n_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_w_n_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_w_n_scalar_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_w_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_w_out out x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_w_x_scalar ~x ~n =
  stubs_special_chebyshev_polynomial_w_x_scalar x n |> with_tensor_gc
;;

let special_chebyshev_polynomial_w_x_scalar_out ~out ~x ~n =
  stubs_special_chebyshev_polynomial_w_x_scalar_out out x n |> with_tensor_gc
;;

let special_digamma self = stubs_special_digamma self |> with_tensor_gc
let special_digamma_out ~out self = stubs_special_digamma_out out self |> with_tensor_gc
let special_entr self = stubs_special_entr self |> with_tensor_gc
let special_entr_out ~out self = stubs_special_entr_out out self |> with_tensor_gc
let special_erf self = stubs_special_erf self |> with_tensor_gc
let special_erf_out ~out self = stubs_special_erf_out out self |> with_tensor_gc
let special_erfc self = stubs_special_erfc self |> with_tensor_gc
let special_erfc_out ~out self = stubs_special_erfc_out out self |> with_tensor_gc
let special_erfcx self = stubs_special_erfcx self |> with_tensor_gc
let special_erfcx_out ~out self = stubs_special_erfcx_out out self |> with_tensor_gc
let special_erfinv self = stubs_special_erfinv self |> with_tensor_gc
let special_erfinv_out ~out self = stubs_special_erfinv_out out self |> with_tensor_gc
let special_exp2 self = stubs_special_exp2 self |> with_tensor_gc
let special_exp2_out ~out self = stubs_special_exp2_out out self |> with_tensor_gc
let special_expit self = stubs_special_expit self |> with_tensor_gc
let special_expit_out ~out self = stubs_special_expit_out out self |> with_tensor_gc
let special_expm1 self = stubs_special_expm1 self |> with_tensor_gc
let special_expm1_out ~out self = stubs_special_expm1_out out self |> with_tensor_gc
let special_gammainc self other = stubs_special_gammainc self other |> with_tensor_gc

let special_gammainc_out ~out self other =
  stubs_special_gammainc_out out self other |> with_tensor_gc
;;

let special_gammaincc self other = stubs_special_gammaincc self other |> with_tensor_gc

let special_gammaincc_out ~out self other =
  stubs_special_gammaincc_out out self other |> with_tensor_gc
;;

let special_gammaln self = stubs_special_gammaln self |> with_tensor_gc
let special_gammaln_out ~out self = stubs_special_gammaln_out out self |> with_tensor_gc

let special_hermite_polynomial_h ~x ~n =
  stubs_special_hermite_polynomial_h x n |> with_tensor_gc
;;

let special_hermite_polynomial_h_n_scalar ~x ~n =
  stubs_special_hermite_polynomial_h_n_scalar x n |> with_tensor_gc
;;

let special_hermite_polynomial_h_n_scalar_out ~out ~x ~n =
  stubs_special_hermite_polynomial_h_n_scalar_out out x n |> with_tensor_gc
;;

let special_hermite_polynomial_h_out ~out ~x ~n =
  stubs_special_hermite_polynomial_h_out out x n |> with_tensor_gc
;;

let special_hermite_polynomial_h_x_scalar ~x ~n =
  stubs_special_hermite_polynomial_h_x_scalar x n |> with_tensor_gc
;;

let special_hermite_polynomial_h_x_scalar_out ~out ~x ~n =
  stubs_special_hermite_polynomial_h_x_scalar_out out x n |> with_tensor_gc
;;

let special_hermite_polynomial_he ~x ~n =
  stubs_special_hermite_polynomial_he x n |> with_tensor_gc
;;

let special_hermite_polynomial_he_n_scalar ~x ~n =
  stubs_special_hermite_polynomial_he_n_scalar x n |> with_tensor_gc
;;

let special_hermite_polynomial_he_n_scalar_out ~out ~x ~n =
  stubs_special_hermite_polynomial_he_n_scalar_out out x n |> with_tensor_gc
;;

let special_hermite_polynomial_he_out ~out ~x ~n =
  stubs_special_hermite_polynomial_he_out out x n |> with_tensor_gc
;;

let special_hermite_polynomial_he_x_scalar ~x ~n =
  stubs_special_hermite_polynomial_he_x_scalar x n |> with_tensor_gc
;;

let special_hermite_polynomial_he_x_scalar_out ~out ~x ~n =
  stubs_special_hermite_polynomial_he_x_scalar_out out x n |> with_tensor_gc
;;

let special_i0 self = stubs_special_i0 self |> with_tensor_gc
let special_i0_out ~out self = stubs_special_i0_out out self |> with_tensor_gc
let special_i0e self = stubs_special_i0e self |> with_tensor_gc
let special_i0e_out ~out self = stubs_special_i0e_out out self |> with_tensor_gc
let special_i1 self = stubs_special_i1 self |> with_tensor_gc
let special_i1_out ~out self = stubs_special_i1_out out self |> with_tensor_gc
let special_i1e self = stubs_special_i1e self |> with_tensor_gc
let special_i1e_out ~out self = stubs_special_i1e_out out self |> with_tensor_gc

let special_laguerre_polynomial_l ~x ~n =
  stubs_special_laguerre_polynomial_l x n |> with_tensor_gc
;;

let special_laguerre_polynomial_l_n_scalar ~x ~n =
  stubs_special_laguerre_polynomial_l_n_scalar x n |> with_tensor_gc
;;

let special_laguerre_polynomial_l_n_scalar_out ~out ~x ~n =
  stubs_special_laguerre_polynomial_l_n_scalar_out out x n |> with_tensor_gc
;;

let special_laguerre_polynomial_l_out ~out ~x ~n =
  stubs_special_laguerre_polynomial_l_out out x n |> with_tensor_gc
;;

let special_laguerre_polynomial_l_x_scalar ~x ~n =
  stubs_special_laguerre_polynomial_l_x_scalar x n |> with_tensor_gc
;;

let special_laguerre_polynomial_l_x_scalar_out ~out ~x ~n =
  stubs_special_laguerre_polynomial_l_x_scalar_out out x n |> with_tensor_gc
;;

let special_legendre_polynomial_p ~x ~n =
  stubs_special_legendre_polynomial_p x n |> with_tensor_gc
;;

let special_legendre_polynomial_p_n_scalar ~x ~n =
  stubs_special_legendre_polynomial_p_n_scalar x n |> with_tensor_gc
;;

let special_legendre_polynomial_p_n_scalar_out ~out ~x ~n =
  stubs_special_legendre_polynomial_p_n_scalar_out out x n |> with_tensor_gc
;;

let special_legendre_polynomial_p_out ~out ~x ~n =
  stubs_special_legendre_polynomial_p_out out x n |> with_tensor_gc
;;

let special_legendre_polynomial_p_x_scalar ~x ~n =
  stubs_special_legendre_polynomial_p_x_scalar x n |> with_tensor_gc
;;

let special_legendre_polynomial_p_x_scalar_out ~out ~x ~n =
  stubs_special_legendre_polynomial_p_x_scalar_out out x n |> with_tensor_gc
;;

let special_log1p self = stubs_special_log1p self |> with_tensor_gc
let special_log1p_out ~out self = stubs_special_log1p_out out self |> with_tensor_gc
let special_log_ndtr self = stubs_special_log_ndtr self |> with_tensor_gc
let special_log_ndtr_out ~out self = stubs_special_log_ndtr_out out self |> with_tensor_gc

let special_log_softmax self ~dim ~dtype =
  stubs_special_log_softmax self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let special_logit self ~eps =
  stubs_special_logit
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let special_logit_out ~out self ~eps =
  stubs_special_logit_out
    out
    self
    (Option.value eps ~default:0.0)
    (match eps with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let special_logsumexp self ~dim ~keepdim =
  stubs_special_logsumexp
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let special_logsumexp_out ~out self ~dim ~keepdim =
  stubs_special_logsumexp_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let special_modified_bessel_i0 self =
  stubs_special_modified_bessel_i0 self |> with_tensor_gc
;;

let special_modified_bessel_i0_out ~out self =
  stubs_special_modified_bessel_i0_out out self |> with_tensor_gc
;;

let special_modified_bessel_i1 self =
  stubs_special_modified_bessel_i1 self |> with_tensor_gc
;;

let special_modified_bessel_i1_out ~out self =
  stubs_special_modified_bessel_i1_out out self |> with_tensor_gc
;;

let special_modified_bessel_k0 self =
  stubs_special_modified_bessel_k0 self |> with_tensor_gc
;;

let special_modified_bessel_k0_out ~out self =
  stubs_special_modified_bessel_k0_out out self |> with_tensor_gc
;;

let special_modified_bessel_k1 self =
  stubs_special_modified_bessel_k1 self |> with_tensor_gc
;;

let special_modified_bessel_k1_out ~out self =
  stubs_special_modified_bessel_k1_out out self |> with_tensor_gc
;;

let special_multigammaln self ~p =
  stubs_special_multigammaln self (Int64.of_int p) |> with_tensor_gc
;;

let special_multigammaln_out ~out self ~p =
  stubs_special_multigammaln_out out self (Int64.of_int p) |> with_tensor_gc
;;

let special_ndtr self = stubs_special_ndtr self |> with_tensor_gc
let special_ndtr_out ~out self = stubs_special_ndtr_out out self |> with_tensor_gc
let special_ndtri self = stubs_special_ndtri self |> with_tensor_gc
let special_ndtri_out ~out self = stubs_special_ndtri_out out self |> with_tensor_gc

let special_polygamma ~n self =
  stubs_special_polygamma (Int64.of_int n) self |> with_tensor_gc
;;

let special_polygamma_out ~out ~n self =
  stubs_special_polygamma_out out (Int64.of_int n) self |> with_tensor_gc
;;

let special_psi self = stubs_special_psi self |> with_tensor_gc
let special_psi_out ~out self = stubs_special_psi_out out self |> with_tensor_gc

let special_round self ~decimals =
  stubs_special_round self (Int64.of_int decimals) |> with_tensor_gc
;;

let special_round_out ~out self ~decimals =
  stubs_special_round_out out self (Int64.of_int decimals) |> with_tensor_gc
;;

let special_scaled_modified_bessel_k0 ~x =
  stubs_special_scaled_modified_bessel_k0 x |> with_tensor_gc
;;

let special_scaled_modified_bessel_k0_out ~out ~x =
  stubs_special_scaled_modified_bessel_k0_out out x |> with_tensor_gc
;;

let special_scaled_modified_bessel_k1 ~x =
  stubs_special_scaled_modified_bessel_k1 x |> with_tensor_gc
;;

let special_scaled_modified_bessel_k1_out ~out ~x =
  stubs_special_scaled_modified_bessel_k1_out out x |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_t ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_t x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_t_n_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_t_n_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_t_n_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_t_n_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_t_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_t_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_t_x_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_t_x_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_t_x_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_t_x_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_u ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_u x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_u_n_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_u_n_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_u_n_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_u_n_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_u_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_u_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_u_x_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_u_x_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_u_x_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_u_x_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_v ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_v x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_v_n_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_v_n_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_v_n_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_v_n_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_v_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_v_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_v_x_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_v_x_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_v_x_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_v_x_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_w ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_w x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_w_n_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_w_n_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_w_n_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_w_n_scalar_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_w_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_w_out out x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_w_x_scalar ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_w_x_scalar x n |> with_tensor_gc
;;

let special_shifted_chebyshev_polynomial_w_x_scalar_out ~out ~x ~n =
  stubs_special_shifted_chebyshev_polynomial_w_x_scalar_out out x n |> with_tensor_gc
;;

let special_sinc self = stubs_special_sinc self |> with_tensor_gc
let special_sinc_out ~out self = stubs_special_sinc_out out self |> with_tensor_gc

let special_softmax self ~dim ~dtype =
  stubs_special_softmax self (Int64.of_int dim) (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let special_spherical_bessel_j0 ~x = stubs_special_spherical_bessel_j0 x |> with_tensor_gc

let special_spherical_bessel_j0_out ~out ~x =
  stubs_special_spherical_bessel_j0_out out x |> with_tensor_gc
;;

let special_xlog1py self other = stubs_special_xlog1py self other |> with_tensor_gc

let special_xlog1py_other_scalar self other =
  stubs_special_xlog1py_other_scalar self other |> with_tensor_gc
;;

let special_xlog1py_other_scalar_out ~out self other =
  stubs_special_xlog1py_other_scalar_out out self other |> with_tensor_gc
;;

let special_xlog1py_out ~out self other =
  stubs_special_xlog1py_out out self other |> with_tensor_gc
;;

let special_xlog1py_self_scalar self other =
  stubs_special_xlog1py_self_scalar self other |> with_tensor_gc
;;

let special_xlog1py_self_scalar_out ~out self other =
  stubs_special_xlog1py_self_scalar_out out self other |> with_tensor_gc
;;

let special_xlogy self other = stubs_special_xlogy self other |> with_tensor_gc

let special_xlogy_other_scalar self other =
  stubs_special_xlogy_other_scalar self other |> with_tensor_gc
;;

let special_xlogy_other_scalar_out ~out self other =
  stubs_special_xlogy_other_scalar_out out self other |> with_tensor_gc
;;

let special_xlogy_out ~out self other =
  stubs_special_xlogy_out out self other |> with_tensor_gc
;;

let special_xlogy_self_scalar self other =
  stubs_special_xlogy_self_scalar self other |> with_tensor_gc
;;

let special_xlogy_self_scalar_out ~out self other =
  stubs_special_xlogy_self_scalar_out out self other |> with_tensor_gc
;;

let special_zeta self other = stubs_special_zeta self other |> with_tensor_gc

let special_zeta_other_scalar self other =
  stubs_special_zeta_other_scalar self other |> with_tensor_gc
;;

let special_zeta_other_scalar_out ~out self other =
  stubs_special_zeta_other_scalar_out out self other |> with_tensor_gc
;;

let special_zeta_out ~out self other =
  stubs_special_zeta_out out self other |> with_tensor_gc
;;

let special_zeta_self_scalar self other =
  stubs_special_zeta_self_scalar self other |> with_tensor_gc
;;

let special_zeta_self_scalar_out ~out self other =
  stubs_special_zeta_self_scalar_out out self other |> with_tensor_gc
;;

let split self ~split_size ~dim =
  stubs_split self (Int64.of_int split_size) (Int64.of_int dim) |> to_tensor_list
;;

let split_copy self ~split_size ~dim =
  stubs_split_copy self (Int64.of_int split_size) (Int64.of_int dim) |> to_tensor_list
;;

let split_copy_tensor_out ~out self ~split_size ~dim =
  let result =
    stubs_split_copy_tensor_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      self
      (Int64.of_int split_size)
      (Int64.of_int dim)
  in
  keep_values_alive out;
  result
;;

let split_sizes self ~split_size ~dim =
  stubs_split_sizes
    self
    (List.map Int64.of_int split_size |> CArray.of_list int64_t |> CArray.start)
    (List.length split_size)
    (Int64.of_int dim)
  |> to_tensor_list
;;

let split_with_sizes self ~split_sizes ~dim =
  stubs_split_with_sizes
    self
    (List.map Int64.of_int split_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length split_sizes)
    (Int64.of_int dim)
  |> to_tensor_list
;;

let split_with_sizes_copy self ~split_sizes ~dim =
  stubs_split_with_sizes_copy
    self
    (List.map Int64.of_int split_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length split_sizes)
    (Int64.of_int dim)
  |> to_tensor_list
;;

let split_with_sizes_copy_out ~out self ~split_sizes ~dim =
  let result =
    stubs_split_with_sizes_copy_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      self
      (List.map Int64.of_int split_sizes |> CArray.of_list int64_t |> CArray.start)
      (List.length split_sizes)
      (Int64.of_int dim)
  in
  keep_values_alive out;
  result
;;

let sqrt self = stubs_sqrt self |> with_tensor_gc
let sqrt_ self = stubs_sqrt_ self |> with_tensor_gc
let sqrt_out ~out self = stubs_sqrt_out out self |> with_tensor_gc
let square self = stubs_square self |> with_tensor_gc
let square_ self = stubs_square_ self |> with_tensor_gc
let square_out ~out self = stubs_square_out out self |> with_tensor_gc
let squeeze self = stubs_squeeze self |> with_tensor_gc
let squeeze_ self = stubs_squeeze_ self |> with_tensor_gc
let squeeze_copy self = stubs_squeeze_copy self |> with_tensor_gc

let squeeze_copy_dim self ~dim =
  stubs_squeeze_copy_dim self (Int64.of_int dim) |> with_tensor_gc
;;

let squeeze_copy_dim_out ~out self ~dim =
  stubs_squeeze_copy_dim_out out self (Int64.of_int dim) |> with_tensor_gc
;;

let squeeze_copy_dims self ~dim =
  stubs_squeeze_copy_dims
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let squeeze_copy_dims_out ~out self ~dim =
  stubs_squeeze_copy_dims_out
    out
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let squeeze_copy_out ~out self = stubs_squeeze_copy_out out self |> with_tensor_gc
let squeeze_dim self ~dim = stubs_squeeze_dim self (Int64.of_int dim) |> with_tensor_gc
let squeeze_dim_ self ~dim = stubs_squeeze_dim_ self (Int64.of_int dim) |> with_tensor_gc

let squeeze_dims self ~dim =
  stubs_squeeze_dims
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let squeeze_dims_ self ~dim =
  stubs_squeeze_dims_
    self
    (List.map Int64.of_int dim |> CArray.of_list int64_t |> CArray.start)
    (List.length dim)
  |> with_tensor_gc
;;

let sspaddmm ?beta ?alpha self ~mat1 ~mat2 =
  stubs_sspaddmm
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sspaddmm_out ?beta ?alpha ~out self ~mat1 ~mat2 =
  stubs_sspaddmm_out
    out
    self
    mat1
    mat2
    (match beta with
     | Some v -> v
     | None -> none_scalar)
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let stack tensors ~dim =
  let result =
    stubs_stack
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let stack_out ~out tensors ~dim =
  let result =
    stubs_stack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
      (Int64.of_int dim)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let std self ~unbiased = stubs_std self (if unbiased then 1 else 0) |> with_tensor_gc

let std_correction self ~dim ~correction ~keepdim =
  stubs_std_correction
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let std_correction_out ~out self ~dim ~correction ~keepdim =
  stubs_std_correction_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let std_dim self ~dim ~unbiased ~keepdim =
  stubs_std_dim
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if unbiased then 1 else 0)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let std_mean self ~unbiased =
  let out__ = CArray.make raw_tensor 2 in
  stubs_std_mean (CArray.start out__) self (if unbiased then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let std_mean_correction self ~dim ~correction ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_std_mean_correction
    (CArray.start out__)
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let std_mean_correction_out ~out0 ~out1 self ~dim ~correction ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_std_mean_correction_out
    (CArray.start out__)
    out0
    out1
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let std_mean_dim self ~dim ~unbiased ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_std_mean_dim
    (CArray.start out__)
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if unbiased then 1 else 0)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let std_out ~out self ~dim ~unbiased ~keepdim =
  stubs_std_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if unbiased then 1 else 0)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let stft
  self
  ~n_fft
  ~hop_length
  ~win_length
  ~window
  ~normalized
  ~onesided
  ~return_complex
  ~align_to_window
  =
  stubs_stft
    self
    (Int64.of_int n_fft)
    (match hop_length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match hop_length with
     | Some _ -> 0
     | None -> 1)
    (match win_length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match win_length with
     | Some _ -> 0
     | None -> 1)
    (match window with
     | Some v -> v
     | None -> none_gc_tensor)
    (if normalized then 1 else 0)
    (if onesided then 1 else 0)
    (if return_complex then 1 else 0)
    (if align_to_window then 1 else 0)
  |> with_tensor_gc
;;

let stft_center
  self
  ~n_fft
  ~hop_length
  ~win_length
  ~window
  ~center
  ~pad_mode
  ~normalized
  ~onesided
  ~return_complex
  ~align_to_window
  =
  stubs_stft_center
    self
    (Int64.of_int n_fft)
    (match hop_length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match hop_length with
     | Some _ -> 0
     | None -> 1)
    (match win_length with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match win_length with
     | Some _ -> 0
     | None -> 1)
    (match window with
     | Some v -> v
     | None -> none_gc_tensor)
    (if center then 1 else 0)
    pad_mode
    (if normalized then 1 else 0)
    (if onesided then 1 else 0)
    (if return_complex then 1 else 0)
    (if align_to_window then 1 else 0)
  |> with_tensor_gc
;;

let stride self ~dim = stubs_stride self (Int64.of_int dim)

let sub ?alpha self other =
  stubs_sub
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sub_ ?alpha self other =
  stubs_sub_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sub_out ?alpha ~out self other =
  stubs_sub_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sub_scalar ?alpha self other =
  stubs_sub_scalar
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sub_scalar_ ?alpha self other =
  stubs_sub_scalar_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sub_scalar_out ?alpha ~out self other =
  stubs_sub_scalar_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let subtract ?alpha self other =
  stubs_subtract
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let subtract_ ?alpha self other =
  stubs_subtract_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let subtract_out ?alpha ~out self other =
  stubs_subtract_out
    out
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let subtract_scalar ?alpha self other =
  stubs_subtract_scalar
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let subtract_scalar_ ?alpha self other =
  stubs_subtract_scalar_
    self
    other
    (match alpha with
     | Some v -> v
     | None -> none_scalar)
  |> with_tensor_gc
;;

let sum self ~dtype = stubs_sum self (Kind.packed_to_int dtype) |> with_tensor_gc

let sum_dim_intlist self ~dim ~keepdim ~dtype =
  stubs_sum_dim_intlist
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let sum_intlist_out ~out self ~dim ~keepdim ~dtype =
  stubs_sum_intlist_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if keepdim then 1 else 0)
    (Kind.packed_to_int dtype)
  |> with_tensor_gc
;;

let sum_out ~out self ~dtype =
  stubs_sum_out out self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let sum_to_size self ~size =
  stubs_sum_to_size
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let svd self ~some ~compute_uv =
  let out__ = CArray.make raw_tensor 3 in
  stubs_svd
    (CArray.start out__)
    self
    (if some then 1 else 0)
    (if compute_uv then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let svd_u ~u ~s ~v self ~some ~compute_uv =
  let out__ = CArray.make raw_tensor 3 in
  stubs_svd_u
    (CArray.start out__)
    u
    s
    v
    self
    (if some then 1 else 0)
    (if compute_uv then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let swapaxes self ~axis0 ~axis1 =
  stubs_swapaxes self (Int64.of_int axis0) (Int64.of_int axis1) |> with_tensor_gc
;;

let swapaxes_ self ~axis0 ~axis1 =
  stubs_swapaxes_ self (Int64.of_int axis0) (Int64.of_int axis1) |> with_tensor_gc
;;

let swapdims self ~dim0 ~dim1 =
  stubs_swapdims self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let swapdims_ self ~dim0 ~dim1 =
  stubs_swapdims_ self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let tr self = stubs_tr self |> with_tensor_gc
let t_ self = stubs_t_ self |> with_tensor_gc
let t_copy self = stubs_t_copy self |> with_tensor_gc
let t_copy_out ~out self = stubs_t_copy_out out self |> with_tensor_gc
let take self ~index = stubs_take self index |> with_tensor_gc

let take_along_dim self ~indices ~dim =
  stubs_take_along_dim
    self
    indices
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let take_along_dim_out ~out self ~indices ~dim =
  stubs_take_along_dim_out
    out
    self
    indices
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let take_out ~out self ~index = stubs_take_out out self index |> with_tensor_gc
let tan self = stubs_tan self |> with_tensor_gc
let tan_ self = stubs_tan_ self |> with_tensor_gc
let tan_out ~out self = stubs_tan_out out self |> with_tensor_gc
let tanh self = stubs_tanh self |> with_tensor_gc
let tanh_ self = stubs_tanh_ self |> with_tensor_gc

let tanh_backward ~grad_output ~output =
  stubs_tanh_backward grad_output output |> with_tensor_gc
;;

let tanh_backward_grad_input ~grad_input ~grad_output ~output =
  stubs_tanh_backward_grad_input grad_input grad_output output |> with_tensor_gc
;;

let tanh_out ~out self = stubs_tanh_out out self |> with_tensor_gc

let tensor_split self ~sections ~dim =
  stubs_tensor_split self (Int64.of_int sections) (Int64.of_int dim) |> to_tensor_list
;;

let tensor_split_indices self ~indices ~dim =
  stubs_tensor_split_indices
    self
    (List.map Int64.of_int indices |> CArray.of_list int64_t |> CArray.start)
    (List.length indices)
    (Int64.of_int dim)
  |> to_tensor_list
;;

let tensor_split_tensor_indices_or_sections self ~tensor_indices_or_sections ~dim =
  stubs_tensor_split_tensor_indices_or_sections
    self
    tensor_indices_or_sections
    (Int64.of_int dim)
  |> to_tensor_list
;;

let tensordot self other ~dims_self ~dims_other =
  stubs_tensordot
    self
    other
    (List.map Int64.of_int dims_self |> CArray.of_list int64_t |> CArray.start)
    (List.length dims_self)
    (List.map Int64.of_int dims_other |> CArray.of_list int64_t |> CArray.start)
    (List.length dims_other)
  |> with_tensor_gc
;;

let tensordot_out ~out self other ~dims_self ~dims_other =
  stubs_tensordot_out
    out
    self
    other
    (List.map Int64.of_int dims_self |> CArray.of_list int64_t |> CArray.start)
    (List.length dims_self)
    (List.map Int64.of_int dims_other |> CArray.of_list int64_t |> CArray.start)
    (List.length dims_other)
  |> with_tensor_gc
;;

let threshold self ~threshold ~value =
  stubs_threshold self threshold value |> with_tensor_gc
;;

let threshold_ self ~threshold ~value =
  stubs_threshold_ self threshold value |> with_tensor_gc
;;

let threshold_backward ~grad_output self ~threshold =
  stubs_threshold_backward grad_output self threshold |> with_tensor_gc
;;

let threshold_backward_grad_input ~grad_input ~grad_output self ~threshold =
  stubs_threshold_backward_grad_input grad_input grad_output self threshold
  |> with_tensor_gc
;;

let threshold_out ~out self ~threshold ~value =
  stubs_threshold_out out self threshold value |> with_tensor_gc
;;

let tile self ~dims =
  stubs_tile
    self
    (List.map Int64.of_int dims |> CArray.of_list int64_t |> CArray.start)
    (List.length dims)
  |> with_tensor_gc
;;

let to_ self ~device = stubs_to_ self (Device.to_int device) |> with_tensor_gc

let to_dense self ~dtype ~masked_grad =
  stubs_to_dense self (Kind.packed_to_int dtype) (if masked_grad then 1 else 0)
  |> with_tensor_gc
;;

let to_dense_backward ~grad input ~masked_grad =
  stubs_to_dense_backward grad input (if masked_grad then 1 else 0) |> with_tensor_gc
;;

let to_device self ~device ~dtype ~non_blocking ~copy =
  stubs_to_device
    self
    (Device.to_int device)
    (Kind.packed_to_int dtype)
    (if non_blocking then 1 else 0)
    (if copy then 1 else 0)
  |> with_tensor_gc
;;

let to_dtype self ~dtype ~non_blocking ~copy =
  stubs_to_dtype
    self
    (Kind.packed_to_int dtype)
    (if non_blocking then 1 else 0)
    (if copy then 1 else 0)
  |> with_tensor_gc
;;

let to_dtype_layout self ~options ~non_blocking ~copy =
  stubs_to_dtype_layout
    self
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
    (if non_blocking then 1 else 0)
    (if copy then 1 else 0)
  |> with_tensor_gc
;;

let to_mkldnn self ~dtype =
  stubs_to_mkldnn self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let to_mkldnn_backward ~grad input = stubs_to_mkldnn_backward grad input |> with_tensor_gc

let to_mkldnn_out ~out self ~dtype =
  stubs_to_mkldnn_out out self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let to_other self other ~non_blocking ~copy =
  stubs_to_other self other (if non_blocking then 1 else 0) (if copy then 1 else 0)
  |> with_tensor_gc
;;

let to_padded_tensor self ~padding ~output_size =
  stubs_to_padded_tensor
    self
    padding
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let to_padded_tensor_out ~out self ~padding ~output_size =
  stubs_to_padded_tensor_out
    out
    self
    padding
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
  |> with_tensor_gc
;;

let topk self ~k ~dim ~largest ~sorted =
  let out__ = CArray.make raw_tensor 2 in
  stubs_topk
    (CArray.start out__)
    self
    (Int64.of_int k)
    (Int64.of_int dim)
    (if largest then 1 else 0)
    (if sorted then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let topk_values ~values ~indices self ~k ~dim ~largest ~sorted =
  let out__ = CArray.make raw_tensor 2 in
  stubs_topk_values
    (CArray.start out__)
    values
    indices
    self
    (Int64.of_int k)
    (Int64.of_int dim)
    (if largest then 1 else 0)
    (if sorted then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let totype self ~scalar_type =
  stubs_totype self (Kind.packed_to_int scalar_type) |> with_tensor_gc
;;

let trace self = stubs_trace self |> with_tensor_gc

let trace_backward ~grad ~sizes =
  stubs_trace_backward
    grad
    (List.map Int64.of_int sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length sizes)
  |> with_tensor_gc
;;

let trace_out ~out self = stubs_trace_out out self |> with_tensor_gc

let transpose self ~dim0 ~dim1 =
  stubs_transpose self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let transpose_ self ~dim0 ~dim1 =
  stubs_transpose_ self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let transpose_copy self ~dim0 ~dim1 =
  stubs_transpose_copy self (Int64.of_int dim0) (Int64.of_int dim1) |> with_tensor_gc
;;

let transpose_copy_int_out ~out self ~dim0 ~dim1 =
  stubs_transpose_copy_int_out out self (Int64.of_int dim0) (Int64.of_int dim1)
  |> with_tensor_gc
;;

let trapezoid ~y ~x ~dim = stubs_trapezoid y x (Int64.of_int dim) |> with_tensor_gc

let trapezoid_dx ?dx ~y ~dim () =
  stubs_trapezoid_dx
    y
    (match dx with
     | Some v -> v
     | None -> none_scalar)
    (Int64.of_int dim)
  |> with_tensor_gc
;;

let trapz ~y ~x ~dim = stubs_trapz y x (Int64.of_int dim) |> with_tensor_gc
let trapz_dx ~y ~dx ~dim = stubs_trapz_dx y dx (Int64.of_int dim) |> with_tensor_gc

let triangular_solve self ~a ~upper ~transpose ~unitriangular =
  let out__ = CArray.make raw_tensor 2 in
  stubs_triangular_solve
    (CArray.start out__)
    self
    a
    (if upper then 1 else 0)
    (if transpose then 1 else 0)
    (if unitriangular then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let triangular_solve_x ~x ~m self ~a ~upper ~transpose ~unitriangular =
  let out__ = CArray.make raw_tensor 2 in
  stubs_triangular_solve_x
    (CArray.start out__)
    x
    m
    self
    a
    (if upper then 1 else 0)
    (if transpose then 1 else 0)
    (if unitriangular then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let tril self ~diagonal = stubs_tril self (Int64.of_int diagonal) |> with_tensor_gc
let tril_ self ~diagonal = stubs_tril_ self (Int64.of_int diagonal) |> with_tensor_gc

let tril_indices ~row ~col ~offset ~options =
  stubs_tril_indices
    (Int64.of_int row)
    (Int64.of_int col)
    (Int64.of_int offset)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let tril_indices_out ~out ~row ~col ~offset =
  stubs_tril_indices_out out (Int64.of_int row) (Int64.of_int col) (Int64.of_int offset)
  |> with_tensor_gc
;;

let tril_out ~out self ~diagonal =
  stubs_tril_out out self (Int64.of_int diagonal) |> with_tensor_gc
;;

let triplet_margin_loss ~anchor ~positive ~negative ~margin ~p ~eps ~swap ~reduction =
  stubs_triplet_margin_loss
    anchor
    positive
    negative
    margin
    p
    eps
    (if swap then 1 else 0)
    (Reduction.to_int reduction |> Int64.of_int)
  |> with_tensor_gc
;;

let triu self ~diagonal = stubs_triu self (Int64.of_int diagonal) |> with_tensor_gc
let triu_ self ~diagonal = stubs_triu_ self (Int64.of_int diagonal) |> with_tensor_gc

let triu_indices ~row ~col ~offset ~options =
  stubs_triu_indices
    (Int64.of_int row)
    (Int64.of_int col)
    (Int64.of_int offset)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let triu_indices_out ~out ~row ~col ~offset =
  stubs_triu_indices_out out (Int64.of_int row) (Int64.of_int col) (Int64.of_int offset)
  |> with_tensor_gc
;;

let triu_out ~out self ~diagonal =
  stubs_triu_out out self (Int64.of_int diagonal) |> with_tensor_gc
;;

let true_divide self other = stubs_true_divide self other |> with_tensor_gc
let true_divide_ self other = stubs_true_divide_ self other |> with_tensor_gc

let true_divide_out ~out self other =
  stubs_true_divide_out out self other |> with_tensor_gc
;;

let true_divide_scalar self other = stubs_true_divide_scalar self other |> with_tensor_gc

let true_divide_scalar_ self other =
  stubs_true_divide_scalar_ self other |> with_tensor_gc
;;

let trunc self = stubs_trunc self |> with_tensor_gc
let trunc_ self = stubs_trunc_ self |> with_tensor_gc
let trunc_out ~out self = stubs_trunc_out out self |> with_tensor_gc
let type_as self other = stubs_type_as self other |> with_tensor_gc
let unbind self ~dim = stubs_unbind self (Int64.of_int dim) |> to_tensor_list
let unbind_copy self ~dim = stubs_unbind_copy self (Int64.of_int dim) |> to_tensor_list

let unbind_copy_int_out ~out self ~dim =
  let result =
    stubs_unbind_copy_int_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      self
      (Int64.of_int dim)
  in
  keep_values_alive out;
  result
;;

let unflatten self ~dim ~sizes =
  stubs_unflatten
    self
    (Int64.of_int dim)
    (List.map Int64.of_int sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length sizes)
  |> with_tensor_gc
;;

let unflatten_dense_tensors ~flat tensors =
  let result =
    stubs_unflatten_dense_tensors
      flat
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> to_tensor_list
  in
  keep_values_alive tensors;
  result
;;

let unfold self ~dimension ~size ~step =
  stubs_unfold self (Int64.of_int dimension) (Int64.of_int size) (Int64.of_int step)
  |> with_tensor_gc
;;

let unfold_backward ~grad_in ~input_sizes ~dim ~size ~step =
  stubs_unfold_backward
    grad_in
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int dim)
    (Int64.of_int size)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let unfold_backward_out ~out ~grad_in ~input_sizes ~dim ~size ~step =
  stubs_unfold_backward_out
    out
    grad_in
    (List.map Int64.of_int input_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length input_sizes)
    (Int64.of_int dim)
    (Int64.of_int size)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let unfold_copy self ~dimension ~size ~step =
  stubs_unfold_copy self (Int64.of_int dimension) (Int64.of_int size) (Int64.of_int step)
  |> with_tensor_gc
;;

let unfold_copy_out ~out self ~dimension ~size ~step =
  stubs_unfold_copy_out
    out
    self
    (Int64.of_int dimension)
    (Int64.of_int size)
    (Int64.of_int step)
  |> with_tensor_gc
;;

let uniform self ~from ~to_ = stubs_uniform self from to_ |> with_tensor_gc
let uniform_ self ~from ~to_ = stubs_uniform_ self from to_ |> with_tensor_gc

let uniform_out ~out self ~from ~to_ =
  stubs_uniform_out out self from to_ |> with_tensor_gc
;;

let unique_consecutive self ~return_inverse ~return_counts ~dim =
  let out__ = CArray.make raw_tensor 3 in
  stubs_unique_consecutive
    (CArray.start out__)
    self
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0)
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let unique_consecutive_out ~out0 ~out1 ~out2 self ~return_inverse ~return_counts ~dim =
  let out__ = CArray.make raw_tensor 3 in
  stubs_unique_consecutive_out
    (CArray.start out__)
    out0
    out1
    out2
    self
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0)
    (match dim with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match dim with
     | Some _ -> 0
     | None -> 1);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let unique_dim self ~dim ~sorted ~return_inverse ~return_counts =
  let out__ = CArray.make raw_tensor 3 in
  stubs_unique_dim
    (CArray.start out__)
    self
    (Int64.of_int dim)
    (if sorted then 1 else 0)
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let unique_dim_consecutive self ~dim ~return_inverse ~return_counts =
  let out__ = CArray.make raw_tensor 3 in
  stubs_unique_dim_consecutive
    (CArray.start out__)
    self
    (Int64.of_int dim)
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let unique_dim_consecutive_out ~out0 ~out1 ~out2 self ~dim ~return_inverse ~return_counts =
  let out__ = CArray.make raw_tensor 3 in
  stubs_unique_dim_consecutive_out
    (CArray.start out__)
    out0
    out1
    out2
    self
    (Int64.of_int dim)
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let unique_dim_out ~out0 ~out1 ~out2 self ~dim ~sorted ~return_inverse ~return_counts =
  let out__ = CArray.make raw_tensor 3 in
  stubs_unique_dim_out
    (CArray.start out__)
    out0
    out1
    out2
    self
    (Int64.of_int dim)
    (if sorted then 1 else 0)
    (if return_inverse then 1 else 0)
    (if return_counts then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  let t2 = CArray.get out__ 2 |> with_tensor_gc in
  t0, t1, t2
;;

let unsafe_chunk self ~chunks ~dim =
  stubs_unsafe_chunk self (Int64.of_int chunks) (Int64.of_int dim) |> to_tensor_list
;;

let unsafe_split self ~split_size ~dim =
  stubs_unsafe_split self (Int64.of_int split_size) (Int64.of_int dim) |> to_tensor_list
;;

let unsafe_split_tensor_out ~out self ~split_size ~dim =
  let result =
    stubs_unsafe_split_tensor_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      self
      (Int64.of_int split_size)
      (Int64.of_int dim)
  in
  keep_values_alive out;
  result
;;

let unsafe_split_with_sizes self ~split_sizes ~dim =
  stubs_unsafe_split_with_sizes
    self
    (List.map Int64.of_int split_sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length split_sizes)
    (Int64.of_int dim)
  |> to_tensor_list
;;

let unsafe_split_with_sizes_out ~out self ~split_sizes ~dim =
  let result =
    stubs_unsafe_split_with_sizes_out
      (CArray.of_list gc_tensor out |> CArray.start)
      (List.length out)
      self
      (List.map Int64.of_int split_sizes |> CArray.of_list int64_t |> CArray.start)
      (List.length split_sizes)
      (Int64.of_int dim)
  in
  keep_values_alive out;
  result
;;

let unsqueeze self ~dim = stubs_unsqueeze self (Int64.of_int dim) |> with_tensor_gc
let unsqueeze_ self ~dim = stubs_unsqueeze_ self (Int64.of_int dim) |> with_tensor_gc

let unsqueeze_copy self ~dim =
  stubs_unsqueeze_copy self (Int64.of_int dim) |> with_tensor_gc
;;

let unsqueeze_copy_out ~out self ~dim =
  stubs_unsqueeze_copy_out out self (Int64.of_int dim) |> with_tensor_gc
;;

let upsample_bicubic2d self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs_upsample_bicubic2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bicubic2d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs_upsample_bicubic2d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bicubic2d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs_upsample_bicubic2d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bicubic2d_out ~out self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs_upsample_bicubic2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bicubic2d_vec input ~output_size ~align_corners ~scale_factors =
  stubs_upsample_bicubic2d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_bilinear2d self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs_upsample_bilinear2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bilinear2d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs_upsample_bilinear2d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bilinear2d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_h
  ~scales_w
  =
  stubs_upsample_bilinear2d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bilinear2d_out ~out self ~output_size ~align_corners ~scales_h ~scales_w =
  stubs_upsample_bilinear2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_bilinear2d_vec input ~output_size ~align_corners ~scale_factors =
  stubs_upsample_bilinear2d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_bilinear2d_vec_out ~out input ~output_size ~align_corners ~scale_factors =
  stubs_upsample_bilinear2d_vec_out
    out
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_linear1d self ~output_size ~align_corners ~scales =
  stubs_upsample_linear1d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_linear1d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales
  =
  stubs_upsample_linear1d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_linear1d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales
  =
  stubs_upsample_linear1d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_linear1d_out ~out self ~output_size ~align_corners ~scales =
  stubs_upsample_linear1d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_linear1d_vec input ~output_size ~align_corners ~scale_factors =
  stubs_upsample_linear1d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_nearest1d self ~output_size ~scales =
  stubs_upsample_nearest1d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest1d_backward ~grad_output ~output_size ~input_size ~scales =
  stubs_upsample_nearest1d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest1d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~scales
  =
  stubs_upsample_nearest1d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest1d_out ~out self ~output_size ~scales =
  stubs_upsample_nearest1d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales ~default:0.0)
    (match scales with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest1d_vec input ~output_size ~scale_factors =
  stubs_upsample_nearest1d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_nearest2d self ~output_size ~scales_h ~scales_w =
  stubs_upsample_nearest2d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest2d_backward ~grad_output ~output_size ~input_size ~scales_h ~scales_w =
  stubs_upsample_nearest2d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest2d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~scales_h
  ~scales_w
  =
  stubs_upsample_nearest2d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest2d_out ~out self ~output_size ~scales_h ~scales_w =
  stubs_upsample_nearest2d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest2d_vec input ~output_size ~scale_factors =
  stubs_upsample_nearest2d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_nearest2d_vec_out ~out input ~output_size ~scale_factors =
  stubs_upsample_nearest2d_vec_out
    out
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_nearest3d self ~output_size ~scales_d ~scales_h ~scales_w =
  stubs_upsample_nearest3d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest3d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs_upsample_nearest3d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest3d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs_upsample_nearest3d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest3d_out ~out self ~output_size ~scales_d ~scales_h ~scales_w =
  stubs_upsample_nearest3d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_nearest3d_vec input ~output_size ~scale_factors =
  stubs_upsample_nearest3d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let upsample_trilinear3d self ~output_size ~align_corners ~scales_d ~scales_h ~scales_w =
  stubs_upsample_trilinear3d
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_trilinear3d_backward
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs_upsample_trilinear3d_backward
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_trilinear3d_backward_grad_input
  ~grad_input
  ~grad_output
  ~output_size
  ~input_size
  ~align_corners
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs_upsample_trilinear3d_backward_grad_input
    grad_input
    grad_output
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (List.map Int64.of_int input_size |> CArray.of_list int64_t |> CArray.start)
    (List.length input_size)
    (if align_corners then 1 else 0)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_trilinear3d_out
  ~out
  self
  ~output_size
  ~align_corners
  ~scales_d
  ~scales_h
  ~scales_w
  =
  stubs_upsample_trilinear3d_out
    out
    self
    (List.map Int64.of_int output_size |> CArray.of_list int64_t |> CArray.start)
    (List.length output_size)
    (if align_corners then 1 else 0)
    (Option.value scales_d ~default:0.0)
    (match scales_d with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_h ~default:0.0)
    (match scales_h with
     | Some _ -> 0
     | None -> 1)
    (Option.value scales_w ~default:0.0)
    (match scales_w with
     | Some _ -> 0
     | None -> 1)
  |> with_tensor_gc
;;

let upsample_trilinear3d_vec input ~output_size ~align_corners ~scale_factors =
  stubs_upsample_trilinear3d_vec
    input
    (match output_size with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match output_size with
     | None -> -1
     | Some v -> List.length v)
    (if align_corners then 1 else 0)
    (scale_factors |> CArray.of_list double |> CArray.start)
    (List.length scale_factors)
  |> with_tensor_gc
;;

let value_selecting_reduction_backward ~grad ~dim ~indices ~sizes ~keepdim =
  stubs_value_selecting_reduction_backward
    grad
    (Int64.of_int dim)
    indices
    (List.map Int64.of_int sizes |> CArray.of_list int64_t |> CArray.start)
    (List.length sizes)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let values self = stubs_values self |> with_tensor_gc
let values_copy self = stubs_values_copy self |> with_tensor_gc
let values_copy_out ~out self = stubs_values_copy_out out self |> with_tensor_gc

let vander ~x ~n ~increasing =
  stubs_vander
    x
    (match n with
     | None -> Int64.zero
     | Some v -> Int64.of_int v)
    (match n with
     | Some _ -> 0
     | None -> 1)
    (if increasing then 1 else 0)
  |> with_tensor_gc
;;

let var self ~unbiased = stubs_var self (if unbiased then 1 else 0) |> with_tensor_gc

let var_correction self ~dim ~correction ~keepdim =
  stubs_var_correction
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let var_correction_out ~out self ~dim ~correction ~keepdim =
  stubs_var_correction_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let var_dim self ~dim ~unbiased ~keepdim =
  stubs_var_dim
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if unbiased then 1 else 0)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let var_mean self ~unbiased =
  let out__ = CArray.make raw_tensor 2 in
  stubs_var_mean (CArray.start out__) self (if unbiased then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let var_mean_correction self ~dim ~correction ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_var_mean_correction
    (CArray.start out__)
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let var_mean_correction_out ~out0 ~out1 self ~dim ~correction ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_var_mean_correction_out
    (CArray.start out__)
    out0
    out1
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    correction
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let var_mean_dim self ~dim ~unbiased ~keepdim =
  let out__ = CArray.make raw_tensor 2 in
  stubs_var_mean_dim
    (CArray.start out__)
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if unbiased then 1 else 0)
    (if keepdim then 1 else 0);
  let t0 = CArray.get out__ 0 |> with_tensor_gc in
  let t1 = CArray.get out__ 1 |> with_tensor_gc in
  t0, t1
;;

let var_out ~out self ~dim ~unbiased ~keepdim =
  stubs_var_out
    out
    self
    (match dim with
     | None -> from_voidp int64_t null
     | Some v -> List.map Int64.of_int v |> CArray.of_list int64_t |> CArray.start)
    (match dim with
     | None -> -1
     | Some v -> List.length v)
    (if unbiased then 1 else 0)
    (if keepdim then 1 else 0)
  |> with_tensor_gc
;;

let vdot self other = stubs_vdot self other |> with_tensor_gc
let vdot_out ~out self other = stubs_vdot_out out self other |> with_tensor_gc

let view self ~size =
  stubs_view
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let view_as self other = stubs_view_as self other |> with_tensor_gc
let view_as_complex self = stubs_view_as_complex self |> with_tensor_gc
let view_as_complex_copy self = stubs_view_as_complex_copy self |> with_tensor_gc

let view_as_complex_copy_out ~out self =
  stubs_view_as_complex_copy_out out self |> with_tensor_gc
;;

let view_as_real self = stubs_view_as_real self |> with_tensor_gc
let view_as_real_copy self = stubs_view_as_real_copy self |> with_tensor_gc

let view_as_real_copy_out ~out self =
  stubs_view_as_real_copy_out out self |> with_tensor_gc
;;

let view_copy self ~size =
  stubs_view_copy
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let view_copy_dtype self ~dtype =
  stubs_view_copy_dtype self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let view_copy_dtype_out ~out self ~dtype =
  stubs_view_copy_dtype_out out self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let view_copy_out ~out self ~size =
  stubs_view_copy_out
    out
    self
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;

let view_dtype self ~dtype =
  stubs_view_dtype self (Kind.packed_to_int dtype) |> with_tensor_gc
;;

let vsplit self ~sections = stubs_vsplit self (Int64.of_int sections) |> to_tensor_list

let vsplit_array self ~indices =
  stubs_vsplit_array
    self
    (List.map Int64.of_int indices |> CArray.of_list int64_t |> CArray.start)
    (List.length indices)
  |> to_tensor_list
;;

let vstack tensors =
  let result =
    stubs_vstack (CArray.of_list gc_tensor tensors |> CArray.start) (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let vstack_out ~out tensors =
  let result =
    stubs_vstack_out
      out
      (CArray.of_list gc_tensor tensors |> CArray.start)
      (List.length tensors)
    |> with_tensor_gc
  in
  keep_values_alive tensors;
  result
;;

let where ~condition = stubs_where condition |> to_tensor_list

let where_scalar ~condition self other =
  stubs_where_scalar condition self other |> with_tensor_gc
;;

let where_scalarother ~condition self other =
  stubs_where_scalarother condition self other |> with_tensor_gc
;;

let where_scalarself ~condition self other =
  stubs_where_scalarself condition self other |> with_tensor_gc
;;

let where_self ~condition self other =
  stubs_where_self condition self other |> with_tensor_gc
;;

let where_self_out ~out ~condition self other =
  stubs_where_self_out out condition self other |> with_tensor_gc
;;

let xlogy self other = stubs_xlogy self other |> with_tensor_gc
let xlogy_ self other = stubs_xlogy_ self other |> with_tensor_gc

let xlogy_outscalar_other ~out self other =
  stubs_xlogy_outscalar_other out self other |> with_tensor_gc
;;

let xlogy_outscalar_self ~out self other =
  stubs_xlogy_outscalar_self out self other |> with_tensor_gc
;;

let xlogy_outtensor ~out self other =
  stubs_xlogy_outtensor out self other |> with_tensor_gc
;;

let xlogy_scalar_other self other = stubs_xlogy_scalar_other self other |> with_tensor_gc

let xlogy_scalar_other_ self other =
  stubs_xlogy_scalar_other_ self other |> with_tensor_gc
;;

let xlogy_scalar_self self other = stubs_xlogy_scalar_self self other |> with_tensor_gc
let zero self = stubs_zero self |> with_tensor_gc
let zero_ self = stubs_zero_ self |> with_tensor_gc
let zero_out ~out self = stubs_zero_out out self |> with_tensor_gc

let zeros ~size ~options =
  stubs_zeros
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
    (Kind.packed_to_int (fst options))
    (Device.to_int (snd options))
  |> with_tensor_gc
;;

let zeros_like self = stubs_zeros_like self |> with_tensor_gc
let zeros_like_out ~out self = stubs_zeros_like_out out self |> with_tensor_gc

let zeros_out ~out ~size =
  stubs_zeros_out
    out
    (List.map Int64.of_int size |> CArray.of_list int64_t |> CArray.start)
    (List.length size)
  |> with_tensor_gc
;;
